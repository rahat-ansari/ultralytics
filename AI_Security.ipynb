{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67c2db8",
      "metadata": {},
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749d45a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649852c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f33c1886",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install streamlit deepface smtplib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3ad0a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Computer Vision Surveillance Demo\n",
        "# =========================================\n",
        "# Compatible with Jupyter Notebook / Google Colab\n",
        "# Requirements: ultralytics, streamlit, opencv-python, deepface, smtplib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "\n",
        "# Load YOLO model (pre-trained COCO dataset)\n",
        "yolo_model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Define authorized persons directory\n",
        "AUTHORIZED_DIR = \"family_members\"  # or authorized_persons\n",
        "\n",
        "# Function to check if face belongs to authorized person\n",
        "def is_authorized_face(frame):\n",
        "    try:\n",
        "        result = DeepFace.find(img_path=frame, db_path=AUTHORIZED_DIR, enforce_detection=False)\n",
        "        if len(result) > 0 and not result[0].empty:\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(\"Face recognition error:\", e)\n",
        "    return False\n",
        "\n",
        "\n",
        "# Distance estimation (very simplified demo)\n",
        "def estimate_distance(bbox, frame_width):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    object_width_px = x2 - x1\n",
        "    focal_length = 500  # placeholder, needs calibration\n",
        "    real_width_cm = 50  # average cattle/person shoulder width\n",
        "    distance = (real_width_cm * focal_length) / object_width_px\n",
        "    return distance\n",
        "\n",
        "\n",
        "# Send email alert\n",
        "def send_alert_email(message):\n",
        "    sender = \"your_email@gmail.com\"\n",
        "    password = \"your_app_password\"  # For Gmail, generate app password\n",
        "    recipient = \"recipient_email@gmail.com\"\n",
        "\n",
        "    msg = MIMEText(message)\n",
        "    msg[\"Subject\"] = \"üö® Security Alert - Unauthorized Activity Detected\"\n",
        "    msg[\"From\"] = sender\n",
        "    msg[\"To\"] = recipient\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "            server.login(sender, password)\n",
        "            server.sendmail(sender, recipient, msg.as_string())\n",
        "            print(\"‚úÖ Alert email sent.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Email failed:\", e)\n",
        "\n",
        "\n",
        "# Threat detection algorithm\n",
        "def detect_threat(frame):\n",
        "    results = yolo_model(frame, show=True, conf=0.5)  # 0=person, 1=bicycle (as proxy for cattle)\n",
        "    for r in results:\n",
        "        for box in r.boxes.xyxy:  # bounding boxes\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            distance = estimate_distance((x1, y1, x2, y2), frame.shape[1])\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "            # Check if authorized\n",
        "            crop = frame[y1:y2, x1:x2]\n",
        "            if not is_authorized_face(crop):\n",
        "                cv2.putText(frame, f\"‚ö† Unauthorized {distance:.1f}cm\", (x1, y1-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "                if distance < 200:  # threshold: 2 meters\n",
        "                    # send_alert_email(\"Unauthorized person detected near cattle!\")\n",
        "                    print(\"Unauthorized person detected near cattle!\")\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "# Main video surveillance loop (for webcam or video file)\n",
        "def run_surveillance(video_source=0):\n",
        "    cap = cv2.VideoCapture(video_source)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed = detect_threat(frame)\n",
        "\n",
        "        cv2.imshow(\"Surveillance Feed\", processed)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Run the demo\n",
        "run_surveillance(0)  # webcam\n",
        "# run_surveillance(\"./media_files/animal_surveillance/goru-churi.mp4\")  # video file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd975dfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c2c572a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Computer Vision Surveillance Demo\n",
        "# =========================================\n",
        "# Compatible with Jupyter Notebook / Google Colab\n",
        "# Requirements: ultralytics, streamlit, opencv-python, deepface, smtplib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "# Load YOLO model (pre-trained COCO dataset)\n",
        "yolo_model = YOLO(\"yolo11m.pt\")\n",
        "\n",
        "# Define authorized persons directory\n",
        "AUTHORIZED_DIR = \"family_members\"  # or authorized_persons\n",
        "\n",
        "# Create the directory if it doesn't exist to avoid errors\n",
        "os.makedirs(AUTHORIZED_DIR, exist_ok=True)\n",
        "\n",
        "# Function to check if face belongs to authorized person\n",
        "def is_authorized_face(frame_crop):\n",
        "    \"\"\"\n",
        "    Checks if a face in the cropped frame is authorized by comparing against a database.\n",
        "    \"\"\"\n",
        "    if frame_crop.size == 0:\n",
        "        return False\n",
        "\n",
        "    # Define the path to the weights file\n",
        "    weights_file = os.path.join(os.path.expanduser(\"~\"), \".deepface\", \"weights\", \"vgg_face_weights.h5\")\n",
        "\n",
        "    # Check if the weights file exists, if not, inform the user\n",
        "    if not os.path.exists(weights_file):\n",
        "        print(\"VGG-Face weights file not found. DeepFace might get stuck downloading it.\")\n",
        "        print(\"Please ensure you have a stable internet connection.\")\n",
        "        print(\"If the download fails repeatedly, consider downloading it manually and placing it in\", os.path.dirname(weights_file))\n",
        "\n",
        "    try:\n",
        "        # We can iterate through known faces and verify.\n",
        "        for person_image in os.listdir(AUTHORIZED_DIR):\n",
        "            if person_image.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                known_face_path = os.path.join(AUTHORIZED_DIR, person_image)\n",
        "                try:\n",
        "                    # The verify function handles detection and comparison.\n",
        "                    result = DeepFace.verify(img1_path=frame_crop,\n",
        "                                           img2_path=known_face_path,\n",
        "                                           model_name='VGG-Face',\n",
        "                                           enforce_detection=False)\n",
        "                    if result.get(\"verified\", False):\n",
        "                        return True  # Found a match\n",
        "                except Exception as e:\n",
        "                    # This can happen if no face is found in the crop, which is expected.\n",
        "                    print(f\"Verification error: {e}\")\n",
        "                    continue\n",
        "    except Exception as e:\n",
        "        print(f\"Face recognition error: {e}\")\n",
        "    return False\n",
        "\n",
        "\n",
        "# Distance estimation (very simplified demo)\n",
        "def estimate_distance(bbox, frame_width):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    object_width_px = x2 - x1\n",
        "    focal_length = 500  # placeholder, needs calibration\n",
        "    real_width_cm = 50  # average cattle/person shoulder width\n",
        "    distance = (real_width_cm * focal_length) / object_width_px\n",
        "    return distance\n",
        "\n",
        "\n",
        "# Send email alert\n",
        "def send_alert_email(message):\n",
        "    sender = \"your_email@gmail.com\"\n",
        "    password = \"your_app_password\"  # For Gmail, generate app password\n",
        "    recipient = \"recipient_email@gmail.com\"\n",
        "\n",
        "    msg = MIMEText(message)\n",
        "    msg[\"Subject\"] = \"üö® Security Alert - Unauthorized Activity Detected\"\n",
        "    msg[\"From\"] = sender\n",
        "    msg[\"To\"] = recipient\n",
        "\n",
        "    try:\n",
        "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "            server.login(sender, password)\n",
        "            server.sendmail(sender, recipient, msg.as_string())\n",
        "            print(\"‚úÖ Alert email sent.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Email failed:\", e)\n",
        "\n",
        "\n",
        "# Threat detection algorithm\n",
        "def detect_threat(frame):\n",
        "    results = yolo_model(frame)  # 0=person, 1=bicycle (as proxy for cattle)\n",
        "    for r in results:\n",
        "        for box in r.boxes.xyxy:  # bounding boxes\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            distance = estimate_distance((x1, y1, x2, y2), frame.shape[1])\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "            # Check if authorized\n",
        "            crop = frame[y1:y2, x1:x2]\n",
        "            if not is_authorized_face(crop):\n",
        "                cv2.putText(frame, f\"‚ö† Unauthorized {distance:.1f}cm\", (x1, y1-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "                if distance < 200:  # threshold: 2 meters\n",
        "                    # send_alert_email(\"Unauthorized person detected near cattle!\")\n",
        "                    print(\"Unauthorized person detected near cattle!\")\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "# Main video surveillance loop (for webcam or video file)\n",
        "def run_surveillance(video_source=0):\n",
        "    cap = cv2.VideoCapture(video_source)\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        processed = detect_threat(frame)\n",
        "\n",
        "        cv2.imshow(\"Surveillance Feed\", processed)\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "# Run the demo\n",
        "if __name__ == \"__main__\":\n",
        "    run_surveillance('./media_files/WIN_20251103_14_11_20_Pro.mp4')  # webcam\n",
        "    # run_surveillance(\"./media_files/animal_surveillance/goru-churi.mp4\")  # video file\n",
        "    # run_surveillance(\"https://youtu.be/P_Puyf_Rb68\")  # video file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed9a6f50",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        " \n",
        "\n",
        "DeepFace.verify(img1_path=\"./images/obama/image1.jpg\", img2_path=\"./family_members/robin/robin_02.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6365529",
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a5cb24",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"yolo11m\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "# DeepFace.stream(db_path = \"family_members/\")\n",
        "# Path to the image for face recognition\n",
        "# img = \"./family_members/robin3.jpg\"\n",
        "\n",
        "# def face_recognition(img):\n",
        "#     # Perform face recognition on the provided image\n",
        "#     # Find faces and identify people using a specific model and distance metric\n",
        "#     people = DeepFace.find(img_path=img, db_path=\"Data/\", model_name=models[2], distance_metric=metrics[1])\n",
        "\n",
        "#     # Display the original image\n",
        "#     plt.imshow(cv2.imread(img))\n",
        "\n",
        "#     # Print the identities of the recognized people\n",
        "#     for person in people:\n",
        "#         print(person['identity'][0].split('/')[1])\n",
        "\n",
        "# Perform face recognition on a single image\n",
        "# face_recognition(img)\n",
        "\n",
        "def realtime_face_recognition():\n",
        "    # Define a video capture object\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    cap = cv2.VideoCapture(\"./media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "\n",
        "    while True:\n",
        "        # Capture the video frame by frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Perform face recognition on the captured frame\n",
        "        # Find faces and identify people using a specific model and distance metric\n",
        "        # people = DeepFace.find(img_path=frame, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "        people = DeepFace.find(img_path=frame, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "\n",
        "        for person in people:\n",
        "            # Retrieve the coordinates of the face bounding box\n",
        "            x = person['source_x'][0]\n",
        "            y = person['source_y'][0]\n",
        "            w = person['source_w'][0]\n",
        "            h = person['source_h'][0]\n",
        "\n",
        "            # Draw a rectangle around the face\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "            # Get the person's name and display it on the image\n",
        "            name = person['identity'][0].split('/')[1]\n",
        "            cv2.putText(frame, name, (x, y), cv2.FONT_ITALIC, 1, (0, 0, 255), 2)\n",
        "\n",
        "        # Display the resulting frame\n",
        "        cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
        "        cv2.resizeWindow('frame', 980, 450)\n",
        "        cv2.imshow('frame', frame)\n",
        "\n",
        "        # Check if the 'q' button is pressed to quit the program\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the video capture object and close all windows\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Perform real-time face recognition using the webcam\n",
        "realtime_face_recognition()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dbce521",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "\n",
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"yolov11m\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "# Load YOLO Model (pretrained)\n",
        "yolo_model = YOLO(\"yolo11m.pt\")  # YOLO Nano model (COCO pretrained)\n",
        "\n",
        "def process_frame(frame):\n",
        "    # Deteksi objek dengan YOLO\n",
        "    results = yolo_model(frame)\n",
        "\n",
        "    # Hasil anotasi pada frame\n",
        "    annotated_frame = results[0].plot()\n",
        "    objects = []\n",
        "\n",
        "    for result in results[0].boxes:\n",
        "        box = result.xyxy.tolist()[0]  # Ambil box pertama\n",
        "        label = result.cls[0]  # Ambil label pertama\n",
        "\n",
        "        # Jika objek adalah manusia, prediksi ekspresi dan umur\n",
        "        if int(label) == 0:  # Label 0 = \"person\" di YOLO COCO\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cropped_face = frame[y1:y2, x1:x2]\n",
        "            \n",
        "            try:\n",
        "                # Prediksi ekspresi dan umur menggunakan DeepFace\n",
        "                # analysis = DeepFace.find(cropped_face, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "                \n",
        "                # # Tambahkan teks ke frame\n",
        "                # cv2.putText(annotated_frame, \n",
        "                #             # f\"Age: {analysis[0].get('age')} Emotion: {analysis[0].get('dominant_emotion')}\", \n",
        "                #             (x1, y1-10), \n",
        "                #             cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                #             0.9, \n",
        "                #             (0, 255, 0), \n",
        "                #             2)\n",
        "                \n",
        "                # objects.append({\n",
        "                #     \"label\": \"person\",\n",
        "                #     # \"age\": analysis[0].get('age'),\n",
        "                #     # \"emotion\": analysis[0].get('dominant_emotion'),\n",
        "                #     \"coordinates\": box\n",
        "                # })\n",
        "                 # Perform face recognition on the captured frame\n",
        "                # Find faces and identify people using a specific model and distance metric\n",
        "                # people = DeepFace.find(img_path=frame, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "                people = DeepFace.find(img_path=frame, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "\n",
        "                for person in people:\n",
        "                    # Retrieve the coordinates of the face bounding box\n",
        "                    x = person['source_x'][0]\n",
        "                    y = person['source_y'][0]\n",
        "                    w = person['source_w'][0]\n",
        "                    h = person['source_h'][0]\n",
        "\n",
        "                    # Draw a rectangle around the face\n",
        "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "                    # Get the person's name and display it on the image\n",
        "                    name = person['identity'][0].split('/')[1]\n",
        "                    cv2.putText(frame, name, (x, y), cv2.FONT_ITALIC, 1, (0, 0, 255), 2)\n",
        "\n",
        "                # Display the resulting frame\n",
        "                cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
        "                # cv2.resizeWindow('frame', 450, 300)\n",
        "                cv2.imshow('frame', frame)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing face: {e}\")\n",
        "\n",
        "    return annotated_frame, objects\n",
        "\n",
        "def main():\n",
        "    # Inisialisasi kamera\n",
        "    cap = cv2.VideoCapture(\"/media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        # Baca frame dari kamera\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            print(\"Gagal membaca frame dari kamera\")\n",
        "            break\n",
        "\n",
        "        # Proses frame\n",
        "        annotated_frame, objects = process_frame(frame)\n",
        "\n",
        "        # Tampilkan frame yang sudah diproses\n",
        "        cv2.imshow(\"Real-Time Detection\", annotated_frame)\n",
        "\n",
        "        # Cetak informasi objek yang terdeteksi\n",
        "        if objects:\n",
        "            print(\"Objek Terdeteksi:\")\n",
        "            for obj in objects:\n",
        "                print(f\"- Person: Umur {obj['age']}, Emosi {obj['emotion']}\")\n",
        "\n",
        "        # Keluar jika tombol 'q' ditekan\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Tutup kamera dan jendela\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adfd49f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "YOLO11 + DeepFace Surveillance Example\n",
        "Single-file demo that uses Ultralytics YOLO11 for detection and DeepFace for face recognition.\n",
        "\n",
        "Requirements:\n",
        "  pip install ultralytics deepface opencv-python-headless imutils playsound numpy\n",
        "\n",
        "Notes:\n",
        " - Adjust MODEL_PATH and DATABASE_DIR to your environment.\n",
        " - This script assumes you have a folder `database/` with subfolders per person containing reference images.\n",
        " - YOLO11 model used here is `yolo11n.pt` by default; change to a different checkpoint if needed.\n",
        " - Ensure you comply with local laws and obtain consent before deploying facial recognition.\n",
        "\n",
        "Author: Generated by ChatGPT for user\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "except Exception as e:\n",
        "    raise ImportError(\"ultralytics is required. Install with `pip install ultralytics`\\noriginal error: %s\" % e)\n",
        "\n",
        "try:\n",
        "    from deepface import DeepFace\n",
        "except Exception as e:\n",
        "    raise ImportError(\"deepface is required. Install with `pip install deepface`\\noriginal error: %s\" % e)\n",
        "\n",
        "# ------------------------- CONFIG -------------------------\n",
        "MODEL_PATH = \"yolo11n.pt\"  # change to your YOLO11 checkpoint or path (e.g., \"yolo11s.pt\")\n",
        "DATABASE_DIR = \"database\"   # folder structure: database/person_name/img1.jpg, img2.jpg, ...\n",
        "VIDEO_SOURCE = 0            # 0 for webcam, or 'rtsp://...' or path to video file\n",
        "RECOG_BACKEND = \"facenet\"  # deepface backend: 'facenet','arcface','vggface','deepface', etc.\n",
        "REC_THRESHOLD = 0.4         # similarity threshold (lower=more strict for some backends)\n",
        "SKIP_FRAMES = 2             # process every SKIP_FRAMES-th frame for speed\n",
        "SHOW_WINDOW = True\n",
        "SAVE_LOG = True\n",
        "LOG_FILE = \"surveillance_log.csv\"\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# helper: prepare database embeddings using DeepFace\n",
        "def build_db_embeddings(db_dir: str, model_name: str = RECOG_BACKEND):\n",
        "    db = {}\n",
        "    if not os.path.isdir(db_dir):\n",
        "        print(f\"[WARN] Database directory '{db_dir}' not found. No reference faces loaded.\")\n",
        "        return db\n",
        "\n",
        "    print(\"[INFO] Building face embeddings from database...\")\n",
        "    for person in os.listdir(db_dir):\n",
        "        person_dir = os.path.join(db_dir, person)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        embeddings = []\n",
        "        for img_name in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_name)\n",
        "            try:\n",
        "                # DeepFace.represent returns an embedding vector\n",
        "                rep = DeepFace.represent(img_path, model_name=model_name, enforce_detection=True)\n",
        "                if isinstance(rep, list):\n",
        "                    rep = rep[0][\"embedding\"] if \"embedding\" in rep[0] else rep[0]\n",
        "                embeddings.append(np.array(rep))\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Could not process {img_path}: {e}\")\n",
        "        if embeddings:\n",
        "            db[person] = np.vstack(embeddings)\n",
        "            print(f\"[INFO] Loaded {db[person].shape[0]} images for '{person}'\")\n",
        "    return db\n",
        "\n",
        "# helper: match a face embedding to database\n",
        "def match_embedding(embedding: np.ndarray, db: dict, threshold: float = REC_THRESHOLD):\n",
        "    best_name = None\n",
        "    best_score = float(\"inf\")\n",
        "    for person, embs in db.items():\n",
        "        # compute cosine distance to each stored embedding and take min\n",
        "        # convert to 1 - cosine_similarity\n",
        "        # normalize embedding lengths\n",
        "        emb_norm = embedding / (np.linalg.norm(embedding) + 1e-10)\n",
        "        embs_norm = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-10)\n",
        "        cos_sim = np.dot(embs_norm, emb_norm)\n",
        "        # distance = 1 - similarity\n",
        "        dists = 1.0 - cos_sim\n",
        "        idx = np.argmin(dists)\n",
        "        if dists[idx] < best_score:\n",
        "            best_score = float(dists[idx])\n",
        "            best_name = person\n",
        "    if best_score <= threshold:\n",
        "        return best_name, best_score\n",
        "    return None, best_score\n",
        "\n",
        "# main surveillance loop\n",
        "def run_surveillance(\n",
        "    model_path=MODEL_PATH,\n",
        "    db_dir=DATABASE_DIR,\n",
        "    video_source=VIDEO_SOURCE,\n",
        "    backend=RECOG_BACKEND,\n",
        "    threshold=REC_THRESHOLD,\n",
        "    skip_frames=SKIP_FRAMES,\n",
        "    show_window=SHOW_WINDOW,\n",
        "    save_log=SAVE_LOG,\n",
        "    log_file=LOG_FILE,\n",
        "):\n",
        "    # load YOLO model\n",
        "    print(f\"[INFO] Loading YOLO model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # build database embeddings\n",
        "    db = build_db_embeddings(db_dir, model_name=backend)\n",
        "\n",
        "    # open video source\n",
        "    cap = cv2.VideoCapture(video_source)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Could not open video source {video_source}\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    if save_log:\n",
        "        with open(log_file, \"w\") as f:\n",
        "            f.write(\"timestamp,frame,object,x1,y1,x2,y2,name,score\\n\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"[INFO] End of stream or cannot fetch frame\")\n",
        "                break\n",
        "\n",
        "            frame_idx += 1\n",
        "            if frame_idx % skip_frames != 0:\n",
        "                continue\n",
        "\n",
        "            # run detection\n",
        "            results = model.predict(frame, imgsz=640, conf=0.4, iou=0.5)\n",
        "\n",
        "            # results can contain multiple images (batch); take first\n",
        "            r = results[0]\n",
        "\n",
        "            # iterate detections\n",
        "            for det in r.boxes:\n",
        "                cls = int(det.cls[0]) if hasattr(det, 'cls') else int(det.cls)\n",
        "                conf = float(det.conf[0]) if hasattr(det, 'conf') else float(det.conf)\n",
        "                x1, y1, x2, y2 = map(int, det.xyxy[0]) if hasattr(det, 'xyxy') else map(int, det.xyxy)\n",
        "\n",
        "                # NOTE: class mapping depends on the model's dataset\n",
        "                # Commonly COCO uses 0=person; YOLO11 may include 'face' class in some configurations.\n",
        "                # We'll treat class 0 as 'person' here; adjust if your model labels differ.\n",
        "                label = 'person' if cls == 0 else f'class_{cls}'\n",
        "\n",
        "                # crop ROI for face recognition: try to detect face inside person bbox\n",
        "                roi = frame[y1:y2, x1:x2]\n",
        "                if roi.size == 0:\n",
        "                    continue\n",
        "\n",
        "                # use DeepFace to detect & represent face(s) in ROI\n",
        "                try:\n",
        "                    # DeepFace.extract_faces returns a list of dicts with 'facial_area' and 'face'\n",
        "                    faces = DeepFace.extract_faces(img_path=roi, detector_backend='opencv', enforce_detection=False)\n",
        "                except Exception as e:\n",
        "                    # as a fallback, try enforce_detection True\n",
        "                    faces = []\n",
        "\n",
        "                if faces:\n",
        "                    for face_info in faces:\n",
        "                        facial_img = face_info.get('face')\n",
        "                        if facial_img is None:\n",
        "                            continue\n",
        "                        # get embedding\n",
        "                        try:\n",
        "                            rep = DeepFace.represent(img_path = facial_img, model_name = backend, enforce_detection = False)\n",
        "                            if isinstance(rep, list):\n",
        "                                rep = rep[0][\"embedding\"] if \"embedding\" in rep[0] else rep[0]\n",
        "                            emb = np.array(rep)\n",
        "                        except Exception as e:\n",
        "                            print(f\"[WARN] embedding error: {e}\")\n",
        "                            continue\n",
        "\n",
        "                        name, score = match_embedding(emb, db, threshold)\n",
        "                        # draw box & label\n",
        "                        if name:\n",
        "                            text = f\"{name} ({score:.3f})\"\n",
        "                        else:\n",
        "                            text = f\"Unknown ({score:.3f})\"\n",
        "\n",
        "                        # compute absolute coords of facial area relative to frame\n",
        "                        area = face_info.get('facial_area')\n",
        "                        if area:\n",
        "                            fx, fy, fw, fh = area['x'], area['y'], area['w'], area['h']\n",
        "                            # area is relative to the roi; convert to frame coords\n",
        "                            ax1 = x1 + int(fx)\n",
        "                            ay1 = y1 + int(fy)\n",
        "                            ax2 = ax1 + int(fw)\n",
        "                            ay2 = ay1 + int(fh)\n",
        "                            cv2.rectangle(frame, (ax1, ay1), (ax2, ay2), (0,255,0), 2)\n",
        "                            cv2.putText(frame, text, (ax1, ay1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "\n",
        "                        # log\n",
        "                        if save_log:\n",
        "                            ts = time.time()\n",
        "                            with open(log_file, 'a') as f:\n",
        "                                f.write(f\"{ts},{frame_idx},{label},{x1},{y1},{x2},{y2},{name},{score}\\n\")\n",
        "\n",
        "                else:\n",
        "                    # no faces found inside this detection; optionally run full-frame face detector\n",
        "                    pass\n",
        "\n",
        "            # show\n",
        "            if show_window:\n",
        "                cv2.imshow('surveillance', frame)\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('[INFO] Interrupted by user')\n",
        "    finally:\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(f\"[INFO] Done. Processed {frame_idx} frames in {time.time()-start_time:.2f}s\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', default=MODEL_PATH)\n",
        "    parser.add_argument('--db', default=DATABASE_DIR)\n",
        "    parser.add_argument('--source', default=VIDEO_SOURCE)\n",
        "    parser.add_argument('--backend', default=RECOG_BACKEND)\n",
        "    parser.add_argument('--threshold', type=float, default=REC_THRESHOLD)\n",
        "    parser.add_argument('--skip', type=int, default=SKIP_FRAMES)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    run_surveillance(model_path=args.model, db_dir=args.db, video_source=args.source, backend=args.backend, threshold=args.threshold, skip_frames=args.skip)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5404b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.engine.results import Results  \n",
        "from deepface import DeepFace\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "totalKnownFaces=0\n",
        "totalUnknownFaces=0\n",
        "knownNames =[]\n",
        "\n",
        "def faceRecognition(input_image):\n",
        "\n",
        "    global totalKnownFaces\n",
        "    global totalUnknownFaces\n",
        "\n",
        "\n",
        "    # Path to the directory containing cropped objects\n",
        "    cropped_objects_dir = \"./faces/\"\n",
        "    \n",
        "    # Path to the directory to save unknown faces\n",
        "    unknown_faces_dir = \"./unknown/\"\n",
        "    \n",
        "    # Path to the directory to save known faces\n",
        "    known_faces_dir = \"./known/\"\n",
        "    \n",
        "    # Initialize a list to store the extracted names\n",
        "    extracted_names = []\n",
        "    \n",
        "    # Check if the 'unknown' folder exists, otherwise create it\n",
        "    if not os.path.exists(unknown_faces_dir):\n",
        "        os.makedirs(unknown_faces_dir)\n",
        "    else:\n",
        "        # If the 'unknown' folder exists, clear all files and subfolders\n",
        "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
        "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
        "            if os.path.isfile(file_or_folder_path):\n",
        "                os.remove(file_or_folder_path)\n",
        "            elif os.path.isdir(file_or_folder_path):\n",
        "                shutil.rmtree(file_or_folder_path)\n",
        "\n",
        "    # Check if the 'known' folder exists, otherwise create it\n",
        "    if not os.path.exists(known_faces_dir):\n",
        "        os.makedirs(known_faces_dir)\n",
        "    else:\n",
        "        # If the 'known' folder exists, clear all files and subfolders\n",
        "        for file_or_folder in os.listdir(known_faces_dir):\n",
        "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
        "            if os.path.isfile(file_or_folder_path):\n",
        "                os.remove(file_or_folder_path)\n",
        "            elif os.path.isdir(file_or_folder_path):\n",
        "                shutil.rmtree(file_or_folder_path)\n",
        "    \n",
        "    # Iterate through the image files in the directory\n",
        "    for filename in os.listdir(cropped_objects_dir):\n",
        "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            img_path = os.path.join(cropped_objects_dir, filename)\n",
        "            model = DeepFace.find(img_path=img_path, db_path=\"family_members\", enforce_detection=False, model_name=\"Facenet512\")\n",
        "\n",
        "            # print(\"Model length:\", len(model))\n",
        "            # print(\"Model:\", model)\n",
        "\n",
        "\n",
        "            # Check if a face was recognized in the image\n",
        "            if model and len(model[0]['identity']) > 0:\n",
        "                # Extract the name and append it to the list\n",
        "                name = model[0]['identity'][0].split('/')[1]\n",
        "\n",
        "                # name = model[0]['identity'][0].split('/')[0]\n",
        "   \n",
        "\n",
        "                print(\"Name:\", name)\n",
        "\n",
        "                # Save the known face into the 'known' folder\n",
        "                known_faces_path = os.path.join(known_faces_dir, f\"{name}.jpg\")\n",
        "                totalKnownFaces+=1\n",
        "                knownNames.append(name)\n",
        "                shutil.copy(img_path, known_faces_path)\n",
        "                \n",
        "            else:\n",
        "                # If no face is recognized, set name to 'unknown'\n",
        "                name = 'unknown'\n",
        "                print(\"No face detected in:\", img_path)\n",
        "                # Save the unknown face into the 'unknown' folder\n",
        "                unknown_faces_path = os.path.join(unknown_faces_dir, f\"{totalUnknownFaces}.jpg\")\n",
        "                totalUnknownFaces+=1\n",
        "                shutil.copy(img_path, unknown_faces_path)\n",
        "                \n",
        "            extracted_names.append(name)\n",
        "            \n",
        "    return extracted_names\n",
        "\n",
        "def getKnownName():\n",
        "    return knownNames\n",
        "\n",
        "def setKnownName():\n",
        "    global knownNames\n",
        "    knownNames=[]\n",
        "\n",
        "def setFacesToZero():\n",
        "    global totalKnownFaces\n",
        "    global totalUnknownFaces\n",
        "    totalKnownFaces=0\n",
        "    totalUnknownFaces=0\n",
        "\n",
        "def getKnownFaces():\n",
        "    return totalKnownFaces\n",
        "\n",
        "def getUnknownFaces():\n",
        "    return totalUnknownFaces\n",
        "\n",
        "def faceExtraction(input_image, model, results):\n",
        "    # Load the image\n",
        "    image = Image.open(input_image)\n",
        "    detected_objects = []\n",
        "\n",
        "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
        "        for box in results.boxes.xyxy:\n",
        "            object_id = int(box[-1])\n",
        "            object_name = results.names.get(object_id)\n",
        "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
        "\n",
        "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
        "\n",
        "    # Create or clear the 'faces' directory\n",
        "    if os.path.exists(\"./faces\"):\n",
        "        shutil.rmtree(\"./faces\")\n",
        "    os.makedirs(\"./faces\")\n",
        "\n",
        "    totalFaces=0\n",
        "    # Crop and save each detected object\n",
        "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
        "        object_image = image.crop((x1, y1, x2, y2))\n",
        "        object_image.save(f\"./faces/face{i}.jpg\")\n",
        "        totalFaces+=1\n",
        "        \n",
        "    return totalFaces\n",
        "\n",
        "\n",
        "\n",
        "def faceDetection(uploaded_file):\n",
        "    img = Image.open(uploaded_file)\n",
        "    temp_image_path = \"./temp_image.jpg\"  # Temporary path to store the converted image\n",
        "    img.save(temp_image_path, format=\"JPEG\")\n",
        "\n",
        "    # Use the Ultralytics model\n",
        "    model = YOLO('best.pt')\n",
        "    results: Results = model.predict(temp_image_path)[0]\n",
        "\n",
        "    total_faces = faceExtraction(temp_image_path, model, results)\n",
        "    \n",
        "    # Remove the temporary image file\n",
        "    os.remove(temp_image_path)\n",
        "\n",
        "    return total_faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed87a093",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"yolov11m\", \"yolov11m\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "# Load YOLO Model (pretrained)\n",
        "yolo_model = YOLO(\"yolo11m.pt\")  # YOLO Nano model (COCO pretrained)\n",
        "\n",
        "def process_frame(frame):\n",
        "    # Deteksi objek dengan YOLO\n",
        "    results = yolo_model(frame)\n",
        "\n",
        "    # Hasil anotasi pada frame\n",
        "    annotated_frame = results[0].plot()\n",
        "    objects = []\n",
        "\n",
        "    for result in results[0].boxes:\n",
        "        box = result.xyxy.tolist()[0]  # Ambil box pertama\n",
        "        label = result.cls[0]  # Ambil label pertama\n",
        "\n",
        "        # Jika objek adalah manusia, prediksi ekspresi dan umur\n",
        "        if int(label) == 0:  # Label 0 = \"person\" di YOLO COCO\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cropped_face = frame[y1:y2, x1:x2]\n",
        "            \n",
        "            try:\n",
        "                # Prediksi ekspresi dan umur menggunakan DeepFace\n",
        "                analysis = DeepFace.find(cropped_face, db_path=\"family_members/\", actions=['identify', 'emotion', 'age'], enforce_detection=False)\n",
        "                \n",
        "                # Tambahkan teks ke frame\n",
        "                cv2.putText(annotated_frame, \n",
        "                            f\"Age: {analysis[0].get('age')} Emotion: {analysis[0].get('dominant_emotion')}\", \n",
        "                            (x1, y1-10), \n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                            0.9, \n",
        "                            (0, 255, 0), \n",
        "                            2)\n",
        "                \n",
        "                objects.append({\n",
        "                    \"label\": \"person\",\n",
        "                    \"age\": analysis[0].get('age'),\n",
        "                    \"emotion\": analysis[0].get('dominant_emotion'),\n",
        "                    \"coordinates\": box\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing face: {e}\")\n",
        "\n",
        "    return annotated_frame, objects\n",
        "\n",
        "def main():\n",
        "    # Inisialisasi kamera\n",
        "    cap = cv2.VideoCapture(\"./media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        # Baca frame dari kamera\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        if not ret:\n",
        "            print(\"Gagal membaca frame dari kamera\")\n",
        "            break\n",
        "\n",
        "        # Proses frame\n",
        "        annotated_frame, objects = process_frame(frame)\n",
        "\n",
        "        # Tampilkan frame yang sudah diproses\n",
        "        cv2.imshow(\"Real-Time Detection\", annotated_frame)\n",
        "\n",
        "        # Cetak informasi objek yang terdeteksi\n",
        "        if objects:\n",
        "            print(\"Objek Terdeteksi:\")\n",
        "            for obj in objects:\n",
        "                print(f\"- Person: Umur {obj['age']}, Emosi {obj['emotion']}\")\n",
        "\n",
        "        # Keluar jika tombol 'q' ditekan\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Tutup kamera dan jendela\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28b0935",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "# import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "# Load your YOLO11 model. For face detection, you can:\n",
        "# - Use a pre-trained YOLO11 model and filter for 'person' class, then use a face detector.\n",
        "# - Ideally, train a custom YOLO11 model on a face dataset for best results.\n",
        "model = YOLO(\"yolo11m.pt\")  # Or your custom face-detection model\n",
        "\n",
        "# Start video capture (from a file or webcam)\n",
        "cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")  # 0 for default webcam, or replace with file path\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Stage 1: Run Face Detection with YOLO11\n",
        "    results = model(frame, conf=0.5)  # Adjust confidence as needed\n",
        "    \n",
        "    for r in results:\n",
        "        boxes = r.boxes\n",
        "        for box in boxes:\n",
        "            # Get bounding box coordinates\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            \n",
        "            # Optional: Filter for a specific class (e.g., 'person') if using a general detector\n",
        "            # if model.names[cls] == 'person':\n",
        "            \n",
        "            # Crop the detected face from the frame\n",
        "            cropped_face = frame[y1:y2, x1:x2]\n",
        "            \n",
        "            # Check if the cropped area is valid\n",
        "            if cropped_face.size == 0:\n",
        "                continue\n",
        "            \n",
        "            # Stage 2: Run Face Recognition with DeepFace\n",
        "            try:\n",
        "                # Use DeepFace to analyze the cropped face.\n",
        "                # The 'actions' parameter can include ['verify', 'emotion', 'age', 'gender'] etc.\n",
        "                # analysis = DeepFace.verify(cropped_face, actions=['emotion'], enforce_detection=False)\n",
        "                analysis = DeepFace.find(img_path=frame, db_path=\"family_members/\", model_name=models[1], distance_metric=metrics[1], enforce_detection=False)\n",
        "                # If using verification against a database:\n",
        "                # result = DeepFace.verify(cropped_face, \"path_to_reference_image.jpg\")\n",
        "                \n",
        "                # Extract the dominant emotion (or other analysis results)\n",
        "                dominant_emotion = analysis[0]['dominant_emotion']\n",
        "                identity = \"Unknown\"  # Placeholder. Replace with DeepFace.verify() logic.\n",
        "                \n",
        "                # Draw the bounding box and label\n",
        "                label = f\"{identity} - {dominant_emotion}\"\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                \n",
        "            except Exception as e:\n",
        "                # Handle cases where DeepFace analysis fails\n",
        "                print(f\"DeepFace analysis error: {e}\")\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Facial Recognition Surveillance', frame)\n",
        "    \n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76979b7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "import smtplib\n",
        "from email.mime.text import MIMEText\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    # no-op references to pacify linters about \"is not accessed\"\n",
        "    from pathlib import Path as _Path  # noqa: F401\n",
        "    import smtplib as _smtplib  # noqa: F401\n",
        "    from email.mime.text import MIMEText as _MIMEText  # noqa: F401\n",
        "    import matplotlib.pyplot as _plt  # noqa: F401\n",
        "    import numpy as _np  # noqa: F401\n",
        "    _ = (_Path, _smtplib, _MIMEText, _plt, _np)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# List of available backends, models, and distance metrics\n",
        "backends = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\"]\n",
        "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\"]\n",
        "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "except Exception as e:\n",
        "    raise ImportError(\"ultralytics is required. Install with `pip install ultralytics`\\noriginal error: %s\" % e)\n",
        "\n",
        "try:\n",
        "    from deepface import DeepFace\n",
        "except Exception as e:\n",
        "    raise ImportError(\"deepface is required. Install with `pip install deepface`\\noriginal error: %s\" % e)\n",
        "\n",
        "# ------------------------- CONFIG -------------------------\n",
        "MODEL_PATH = \"yolo11m.pt\"  # change to your YOLO11 checkpoint or path (e.g., \"yolo11s.pt\")\n",
        "DATABASE_DIR = \"family_members/\"   # folder structure: database/person_name/img1.jpg, img2.jpg, ...\n",
        "VIDEO_SOURCE = \"media_files/WIN_20251103_14_11_20_Pro.mp4\"            # 0 for webcam, or 'rtsp://...' or path to video file\n",
        "RECOG_BACKEND = \"Facenet\"  # deepface backend: 'facenet','arcface','vggface','deepface', etc.\n",
        "REC_THRESHOLD = 0.25         # similarity threshold (lower=more strict for some backends)\n",
        "SKIP_FRAMES = 2             # process every SKIP_FRAMES-th frame for speed\n",
        "SHOW_WINDOW = True\n",
        "SAVE_LOG = True\n",
        "LOG_FILE = \"surveillance_log.csv\"\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# helper: prepare database embeddings using DeepFace\n",
        "def build_db_embeddings(db_dir: str, model_name: str = RECOG_BACKEND):\n",
        "    db = {}\n",
        "    if not os.path.isdir(db_dir):\n",
        "        print(f\"[WARN] Database directory '{db_dir}' not found. No reference faces loaded.\")\n",
        "        return db\n",
        "\n",
        "    print(\"[INFO] Building face embeddings from database...\")\n",
        "    for person in os.listdir(db_dir):\n",
        "        person_dir = os.path.join(db_dir, person)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        embeddings = []\n",
        "        for img_name in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_name)\n",
        "            try:\n",
        "                # DeepFace.represent returns an embedding vector\n",
        "                rep = DeepFace.represent(img_path, model_name=model_name, enforce_detection=True)\n",
        "                if isinstance(rep, list):\n",
        "                    rep = rep[0][\"embedding\"] if \"embedding\" in rep[0] else rep[0]\n",
        "                embeddings.append(np.array(rep))\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Could not process {img_path}: {e}\")\n",
        "        if embeddings:\n",
        "            db[person] = np.vstack(embeddings)\n",
        "            print(f\"[INFO] Loaded {db[person].shape[0]} images for '{person}'\")\n",
        "    return db\n",
        "\n",
        "# helper: match a face embedding to database\n",
        "def match_embedding(embedding: np.ndarray, db: dict, threshold: float = REC_THRESHOLD):\n",
        "    best_name = None\n",
        "    best_score = float(\"inf\")\n",
        "    for person, embs in db.items():\n",
        "        # compute cosine distance to each stored embedding and take min\n",
        "        # convert to 1 - cosine_similarity\n",
        "        # normalize embedding lengths\n",
        "        emb_norm = embedding / (np.linalg.norm(embedding) + 1e-10)\n",
        "        embs_norm = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-10)\n",
        "        cos_sim = np.dot(embs_norm, emb_norm)\n",
        "        # distance = 1 - similarity\n",
        "        dists = 1.0 - cos_sim\n",
        "        idx = np.argmin(dists)\n",
        "        if dists[idx] < best_score:\n",
        "            best_score = float(dists[idx])\n",
        "            best_name = person\n",
        "    if best_score <= threshold:\n",
        "        return best_name, best_score\n",
        "    return None, best_score\n",
        "\n",
        "# main surveillance loop\n",
        "def run_surveillance(\n",
        "    model_path=MODEL_PATH,\n",
        "    db_dir=DATABASE_DIR,\n",
        "    video_source=VIDEO_SOURCE,\n",
        "    backend=RECOG_BACKEND,\n",
        "    threshold=REC_THRESHOLD,\n",
        "    skip_frames=SKIP_FRAMES,\n",
        "    show_window=SHOW_WINDOW,\n",
        "    save_log=SAVE_LOG,\n",
        "    log_file=LOG_FILE,\n",
        "):\n",
        "    # load YOLO model\n",
        "    print(f\"[INFO] Loading YOLO model: {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # build database embeddings\n",
        "    db = build_db_embeddings(db_dir, model_name=backend)\n",
        "\n",
        "    # open video source\n",
        "    cap = cv2.VideoCapture(video_source)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Could not open video source {video_source}\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    if save_log:\n",
        "        with open(log_file, \"w\") as f:\n",
        "            f.write(\"timestamp,frame,object,x1,y1,x2,y2,name,score\\n\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"[INFO] End of stream or cannot fetch frame\")\n",
        "                break\n",
        "\n",
        "            frame_idx += 1\n",
        "            if frame_idx % skip_frames != 0:\n",
        "                continue\n",
        "\n",
        "            # run detection\n",
        "            results = model.predict(frame, imgsz=640, conf=0.25, iou=0.5)\n",
        "\n",
        "            # results can contain multiple images (batch); take first\n",
        "            r = results[0]\n",
        "\n",
        "            # iterate detections\n",
        "            for det in r.boxes:\n",
        "                cls = int(det.cls[0]) if hasattr(det, 'cls') else int(det.cls)\n",
        "                conf = float(det.conf[0]) if hasattr(det, 'conf') else float(det.conf)\n",
        "                x1, y1, x2, y2 = map(int, det.xyxy[0]) if hasattr(det, 'xyxy') else map(int, det.xyxy)\n",
        "\n",
        "                # NOTE: class mapping depends on the model's dataset\n",
        "                # Commonly COCO uses 0=person; YOLO11 may include 'face' class in some configurations.\n",
        "                # We'll treat class 0 as 'person' here; adjust if your model labels differ.\n",
        "                label = 'person' if cls == 0 else f'class_{cls}'\n",
        "\n",
        "                # crop ROI for face recognition: try to detect face inside person bbox\n",
        "                roi = frame[y1:y2, x1:x2]\n",
        "                if roi.size == 0:\n",
        "                    continue\n",
        "\n",
        "                # use DeepFace to detect & represent face(s) in ROI\n",
        "                try:\n",
        "                    # DeepFace.extract_faces returns a list of dicts with 'facial_area' and 'face'\n",
        "                    faces = DeepFace.extract_faces(img_path=roi, detector_backend='opencv', enforce_detection=False)\n",
        "                except Exception as e:\n",
        "                    # as a fallback, try enforce_detection True\n",
        "                    faces = []\n",
        "\n",
        "                if faces:\n",
        "                    for face_info in faces:\n",
        "                        facial_img = face_info.get('face')\n",
        "                        if facial_img is None:\n",
        "                            continue\n",
        "                        # get embedding\n",
        "                        try:\n",
        "                            rep = DeepFace.represent(img_path=facial_img, model_name=backend, enforce_detection=False)\n",
        "                            if isinstance(rep, list):\n",
        "                                rep = rep[0][\"embedding\"] if \"embedding\" in rep[0] else rep[0]\n",
        "                            emb = np.array(rep)\n",
        "                        except Exception as e:\n",
        "                            print(f\"[WARN] embedding error: {e}\")\n",
        "                            continue\n",
        "\n",
        "                        name, score = match_embedding(emb, db, threshold)\n",
        "                        # draw box & label\n",
        "                        if name:\n",
        "                            text = f\"{name} ({score:.3f})\"\n",
        "                        else:\n",
        "                            text = f\"Unknown ({score:.3f})\"\n",
        "\n",
        "                        # compute absolute coords of facial area relative to frame\n",
        "                        area = face_info.get('facial_area')\n",
        "                        if area:\n",
        "                            fx, fy, fw, fh = area['x'], area['y'], area['w'], area['h']\n",
        "                            # area is relative to the roi; convert to frame coords\n",
        "                            ax1 = x1 + int(fx)\n",
        "                            ay1 = y1 + int(fy)\n",
        "                            ax2 = ax1 + int(fw)\n",
        "                            ay2 = ay1 + int(fh)\n",
        "                            cv2.rectangle(frame, (ax1, ay1), (ax2, ay2), (0,255,0), 2)\n",
        "                            cv2.putText(frame, text, (ax1, ay1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "\n",
        "                        # log\n",
        "                        if save_log:\n",
        "                            ts = time.time()\n",
        "                            with open(log_file, 'a') as f:\n",
        "                                f.write(f\"{ts},{frame_idx},{label},{x1},{y1},{x2},{y2},{name},{score}\\n\")\n",
        "\n",
        "                else:\n",
        "                    # no faces found inside this detection; optionally run full-frame face detector\n",
        "                    pass\n",
        "\n",
        "            # show\n",
        "            if show_window:\n",
        "                cv2.imshow('surveillance', frame)\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print('[INFO] Interrupted by user')\n",
        "    finally:\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(f\"[INFO] Done. Processed {frame_idx} frames in {time.time()-start_time:.2f}s\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--model', default=MODEL_PATH)\n",
        "    parser.add_argument('--db', default=DATABASE_DIR)\n",
        "    parser.add_argument('--source', default=VIDEO_SOURCE, help=\"0 (int) for webcam, or path/rtsp string\")\n",
        "    parser.add_argument('--backend', default=RECOG_BACKEND)\n",
        "    parser.add_argument('--threshold', type=float, default=REC_THRESHOLD)\n",
        "    parser.add_argument('--skip', type=int, default=SKIP_FRAMES)\n",
        "\n",
        "    # Use parse_known_args so Jupyter/ipykernel extra args (like --f=...) are ignored\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    if unknown:\n",
        "        # optional: log or print unknown args when running standalone\n",
        "        try:\n",
        "            print(f\"[WARN] Ignored unknown args: {unknown}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # sanitize source: if it's a string that can be an int (e.g., '0'), convert to int for webcam\n",
        "    video_source = args.source\n",
        "    try:\n",
        "        # when VIDEO_SOURCE default is int, argparse may produce string; try to coerce\n",
        "        if isinstance(video_source, str):\n",
        "            # allow numeric strings (including negative/0) to be used as ints\n",
        "            if video_source.isdigit() or (video_source.startswith('-') and video_source[1:].isdigit()):\n",
        "                video_source = int(video_source)\n",
        "            else:\n",
        "                # allow \"0\" with whitespace etc.\n",
        "                try:\n",
        "                    video_source = int(float(video_source))\n",
        "                except Exception:\n",
        "                    pass\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    run_surveillance(\n",
        "        model_path=args.model,\n",
        "        db_dir=args.db,\n",
        "        video_source=video_source,\n",
        "        backend=args.backend,\n",
        "        threshold=args.threshold,\n",
        "        skip_frames=args.skip,\n",
        "    )\n",
        "\n",
        "    run_surveillance(model_path=args.model, db_dir=args.db, video_source=args.source, backend=args.backend, threshold=args.threshold, skip_frames=args.skip)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf4390c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Smart Security System with YOLO11, Face Recognition, and Pose Detection\n",
        "Author: Your Name\n",
        "Version: 1.0\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import mediapipe as mp\n",
        "from ultralytics import YOLO\n",
        "import smtplib\n",
        "import pygame\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('security_system.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class SecurityConfig:\n",
        "    \"\"\"Configuration class for security system settings.\"\"\"\n",
        "    known_faces_dir: str = \"family_members/\"\n",
        "    alarm_sound_path: str = \"pols-aagyi-pols.mp3\"\n",
        "    alarm_cooldown: int = 3\n",
        "    confidence_threshold: float = 0.5\n",
        "    face_recognition_tolerance: float = 0.6\n",
        "    pose_visibility_threshold: float = 0.5\n",
        "    # camera_index: int = 0\n",
        "    camera_index: str = \"media_files/animal_surveillance/goru-churi.mp4\"\n",
        "    email_enabled: bool = False\n",
        "    smtp_server: str = \"smtp.gmail.com\"\n",
        "    smtp_port: int = 587\n",
        "    sender_email: str = \"\"\n",
        "    sender_password: str = \"\"\n",
        "    recipient_email: str = \"\"\n",
        "\n",
        "class SecuritySystem:\n",
        "    \"\"\"Main security system class.\"\"\"\n",
        "    \n",
        "    def __init__(self, config: SecurityConfig):\n",
        "        self.config = config\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "        self.last_alarm_time = 0\n",
        "        self.detection_history = {}\n",
        "        self.frame_count = 0\n",
        "        self.sound_loaded = False\n",
        "        \n",
        "        # Initialize components\n",
        "        self._initialize_models()\n",
        "        self._load_known_faces()\n",
        "        self._setup_audio()\n",
        "        self._setup_camera()\n",
        "        \n",
        "    def _initialize_models(self):\n",
        "        \"\"\"Initialize YOLO and MediaPipe models.\"\"\"\n",
        "        try:\n",
        "            self.model = YOLO(\"yolo11n.pt\")\n",
        "            logger.info(\"YOLO model loaded successfully\")\n",
        "            \n",
        "            self.mp_pose = mp.solutions.pose\n",
        "            self.pose = self.mp_pose.Pose(\n",
        "                static_image_mode=False,\n",
        "                model_complexity=1,\n",
        "                enable_segmentation=False,\n",
        "                min_detection_confidence=self.config.confidence_threshold\n",
        "            )\n",
        "            self.mp_drawing = mp.solutions.drawing_utils\n",
        "            logger.info(\"MediaPipe pose model loaded successfully\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize models: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def _load_known_faces(self):\n",
        "        \"\"\"Load known faces from directory.\"\"\"\n",
        "        known_faces_path = Path(self.config.known_faces_dir)\n",
        "        \n",
        "        if not known_faces_path.exists():\n",
        "            logger.warning(f\"Known faces directory '{known_faces_path}' does not exist\")\n",
        "            return\n",
        "        \n",
        "        supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
        "        \n",
        "        for image_path in known_faces_path.glob('*'):\n",
        "            if image_path.suffix.lower() in supported_formats:\n",
        "                try:\n",
        "                    image = face_recognition.load_image_file(str(image_path))\n",
        "                    face_encodings = face_recognition.face_encodings(image)\n",
        "                    \n",
        "                    if face_encodings:\n",
        "                        self.known_face_encodings.append(face_encodings[0])\n",
        "                        name = image_path.stem\n",
        "                        self.known_face_names.append(name)\n",
        "                        logger.info(f\"Loaded known face: {name}\")\n",
        "                    else:\n",
        "                        logger.warning(f\"No face found in {image_path}\")\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error loading face from {image_path}: {e}\")\n",
        "        \n",
        "        logger.info(f\"Loaded {len(self.known_face_encodings)} known faces\")\n",
        "    \n",
        "    def _setup_audio(self):\n",
        "        \"\"\"Setup audio system for alarms.\"\"\"\n",
        "        try:\n",
        "            pygame.mixer.init()\n",
        "            if Path(self.config.alarm_sound_path).exists():\n",
        "                pygame.mixer.music.load(self.config.alarm_sound_path)\n",
        "                self.sound_loaded = True\n",
        "                logger.info(\"Alarm sound loaded successfully\")\n",
        "            else:\n",
        "                logger.warning(f\"Alarm sound file not found: {self.config.alarm_sound_path}\")\n",
        "        except pygame.error as e:\n",
        "            logger.warning(f\"Could not load sound file: {e}\")\n",
        "    \n",
        "    def _setup_camera(self):\n",
        "        \"\"\"Setup camera capture.\"\"\"\n",
        "        self.cap = cv2.VideoCapture(self.config.camera_index)\n",
        "        if not self.cap.isOpened():\n",
        "            logger.error(\"Could not open camera\")\n",
        "            raise RuntimeError(\"Camera initialization failed\")\n",
        "        \n",
        "        # Set camera properties for better performance\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
        "        \n",
        "        logger.info(\"Camera initialized successfully\")\n",
        "    \n",
        "    def send_email_alert(self, alert_type: str = \"THREAT\", person_id: str = \"Unknown\") -> bool:\n",
        "        \"\"\"Send email alert with proper error handling.\"\"\"\n",
        "        if not self.config.email_enabled:\n",
        "            logger.info(\"Email alerts disabled\")\n",
        "            return False\n",
        "        \n",
        "        if not all([self.config.sender_email, self.config.sender_password, self.config.recipient_email]):\n",
        "            logger.error(\"Email configuration incomplete\")\n",
        "            return False\n",
        "        \n",
        "        try:\n",
        "            msg = MIMEMultipart()\n",
        "            msg['From'] = self.config.sender_email\n",
        "            msg['To'] = self.config.recipient_email\n",
        "            msg['Subject'] = f\"Security Alert: {alert_type}\"\n",
        "            \n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            body = f\"\"\"\n",
        "            Security Alert Details:\n",
        "            - Alert Type: {alert_type}\n",
        "            - Person: {person_id}\n",
        "            - Time: {timestamp}\n",
        "            - Location: Main Security Camera\n",
        "            \n",
        "            Please review the situation immediately.\n",
        "            \"\"\"\n",
        "            msg.attach(MIMEText(body, 'plain'))\n",
        "            \n",
        "            with smtplib.SMTP(self.config.smtp_server, self.config.smtp_port) as server:\n",
        "                server.starttls()\n",
        "                server.login(self.config.sender_email, self.config.sender_password)\n",
        "                server.sendmail(self.config.sender_email, self.config.recipient_email, msg.as_string())\n",
        "            \n",
        "            logger.info(f\"Email alert sent: {alert_type} - {person_id}\")\n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to send email: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def play_alarm(self) -> bool:\n",
        "        \"\"\"Play alarm sound with cooldown.\"\"\"\n",
        "        current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
        "        \n",
        "        if self.sound_loaded and (current_time - self.last_alarm_time) > self.config.alarm_cooldown:\n",
        "            try:\n",
        "                pygame.mixer.music.play()\n",
        "                self.last_alarm_time = current_time\n",
        "                logger.info(\"Alarm sound played\")\n",
        "                return True\n",
        "            except pygame.error as e:\n",
        "                logger.error(f\"Failed to play alarm: {e}\")\n",
        "        \n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cfg = SecurityConfig()\n",
        "    system = SecuritySystem(cfg)\n",
        "    system.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf330891",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python security_system.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983d46ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import solutions\n",
        "\n",
        "\n",
        "def count_specific_classes(video_path, output_video_path, model_path, classes_to_count):\n",
        "    \"\"\"Count specific classes of objects in a video.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    assert cap.isOpened(), \"Error reading video file\"\n",
        "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "    line_points = [(20, 400), (1080, 400)]\n",
        "    counter = solutions.ObjectCounter(show=True, region=line_points, model=model_path, classes=classes_to_count)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, im0 = cap.read()\n",
        "        if not success:\n",
        "            print(\"Video frame is empty or processing is complete.\")\n",
        "            break\n",
        "        results = counter(im0)\n",
        "        video_writer.write(results.plot_im)\n",
        "\n",
        "    cap.release()\n",
        "    video_writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "count_specific_classes(\"./media_files/animal_surveillance/goru-churi.mp4\", \"output_specific_classes.avi\", \"yolo11n.pt\", [0, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18722a49",
      "metadata": {},
      "source": [
        "# AI Security alarms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c533e540",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import solutions\n",
        "\n",
        "cap = cv2.VideoCapture(\"./media_files/animal_surveillance/goru-churi.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Video writer\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "from_email = \"abc@gmail.com\"  # the sender email address\n",
        "password = \"---- ---- ---- ----\"  # 16-digits password generated via: https://myaccount.google.com/apppasswords\n",
        "to_email = \"xyz@gmail.com\"  # the receiver email address\n",
        "\n",
        "# Initialize security alarm object\n",
        "securityalarm = solutions.SecurityAlarm(\n",
        "    show=True,  # display the output\n",
        "    model=\"yolo11m.pt\",  # i.e. yolo11s.pt, yolo11m.pt\n",
        "    records=3,  # total detections count to send an email\n",
        "    conf=0.25\n",
        ")\n",
        "\n",
        "# securityalarm.authenticate(from_email, password, to_email)  # authenticate the email server\n",
        "\n",
        "\n",
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    results = securityalarm(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    video_writer.write(results.plot_im)  # write the processed frame.\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()  # destroy all opened windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33114c59",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import solutions\n",
        "import pygame\n",
        "\n",
        "\n",
        "# Setup alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
        "\n",
        "cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Video writer\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "from_email = \"deveansari@gmail.com\"  # the sender email address\n",
        "password = \"ddgl yjef dlaw tuzg\"  # 16-digits password generated via: https://myaccount.google.com/apppasswords\n",
        "# to_email = \"rahat.ansari@live.com\"  # the receiver email address\n",
        "to_email = \"rahatansari.tpu@gmail.com\"  # the receiver email address\n",
        "\n",
        "# Initialize security alarm object\n",
        "securityalarm = solutions.SecurityAlarm(\n",
        "    show=True,  # display the output\n",
        "    model=\"yolo11m.pt\",  # i.e. yolo11s.pt, yolo11m.pt\n",
        "    records=1,  # total detections count to send an email\n",
        "    classes=[0, 2],  # 0=person, 2=car (as proxy for cattle)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# alarm = solutions.SecurityAlarm()\n",
        "securityalarm.authenticate(from_email, password, to_email)  # authenticate the email server\n",
        "\n",
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    results = securityalarm(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    video_writer.write(results.plot_im)  # write the processed frame.\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()  # destroy all opened windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6df550c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import solutions\n",
        "import pygame\n",
        "\n",
        "# Initialize alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: Alarm file '{alarm_file}' not found ‚Äî please check the path.\")\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "assert cap.isOpened(), \"‚ùå Error: Cannot read video file.\"\n",
        "\n",
        "# Video writer setup\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Security Alarm setup\n",
        "securityalarm = solutions.SecurityAlarm(\n",
        "    show=True,             # Show annotated video\n",
        "    model=\"yolo11m.pt\",    # Use YOLOv11 medium model\n",
        "    records=3,             # Number of detections to trigger event\n",
        "    classes=[0, 19]        # 0=person, 19=cow\n",
        ")\n",
        "\n",
        "# Optional: Email setup (you can disable if not needed)\n",
        "from_email = \"deveansari@gmail.com\"\n",
        "password = \"ddgl yjef dlaw tuzg\"  # App password\n",
        "to_email = \"rahatansari.tpu@gmail.com\"\n",
        "\n",
        "securityalarm.authenticate(from_email, password, to_email)\n",
        "\n",
        "# --- PROCESS VIDEO ---\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"‚úÖ Video processing completed.\")\n",
        "        break\n",
        "\n",
        "    # Run YOLO detection\n",
        "    results = securityalarm(im0)\n",
        "    print(results)  # Log results\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9188615d",
      "metadata": {},
      "source": [
        "# AI Security\n",
        "## Introduction\n",
        "In this section, we will explore the various aspects of AI security, including potential threats, vulnerabilities, and best practices for securing AI systems.\n",
        "\n",
        "## Threat Landscape\n",
        "1. **Data Poisoning**: Attackers manipulate training data to compromise model integrity.\n",
        "2. **Model Inversion**: Unauthorized access to model parameters can reveal sensitive information.\n",
        "3. **Adversarial Attacks**: Inputs are subtly altered to mislead AI models.\n",
        "\n",
        "## Best Practices\n",
        "- **Data Validation**: Implement robust data validation to detect anomalies.\n",
        "- **Access Controls**: Enforce strict access controls to sensitive model components.\n",
        "- **Regular Audits**: Conduct regular security audits and penetration testing.\n",
        "\n",
        "## Conclusion\n",
        "AI security is a critical consideration in the deployment of AI systems. By understanding the threat landscape and implementing best practices, organizations can better protect their AI assets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24d9df27",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import solutions\n",
        "import pygame\n",
        "\n",
        "# Initialize alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: Alarm file '{alarm_file}' not found ‚Äî please check the path.\")\n",
        "\n",
        "# --- Define the Extended Class (as shown above) ---\n",
        "class SoundAlarm(solutions.SecurityAlarm):\n",
        "    \"\"\"\n",
        "    Extends SecurityAlarm to play a sound alarm when the detection threshold is exceeded.\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        # We don't need to pass 'alarm_player' to __init__ if we use pygame.mixer directly\n",
        "        # But we must call the parent's init\n",
        "        super().__init__(**kwargs)\n",
        "        self.sound_played = False  # New flag to ensure sound only plays once per event\n",
        "\n",
        "    def process(self, im0):\n",
        "        \"\"\"\n",
        "        Overrides the parent's process method to include playing an alarm sound.\n",
        "        \"\"\"\n",
        "        # Call the parent's process method (handles detection, annotation, and email)\n",
        "        results = super().process(im0) \n",
        "        # print(\"===> \", self)  # Annotated frame\n",
        "\n",
        "        total_det = len(self.clss)\n",
        "        \n",
        "        # Check if the detection threshold is met AND the sound hasn't been played for this event\n",
        "        if total_det >= self.records and not self.sound_played:\n",
        "            # Check if the mixer is initialized and sound isn't already playing\n",
        "            if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                print(\"üö® Playing security alarm!\")\n",
        "                pygame.mixer.music.play()\n",
        "                self.sound_played = True\n",
        "            \n",
        "        # If total detections drop below the threshold, reset the flags\n",
        "        if total_det < self.records and (self.email_sent or self.sound_played):\n",
        "            self.email_sent = False\n",
        "            self.sound_played = False\n",
        "            print(\"üü¢ Alarm system reset.\")\n",
        "\n",
        "        return results\n",
        "# ---------------------------------------------------\n",
        "\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "# cap = cv2.VideoCapture(0)\n",
        "assert cap.isOpened(), \"‚ùå Error: Cannot read video file.\"\n",
        "\n",
        "# Video writer setup (same as original)\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Security Alarm setup: USE THE EXTENDED CLASS\n",
        "securityalarm = SoundAlarm(\n",
        "    show=True,  # Show annotated video\n",
        "    model=\"yolo11m.pt\",  # Use YOLOv11 medium model\n",
        "    records=3,  # Number of detections to trigger event\n",
        "    # classes=[0, 2] # 0=person, 2=car (using car for cattle)\n",
        "    show_labels=True,\n",
        "    show_conf=True,\n",
        "    conf=0.6\n",
        ")\n",
        "\n",
        "# Optional: Email setup\n",
        "from_email = \"deveansari@gmail.com\"\n",
        "password = \"ddgl yjef dlaw tuzg\" # App password\n",
        "to_email = \"rahatansari.tpu@gmail.com\"\n",
        "\n",
        "# securityalarm.authenticate(from_email, password, to_email)\n",
        "\n",
        "# --- PROCESS VIDEO ---\n",
        "# while cap.isOpened():\n",
        "#     success, im0 = cap.read()\n",
        "#     if not success:\n",
        "#         print(\"‚úÖ Video processing completed.\")\n",
        "#         break\n",
        "\n",
        "#     # Run YOLO detection. The overridden process() method in SoundAlarm handles the sound.\n",
        "#     results = securityalarm(im0)\n",
        "#     print(results) # Log results\n",
        "    \n",
        "#     # Allow pygame to process events to keep the sound playing (optional but good practice)\n",
        "#     pygame.event.pump() \n",
        "\n",
        "\n",
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"‚úÖ Video processing completed.\")\n",
        "        break\n",
        "\n",
        "    results = securityalarm(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    video_writer.write(results.plot_im)  # write the processed frame.\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "pygame.mixer.quit()  # Clean up pygame mixer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "179b7652",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition # Required for face recognition\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils import LOGGER\n",
        "import pygame\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils import LOGGER\n",
        "from ultralytics.utils.plotting import colors\n",
        "\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "# Initialize alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: Alarm file '{alarm_file}' not found ‚Äî please check the path.\")\n",
        "\n",
        "# import requests\n",
        "\n",
        "# @dataclass\n",
        "# class Config:\n",
        "#     # model & known faces\n",
        "#     MODEL_PATH: str = \"yolo11n.pt\"  # change to your model\n",
        "#     KNOWN_FACES_DIR: str = \"family_members\"\n",
        "#     ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
        "#     LOG_DIR: str = \"security_logs\"\n",
        "#     OUTPUT_DIR: str = \"security_output\"\n",
        "#     # VIDEO_SOURCE: str = 0  # camera index or video path\n",
        "#     VIDEO_SOURCE: str = \"./media_files/animal_surveillance/goru-churi.mp4\"  # camera index or video path\n",
        "#     FACE_RECOGNITION_INTERVAL: int = 5\n",
        "#     ALERT_COOLDOWN: int = 10  # seconds global cooldown\n",
        "#     PERSON_COOLDOWN: int = 20  # per person cooldown seconds\n",
        "#     YOLO_CONFIDENCE: float = 0.45\n",
        "#     FACE_DETECTION_CONF: float = 0.5\n",
        "#     RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
        "#     RESIZE_FACTOR: float = 0.35\n",
        "\n",
        "#     # Clip saving\n",
        "#     SAVE_CLIP_SECONDS: int = 6  # seconds to save when alarm triggers (uses ring buffer)\n",
        "#     CLIP_FPS: int = 20\n",
        "\n",
        "#     # GPIO buzzer (optional)\n",
        "#     USE_GPIO: bool = False\n",
        "#     BUZZER_PIN: int = 18  # BCM pin; only used if USE_GPIO True and HAS_RPI True\n",
        "#     BUZZER_SECONDS: float = 5.0\n",
        "\n",
        "#     # Telegram\n",
        "#     USE_TELEGRAM: bool = False\n",
        "#     TELEGRAM_BOT_TOKEN: str = \"\"  # put your bot token\n",
        "#     TELEGRAM_CHAT_ID: str = \"\"    # put your chat id\n",
        "#     SEND_IMAGE_ON_ALERT: bool = True\n",
        "\n",
        "#     # secure zone: rectangle (x1,y1,x2,y2) relative fraction of frame: (left, top, right, bottom)\n",
        "#     # set to None to consider whole frame as secure zone\n",
        "#     SECURE_ZONE_REL: Optional[Tuple[float, float, float, float]] = (0.0, 0.0, 1.0, 1.0)\n",
        "\n",
        "#     # recognition thresholds & voting\n",
        "#     RECOGNITION_MIN_VOTES: int = 2\n",
        "#     RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
        "#     RECOGNITION_TIME_WINDOW: float = 3.0\n",
        "\n",
        "#     # drawing & UI\n",
        "#     WINDOW_NAME: str = \"Security Monitoring\"\n",
        "\n",
        "# Load known faces\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "known_faces_dir = \"family_members/\"  # Create this directory and add images\n",
        "if os.path.exists(known_faces_dir):\n",
        "    for person_name in os.listdir(known_faces_dir):\n",
        "        person_dir = os.path.join(known_faces_dir, person_name)\n",
        "        if os.path.isdir(person_dir):\n",
        "            for image_name in os.listdir(person_dir):\n",
        "                image_path = os.path.join(person_dir, image_name)\n",
        "                try:\n",
        "                    image = face_recognition.load_image_file(image_path)\n",
        "                    face_encodings = face_recognition.face_encodings(image)\n",
        "                    if face_encodings:\n",
        "                        known_face_encodings.append(face_encodings[0])\n",
        "                        known_face_names.append(person_name)\n",
        "                        print(f\"Loaded face: {person_name} from {image_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {image_path}: {e}\")\n",
        "\n",
        "if known_face_encodings:\n",
        "    print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
        "else:\n",
        "    print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
        "\n",
        "# Setup alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
        "# --- The SoundAlarm Class (Modified to be a Base for FaceRecognitionAlarm) ---\n",
        "# We redefine SoundAlarm here for completeness, incorporating the previous logic.\n",
        "class SoundAlarm(solutions.SecurityAlarm):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sound_played = False\n",
        "        \n",
        "    def process(self, im0):\n",
        "        # Call the parent's process to handle YOLO detection, tracking, and annotation\n",
        "        super().process(im0) \n",
        "\n",
        "        total_det = len(self.clss)\n",
        "        \n",
        "        # Check if the detection threshold is met AND the alarm hasn't been played\n",
        "        if total_det >= self.records and not self.sound_played:\n",
        "            import pygame\n",
        "            if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                LOGGER.info(\"üö® Playing security alarm!\")\n",
        "                pygame.mixer.music.play()\n",
        "                self.sound_played = True\n",
        "            \n",
        "        # Reset logic for the alarm\n",
        "        if total_det < self.records and (self.email_sent or self.sound_played):\n",
        "            self.email_sent = False\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm system reset.\")\n",
        "            import pygame\n",
        "            if pygame.mixer.get_init():\n",
        "                 pygame.mixer.music.stop()\n",
        "\n",
        "        # SolutionResults is returned by super().process() in the original class logic,\n",
        "        # but since we are overriding, we need to manually return it or structure \n",
        "        # the original SecurityAlarm.process to return it before any further operations.\n",
        "        # For simplicity, we assume the base class's main work is done and we only \n",
        "        # need to return the annotated frame and flags.\n",
        "        return SolutionResults(\n",
        "            plot_im=self.annotator.result(), \n",
        "            total_tracks=len(self.track_ids), \n",
        "            email_sent=self.email_sent,\n",
        "            sound_played=self.sound_played # Add sound_played to results\n",
        "        )\n",
        "\n",
        "# --- The New Extended Class for Face Recognition ---\n",
        "class FaceRecognitionAlarm(SoundAlarm):\n",
        "    def __init__(self, face_data_path=\"face_data_path\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "        self.face_data_path = face_data_path\n",
        "        self._load_known_faces()\n",
        "\n",
        "    def _load_known_faces(self):\n",
        "        \"\"\"Load known faces from the specified directory.\"\"\"\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "\n",
        "        self.known_faces_dir = \"family_members\" \n",
        "        if os.path.exists(self.known_faces_dir):\n",
        "            for person_name in os.listdir(self.known_faces_dir):\n",
        "                self.person_dir = os.path.join(self.known_faces_dir, person_name)\n",
        "                if os.path.isdir(self.person_dir):\n",
        "                    for image_name in os.listdir(self.person_dir):\n",
        "                        image_path = os.path.join(self.person_dir, image_name)\n",
        "                        try:\n",
        "                            image = face_recognition.load_image_file(image_path)\n",
        "                            face_encodings = face_recognition.face_encodings(image)\n",
        "                            if face_encodings:\n",
        "                                self.known_face_encodings.append(face_encodings[0])\n",
        "                                self.known_face_names.append(person_name)\n",
        "                                print(f\"Loaded face: {person_name} from {image_name}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error loading {image_path}: {e}\")\n",
        "\n",
        "        if known_face_encodings:\n",
        "            print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
        "        else:\n",
        "            print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
        "\n",
        "    def process(self, im0):\n",
        "        \"\"\"\n",
        "        Overrides process to check for UNKNOWN persons and only trigger the alarm for them.\n",
        "        \"\"\"\n",
        "        self.extract_tracks(im0) \n",
        "        self.annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "\n",
        "        unknown_person_count = 0\n",
        "        total_person_det = 0\n",
        "\n",
        "        # YOLOv8 class ID for 'person' is 0\n",
        "        person_cls_id = 0 \n",
        "        person_boxes = [box for box, cls in zip(self.boxes, self.clss) if cls == person_cls_id]\n",
        "        \n",
        "        # Convert image to RGB for face_recognition (it expects RGB)\n",
        "        rgb_frame = cv2.cvtColor(im0, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        for i, box in enumerate(self.boxes):\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cls = self.clss[i]\n",
        "            \n",
        "            # Draw bounding box and label as in original code\n",
        "            label = self.names[cls]\n",
        "            color = colors(cls, True)\n",
        "            \n",
        "            # --- Face Recognition Logic ---\n",
        "            is_unknown = False\n",
        "            \n",
        "            # Check only for 'person' detections\n",
        "            if cls == person_cls_id: \n",
        "                total_person_det += 1\n",
        "                \n",
        "                # Extract the face ROI (top, right, bottom, left) from the detection box\n",
        "                # Face recognition is often faster/more accurate on smaller ROIs\n",
        "                # Since the box is for the whole person, we'll use the whole person box for face finding\n",
        "                \n",
        "                # Convert Ultralytics bbox format (x1, y1, x2, y2) to face_recognition's (top, right, bottom, left)\n",
        "                face_locations = [(y1, x2, y2, x1)] \n",
        "                \n",
        "                face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
        "\n",
        "                if face_encodings:\n",
        "                    face_encoding = face_encodings[0]\n",
        "                    # Compare face with known faces\n",
        "                    matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)\n",
        "                    face_distance = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "                    \n",
        "                    best_match_index = np.argmin(face_distance)\n",
        "                    \n",
        "                    if matches[best_match_index]:\n",
        "                        name = self.known_face_names[best_match_index]\n",
        "                        label = f\"{name} (Known)\"\n",
        "                        color = (0, 255, 0) # Green for known\n",
        "                    else:\n",
        "                        name = \"Unknown\"\n",
        "                        label = f\"{name} (Alarm!)\"\n",
        "                        color = (0, 0, 255) # Red for unknown\n",
        "                        is_unknown = True\n",
        "                        unknown_person_count += 1\n",
        "                else:\n",
        "                    # If no face is found (e.g., person is far or side profile), consider it known/ignore\n",
        "                    # depending on the security requirement. Here we'll default to the original label\n",
        "                    label = f\"{self.names[cls]} (Face Hidden/Far)\"\n",
        "\n",
        "            # Apply final label and color\n",
        "            self.annotator.box_label(box, label=label, color=colors(cls, True))\n",
        "\n",
        "        # Alarm Trigger Logic: Use UNKNOWN_PERSON_COUNT instead of total_det\n",
        "        # Override the inherited flags *before* calling the parent's alarm logic\n",
        "        self.clss = [1] * unknown_person_count # Hack to force parent's total_det check on unknown persons\n",
        "\n",
        "        # Execute parent's alarm logic, which will now use unknown_person_count\n",
        "        results = super().process(im0) \n",
        "        \n",
        "        # Restore the correct total detections if needed for external logging\n",
        "        results.total_detections = len(self.boxes)\n",
        "        results.unknown_persons = unknown_person_count\n",
        "        \n",
        "        return SolutionResults(plot_im=results.plot_im, total_tracks=len(self.track_ids), email_sent=self.email_sent)\n",
        "# import os\n",
        "# import cv2\n",
        "# from ultralytics import solutions\n",
        "# import pygame\n",
        "# Note: The custom classes (SoundAlarm, FaceRecognitionAlarm) need to be defined \n",
        "# or imported before they are used here. For a single script, define them at the top.\n",
        "\n",
        "\n",
        "\n",
        "# Open video\n",
        "# cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "assert cap.isOpened(), \"‚ùå Error: Cannot read video file.\"\n",
        "\n",
        "# Video writer setup (kept for completeness)\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Security Alarm setup: USE THE EXTENDED CLASS\n",
        "# records=1 means alarm will trigger if 1 or more UNKNOWN persons are detected.\n",
        "securityalarm = FaceRecognitionAlarm(\n",
        "    show=True, # Show annotated video\n",
        "    model=\"yolo11m.pt\",     # Use a smaller model for speed\n",
        "    records=3,# Number of UNKNOWN detections to trigger event\n",
        "    # classes=[0, 2],            # Only detect 'person' (ID 0 in COCO) and 'bicycle' (ID 2 in COCO)\n",
        "    face_data_path=known_faces_dir, # Pass the path to face data\n",
        "    conf=0.5,\n",
        "    \n",
        ")\n",
        "\n",
        "# Optional: Email setup\n",
        "from_email = \"deveansari@gmail.com\"\n",
        "password = \"ddgl yjef dlaw tuzg\" # App password\n",
        "to_email = \"rahatansari.tpu@gmail.com\"\n",
        "\n",
        "# securityalarm.authenticate(from_email, password, to_email)\n",
        "\n",
        "# --- PROCESS VIDEO ---\n",
        "print(\"\\n--- Starting Video Processing. Press 'q' to terminate. ---\")\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"‚úÖ Video processing completed.\")\n",
        "        break\n",
        "\n",
        "    # Run Detection and Alarm Logic\n",
        "    results = securityalarm(im0)\n",
        "    \n",
        "    # Check for 'q' key press to terminate\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        print(\"üõë Termination key 'q' pressed. Stopping...\")\n",
        "        break\n",
        "    \n",
        "    # Allow pygame to process events\n",
        "    # pygame.event.pump() \n",
        "\n",
        "# Cleanup\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "pygame.mixer.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5e11d8",
      "metadata": {},
      "source": [
        "### 2nd Best AI Security Alarms with Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b468bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils import LOGGER\n",
        "import pygame\n",
        "from ultralytics import solutions \n",
        "# Import SolutionAnnotator directly from where it lives (as it was in the original SecurityAlarm definition)\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "from ultralytics.utils import LOGGER\n",
        "from ultralytics.utils.plotting import colors\n",
        "\n",
        "# --- 1. Pygame and Known Faces Setup (Global) ---\n",
        "\n",
        "# Initialize alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: Alarm file '{alarm_file}' not found ‚Äî please check the path.\")\n",
        "\n",
        "# Define the directory for known faces\n",
        "KNOWN_FACES_DIR = \"family_members\" \n",
        "\n",
        "# --- 2. Extended Class Definitions ---\n",
        "\n",
        "# --- SoundAlarm Class (Base for audio functionality) ---\n",
        "class SoundAlarm(solutions.SecurityAlarm):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sound_played = False\n",
        "        \n",
        "    def process(self, im0):\n",
        "        # The parent's process call here is for annotation, but the inherited \n",
        "        # class will override this to manage the detection list (self.clss)\n",
        "        # for alarm purposes. We will rely on the logic below to handle the alarm \n",
        "        # based on the (possibly modified) self.clss and then call parent's \n",
        "        # methods explicitly for better control.\n",
        "\n",
        "        # 1. Annotation (Draw boxes based on current self.boxes/self.clss)\n",
        "        # The base class's process method does this, but we'll manually draw \n",
        "        # after face recognition to show the correct label/color.\n",
        "        \n",
        "        total_det = len(self.clss)\n",
        "        \n",
        "        # 2. Alarm Trigger Check (Email/Sound)\n",
        "        if total_det >= self.records and not (self.email_sent and self.sound_played):\n",
        "            # Alarm Condition Met - Check individual flags\n",
        "            if not self.email_sent:\n",
        "                # Assuming email setup is working or uncommented\n",
        "                # self.send_email(im0, total_det)\n",
        "                self.email_sent = True\n",
        "                LOGGER.info(\"üìß Email alert condition met.\")\n",
        "                \n",
        "            if not self.sound_played:\n",
        "                if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                    LOGGER.info(\"üö® Playing security alarm!\")\n",
        "                    pygame.mixer.music.play()\n",
        "                    self.sound_played = True\n",
        "            \n",
        "        # 3. Reset logic for the alarm\n",
        "        if total_det < self.records and (self.email_sent or self.sound_played):\n",
        "            self.email_sent = False\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm system reset.\")\n",
        "            if pygame.mixer.get_init():\n",
        "                 pygame.mixer.music.stop()\n",
        "\n",
        "        # Final annotation and display (to be handled in FaceRecognitionAlarm for corrected labels)\n",
        "        \n",
        "        # Returning a SolutionResults object is essential\n",
        "        return SolutionResults(\n",
        "             plot_im=im0, # This will be the annotated image from FaceRecognitionAlarm\n",
        "             total_tracks=len(getattr(self, 'track_ids', [])), \n",
        "             email_sent=self.email_sent,\n",
        "             sound_played=self.sound_played \n",
        "        )\n",
        "\n",
        "\n",
        "# --- FaceRecognitionAlarm Class (Consolidated logic) ---\n",
        "class FaceRecognitionAlarm(solutions.SecurityAlarm): # Inherit from SecurityAlarm, not SoundAlarm now for cleaner override\n",
        "    def __init__(self, face_data_path, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "        self.face_data_path = face_data_path\n",
        "        self.sound_played = False # Add sound state here for alarm control\n",
        "        self._load_known_faces()\n",
        "\n",
        "    def _load_known_faces(self):\n",
        "        \"\"\"Loads face encodings from the specified directory and updates instance attributes.\"\"\"\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "\n",
        "        if not os.path.exists(self.face_data_path):\n",
        "             LOGGER.warning(f\"Face data path '{self.face_data_path}' not found. Cannot load known faces.\")\n",
        "             return\n",
        "\n",
        "        # Use os.walk to search through family_members and authorize_person subdirectories\n",
        "        for root, dirs, files in os.walk(self.face_data_path):\n",
        "            for image_name in files:\n",
        "                if image_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    image_path = os.path.join(root, image_name)\n",
        "                    # The person name is the parent directory name\n",
        "                    person_name = os.path.basename(root)\n",
        "\n",
        "                    try:\n",
        "                        image = face_recognition.load_image_file(image_path)\n",
        "                        face_encodings = face_recognition.face_encodings(image)\n",
        "                        if face_encodings:\n",
        "                            self.known_face_encodings.append(face_encodings[0])\n",
        "                            self.known_face_names.append(person_name)\n",
        "                            LOGGER.info(f\"Loaded face: {person_name} from {image_name}\")\n",
        "                        else:\n",
        "                            LOGGER.warning(f\"No face found in image: {image_path}\")\n",
        "                    except Exception as e:\n",
        "                        LOGGER.error(f\"Error loading {image_path}: {e}\")\n",
        "\n",
        "        if self.known_face_encodings:\n",
        "            LOGGER.info(f\"Successfully loaded {len(self.known_face_encodings)} face encodings for {len(set(self.known_face_names))} people\")\n",
        "        else:\n",
        "            LOGGER.warning(\"No known faces were loaded. All detected persons will be considered unknown.\")\n",
        "\n",
        "    def process(self, im0):\n",
        "        \"\"\"Overrides process to check for UNKNOWN persons and only trigger the alarm for them.\"\"\"\n",
        "        self.extract_tracks(im0) \n",
        "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "\n",
        "        unknown_person_count = 0\n",
        "        person_cls_id = 0 # COCO class ID for 'person'\n",
        "\n",
        "        # Convert image to RGB for face_recognition (it expects RGB)\n",
        "        # Resize the frame for faster face recognition (optional, but highly recommended)\n",
        "        small_frame = cv2.resize(im0, (0, 0), fx=0.25, fy=0.25)\n",
        "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Find all face locations and encodings in the small frame\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "        \n",
        "        # List to store the actual labels/colors to be drawn\n",
        "        labels_to_draw = []\n",
        "        \n",
        "        # Only process objects that are people\n",
        "        for i, box in enumerate(self.boxes):\n",
        "            cls = self.clss[i]\n",
        "            \n",
        "            # Default label and color (YOLO detection)\n",
        "            label = self.names[cls]\n",
        "            color = colors(cls, True)\n",
        "            is_unknown = False\n",
        "\n",
        "            if cls == person_cls_id:\n",
        "                # Check for a corresponding face detection within the person's bounding box\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                (h, w) = im0.shape[:2]\n",
        "\n",
        "                found_face = False\n",
        "                \n",
        "                # Check each detected face location against the YOLO person box\n",
        "                for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "                    # Scale face locations back up to original image size\n",
        "                    top *= 4\n",
        "                    right *= 4\n",
        "                    bottom *= 4\n",
        "                    left *= 4\n",
        "                    \n",
        "                    # Check if the center of the face is inside the YOLO person box\n",
        "                    face_center_x = (left + right) // 2\n",
        "                    face_center_y = (top + bottom) // 2\n",
        "\n",
        "                    if x1 <= face_center_x <= x2 and y1 <= face_center_y <= y2:\n",
        "                        found_face = True\n",
        "                        \n",
        "                        # Perform face recognition\n",
        "                        if self.known_face_encodings:\n",
        "                            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding, tolerance=0.55) # Tweak tolerance\n",
        "                            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "                            best_match_index = np.argmin(face_distances)\n",
        "                            \n",
        "                            if matches[best_match_index]:\n",
        "                                name = self.known_face_names[best_match_index]\n",
        "                                label = f\"{name} (Known)\"\n",
        "                                color = (0, 255, 0) # Green\n",
        "                            else:\n",
        "                                name = \"Unknown\"\n",
        "                                label = f\"{name} (ALARM!)\"\n",
        "                                color = (0, 0, 255) # Red\n",
        "                                is_unknown = True\n",
        "                                unknown_person_count += 1\n",
        "                        else:\n",
        "                            # No known faces loaded, treat as unknown if a face is detected\n",
        "                            name = \"Unknown\"\n",
        "                            label = f\"{name} (ALARM!)\"\n",
        "                            color = (0, 0, 255) # Red\n",
        "                            is_unknown = True\n",
        "                            unknown_person_count += 1\n",
        "                        \n",
        "                        break # Stop searching for more matching faces for this person box\n",
        "                \n",
        "                if not found_face:\n",
        "                    label = f\"{self.names[cls]} (No Face)\" # Use default color if no face is found\n",
        "\n",
        "            # Store the data for drawing\n",
        "            annotator.box_label(box, label=label, color=color)\n",
        "\n",
        "        # Alarm Trigger Logic: Use UNKNOWN_PERSON_COUNT\n",
        "        # Temporarily update self.clss for the parent class's email/sound checks\n",
        "        self.clss = [1] * unknown_person_count \n",
        "        \n",
        "        # --- Alarm Control (Manual implementation from SoundAlarm) ---\n",
        "        total_det = len(self.clss) # This is now the unknown_person_count\n",
        "        \n",
        "        if total_det >= self.records:\n",
        "            if not self.email_sent:\n",
        "                # self.send_email(im0, total_det) # Uncomment if email is setup\n",
        "                self.email_sent = True\n",
        "            if not self.sound_played:\n",
        "                if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                    LOGGER.info(\"üö® Playing security alarm!\")\n",
        "                    pygame.mixer.music.play()\n",
        "                    self.sound_played = True\n",
        "        \n",
        "        # Reset logic\n",
        "        if total_det < self.records and (self.email_sent or self.sound_played):\n",
        "            self.email_sent = False\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm system reset.\")\n",
        "            if pygame.mixer.get_init():\n",
        "                 pygame.mixer.music.stop()\n",
        "        # --- End Alarm Control ---\n",
        "        \n",
        "        plot_im = annotator.result()\n",
        "        self.display_output(plot_im) \n",
        "\n",
        "        # Return the SolutionResults with the correct flags and counts\n",
        "        return SolutionResults(\n",
        "            plot_im=plot_im, \n",
        "            total_tracks=len(self.track_ids), \n",
        "            email_sent=self.email_sent,\n",
        "            sound_played=self.sound_played,\n",
        "            unknown_persons=unknown_person_count\n",
        "        )\n",
        "\n",
        "\n",
        "# --- 3. Main Execution Block ---\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "assert cap.isOpened(), \"‚ùå Error: Cannot read video file.\"\n",
        "\n",
        "# Video writer setup\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Security Alarm setup: USE THE EXTENDED CLASS\n",
        "# records=3 means alarm will trigger if 3 or more UNKNOWN persons are detected.\n",
        "securityalarm = FaceRecognitionAlarm(\n",
        "    show=True, \n",
        "    model=\"yolo11s.pt\", # Changed to a faster model for real-time face recognition\n",
        "    records=1,\n",
        "    # classes=[0, 2],        # Only detect 'person' (ID 0) for face recognition\n",
        "    face_data_path=KNOWN_FACES_DIR,\n",
        "    conf=0.5,\n",
        ")\n",
        "\n",
        "# Optional: Email setup\n",
        "from_email = \"deveansari@gmail.com\"\n",
        "password = \"ddgl yjef dlaw tuzg\" \n",
        "to_email = \"rahatansari.tpu@gmail.com\"\n",
        "\n",
        "# securityalarm.authenticate(from_email, password, to_email) # Uncomment and fix password/email\n",
        "\n",
        "# --- PROCESS VIDEO ---\n",
        "# print(\"\\n--- Starting Video Processing. Press 'q' to terminate. ---\")\n",
        "# while cap.isOpened():\n",
        "#     ret, frame = cap.read()\n",
        "#     if not ret:\n",
        "#         print(\"‚úÖ Video processing completed.\")\n",
        "#         break\n",
        "\n",
        "#     # Run Detection and Alarm Logic\n",
        "#     results = securityalarm(frame)\n",
        "#     writer.write(results.plot_im)\n",
        "#     cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "#     # Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"‚úÖ Video processing completed.\")\n",
        "        break\n",
        "\n",
        "    results = securityalarm(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    # video_writer.write(results.plot_im)  # write the processed frame.\n",
        "\n",
        "    # Check for 'q' key press to terminate\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        print(\"üõë Termination key 'q' pressed. Stopping...\")\n",
        "        break\n",
        "    \n",
        "    # Allow pygame to process events\n",
        "    # pygame.event.pump() \n",
        "\n",
        "# Cleanup\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "pygame.mixer.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4637d5dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import pygame\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils import LOGGER\n",
        "\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "\n",
        "# ========== üîä SOUND SETUP ==========\n",
        "pygame.mixer.init()\n",
        "ALARM_FILE = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(ALARM_FILE):\n",
        "    pygame.mixer.music.load(ALARM_FILE)\n",
        "else:\n",
        "    print(f\"[WARNING] Alarm file '{ALARM_FILE}' not found.\")\n",
        "\n",
        "\n",
        "# ========== üß† KNOWN FACE ENCODING LOADER ==========\n",
        "KNOWN_FACE_DIR = \"family_members\"\n",
        "known_face_encodings, known_face_names = [], []\n",
        "\n",
        "if os.path.exists(KNOWN_FACE_DIR):\n",
        "    for name in os.listdir(KNOWN_FACE_DIR):\n",
        "        person_dir = os.path.join(KNOWN_FACE_DIR, name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        for filename in os.listdir(person_dir):\n",
        "            path = os.path.join(person_dir, filename)\n",
        "            try:\n",
        "                img = face_recognition.load_image_file(path)\n",
        "                enc = face_recognition.face_encodings(img)\n",
        "                if enc:\n",
        "                    known_face_encodings.append(enc[0])\n",
        "                    known_face_names.append(name)\n",
        "                    print(f\"[INFO] Loaded face for {name} from {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] Failed loading {path}: {e}\")\n",
        "else:\n",
        "    print(\"[WARNING] No known_faces directory found.\")\n",
        "\n",
        "\n",
        "# ========== ‚öôÔ∏è EXTENDED SECURITY ALARM WITH SOUND ==========\n",
        "class SoundAlarm(solutions.SecurityAlarm):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.sound_played = False\n",
        "        self.email_sent = False\n",
        "\n",
        "    def trigger_alarm(self):\n",
        "        \"\"\"Play sound + send email.\"\"\"\n",
        "        if not self.sound_played:\n",
        "            if pygame.mixer.get_init():\n",
        "                pygame.mixer.music.play()\n",
        "                print(\"[ALARM] ‚ö†Ô∏è Unknown person detected ‚Äî alarm triggered!\")\n",
        "            self.sound_played = True\n",
        "        if not self.email_sent:\n",
        "            try:\n",
        "                super().trigger_alarm()  # optional email alert\n",
        "                self.email_sent = True\n",
        "            except Exception as e:\n",
        "                LOGGER.warning(f\"Email alert failed: {e}\")\n",
        "\n",
        "    def reset_alarm(self):\n",
        "        \"\"\"Stop alarm and reset states.\"\"\"\n",
        "        if self.sound_played:\n",
        "            if pygame.mixer.get_init():\n",
        "                pygame.mixer.music.stop()\n",
        "                print(\"[ALARM] ‚úÖ Alarm stopped ‚Äî area clear.\")\n",
        "        self.sound_played = False\n",
        "        self.email_sent = False\n",
        "\n",
        "    def __call__(self, im0):\n",
        "        # call base detection\n",
        "        results = super().__call__(im0)\n",
        "        return SolutionResults(\n",
        "            im0=im0,\n",
        "            plot_im=results.plot_im if hasattr(results, \"plot_im\") else im0,\n",
        "            dets=results.dets if hasattr(results, \"dets\") else None\n",
        "        )\n",
        "\n",
        "\n",
        "# ========== üëÅÔ∏è FACE-RECOGNITION ALARM COMBINATION ==========\n",
        "class FaceRecognitionAlarm(solutions.SecurityAlarm):\n",
        "    def __init__(self, *args, known_face_encodings=None, known_face_names=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.known_face_encodings = known_face_encodings or []\n",
        "        self.known_face_names = known_face_names or []\n",
        "        self.sound_played = False\n",
        "\n",
        "    def play_sound(self):\n",
        "        if not self.sound_played:\n",
        "            pygame.mixer.music.play()\n",
        "            self.sound_played = True\n",
        "            print(\"[ALARM] üö® Unknown face ‚Äî sound started!\")\n",
        "\n",
        "    def reset_sound(self):\n",
        "        if self.sound_played:\n",
        "            pygame.mixer.music.stop()\n",
        "            self.sound_played = False\n",
        "            print(\"[ALARM] üîá Sound reset.\")\n",
        "\n",
        "    def __call__(self, im0):\n",
        "        self.extract_tracks(im0)\n",
        "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "        unknown_detected = False\n",
        "\n",
        "        for xyxy, conf, cls in zip(self.boxes, self.confs, self.clss):\n",
        "            if int(cls) != 0:  # 0 = person\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "            face_image = im0[y1:y2, x1:x2]\n",
        "            if face_image.size == 0:\n",
        "                continue\n",
        "\n",
        "            rgb_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
        "            encs = face_recognition.face_encodings(rgb_face)\n",
        "            name = \"Unknown\"\n",
        "\n",
        "            if encs:\n",
        "                matches = face_recognition.compare_faces(self.known_face_encodings, encs[0])\n",
        "                if True in matches:\n",
        "                    name = self.known_face_names[matches.index(True)]\n",
        "\n",
        "            color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
        "            label = f\"{name} ({conf:.2f})\"\n",
        "            annotator.box_label(xyxy, label, color=color)\n",
        "\n",
        "            if name == \"Unknown\":\n",
        "                unknown_detected = True\n",
        "\n",
        "        if unknown_detected:\n",
        "            self.play_sound()\n",
        "        else:\n",
        "            self.reset_sound()\n",
        "\n",
        "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
        "        if total_tracks > 0:\n",
        "            cv2.putText(\n",
        "                im0,\n",
        "                f\"Tracks: {total_tracks}\",\n",
        "                (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1,\n",
        "                (255, 255, 255),\n",
        "                2,\n",
        "            )\n",
        "\n",
        "        return SolutionResults(im0=im0, plot_im=annotator.result())\n",
        "\n",
        "\n",
        "# ========== üé• MAIN LOOP ==========\n",
        "if __name__ == \"__main__\":\n",
        "    cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    assert cap.isOpened(), \"Error: video not found or cannot be opened.\"\n",
        "\n",
        "    w, h, fps = (int(cap.get(x)) for x in\n",
        "                 (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "    writer = cv2.VideoWriter(\"security_output.avi\",\n",
        "                             cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "    face_alarm = FaceRecognitionAlarm(\n",
        "        show=True,\n",
        "        model=\"yolo11m.pt\",\n",
        "        records=3,\n",
        "        # classes=[0],  # person\n",
        "        known_face_encodings=known_face_encodings,\n",
        "        known_face_names=known_face_names\n",
        "    )\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"[INFO] Video finished or empty frame.\")\n",
        "            break\n",
        "\n",
        "        results = face_alarm(frame)\n",
        "        writer.write(results.plot_im)\n",
        "        cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "        # pygame.event.pump()\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    pygame.quit()\n",
        "    print(\"[INFO] Surveillance session ended.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a1bd440",
      "metadata": {},
      "source": [
        "## Best face recognition system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2dbf8fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils import LOGGER\n",
        "import pygame\n",
        "from pathlib import Path  # Fix: Import the Path object\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "from ultralytics.utils.plotting import colors\n",
        "# --- 1. Pygame and Known Faces Setup (Global) ---\n",
        "\n",
        "# Initialize alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: Alarm file '{alarm_file}' not found ‚Äî please check the path.\")\n",
        "\n",
        "# Define the directory for known faces\n",
        "KNOWN_FACES_DIR = \"family_members/\" \n",
        "\n",
        "# --- 2. Extended Class Definitions ---\n",
        "\n",
        "# --- FaceRecognitionAlarm Class (Consolidated logic) ---\n",
        "class FaceRecognitionAlarm(solutions.SecurityAlarm): # Inherit from SecurityAlarm, not SoundAlarm now for cleaner override\n",
        "    \"\"\"\n",
        "    A security alarm that uses face recognition to trigger alerts only for unknown persons.\n",
        "    Optimized to run face recognition intermittently for better performance.\n",
        "    \"\"\"\n",
        "    def __init__(self, face_data_path, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.known_face_encodings = []\n",
        "        self.known_face_names = []\n",
        "        self.face_data_path = face_data_path\n",
        "        self.sound_played = False # Add sound state here for alarm control\n",
        "\n",
        "        # Optimization attributes\n",
        "        self.frame_count = 0\n",
        "        self.recognition_interval = 5  # Process face recognition every 5 frames\n",
        "        self.tracked_faces = {}  # Stores recognition state for each track_id: {'name': str, 'cooldown': int}\n",
        "        self.recognition_cooldown = 15  # Frames to wait before re-checking a face\n",
        "\n",
        "        self._load_known_faces()\n",
        "\n",
        "    def _load_known_faces(self):\n",
        "        \"\"\"Loads face encodings from a directory with a 'person_name/image.jpg' structure.\"\"\"\n",
        "        LOGGER.info(f\"Loading known faces from '{self.face_data_path}'...\")\n",
        "        if not os.path.exists(KNOWN_FACES_DIR):\n",
        "            LOGGER.warning(f\"Known faces directory '{KNOWN_FACES_DIR}' not found.\")\n",
        "            return\n",
        "\n",
        "        for person_name in os.listdir(KNOWN_FACES_DIR):\n",
        "            person_path = Path(KNOWN_FACES_DIR) / person_name\n",
        "            if person_path.is_dir():\n",
        "                for image_file in person_path.glob('*[.jpg,.jpeg,.png]'):\n",
        "                    try:\n",
        "                        image = face_recognition.load_image_file(str(image_file))\n",
        "                        encodings = face_recognition.face_encodings(image)\n",
        "                        if encodings:\n",
        "                            self.known_face_encodings.append(encodings[0])\n",
        "                            self.known_face_names.append(person_name)\n",
        "                            LOGGER.info(f\"  - Loaded face for '{person_name}' from {image_file.name}\")\n",
        "                        else:\n",
        "                            LOGGER.warning(f\"No face found in {image_file}\")\n",
        "                    except Exception as e:\n",
        "                        LOGGER.error(f\"Error loading {image_file}: {e}\")\n",
        "        \n",
        "        if not self.known_face_encodings:\n",
        "            LOGGER.warning(\"No known faces loaded. All detected persons will be 'Unknown'.\")\n",
        "        else:\n",
        "            LOGGER.info(f\"Successfully loaded {len(self.known_face_encodings)} faces for {len(set(self.known_face_names))} people.\")\n",
        "\n",
        "    def _get_face_encodings(self, im0):\n",
        "        \"\"\"Detects faces and computes encodings, but only on interval frames.\"\"\"\n",
        "        if self.frame_count % self.recognition_interval == 0:\n",
        "            small_frame = cv2.resize(im0, (0, 0), fx=0.25, fy=0.25)\n",
        "            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "            return face_locations, face_encodings\n",
        "        return [], []\n",
        "\n",
        "    def _handle_alarm_logic(self, unknown_person_count):\n",
        "        \"\"\"Manages the triggering and resetting of the sound and email alarm.\"\"\"\n",
        "        if unknown_person_count >= self.records:\n",
        "            if not self.email_sent:\n",
        "                # self.send_email(im0, unknown_person_count) # Uncomment if email is setup\n",
        "                self.email_sent = True\n",
        "                LOGGER.info(f\"üìß Email alert condition met for {unknown_person_count} unknown person(s).\")\n",
        "            if not self.sound_played:\n",
        "                if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                    LOGGER.info(\"üö® Playing security alarm!\")\n",
        "                    pygame.mixer.music.play()\n",
        "                    self.sound_played = True\n",
        "        elif self.email_sent or self.sound_played:\n",
        "            self.email_sent = False\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm system reset.\")\n",
        "            if pygame.mixer.get_init():\n",
        "                 pygame.mixer.music.stop()\n",
        "\n",
        "    def process(self, im0):\n",
        "        \"\"\"Overrides process to add optimized face recognition and alarm logic.\"\"\"\n",
        "        self.frame_count += 1\n",
        "        self.extract_tracks(im0)\n",
        "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "\n",
        "        unknown_person_count = 0\n",
        "        person_cls_id = 0  # COCO class ID for 'person'\n",
        "\n",
        "        face_locations, face_encodings = self._get_face_encodings(im0)\n",
        "\n",
        "        # Process each tracked object\n",
        "        for i, (box, track_id) in enumerate(zip(self.boxes, self.track_ids)):\n",
        "            cls = self.clss[i]\n",
        "            label = self.names[cls]\n",
        "            color = colors(cls, True)\n",
        "\n",
        "            if cls == person_cls_id:\n",
        "                if track_id not in self.tracked_faces or self.tracked_faces[track_id]['cooldown'] == 0:\n",
        "                    if face_encodings:\n",
        "                        x1, y1, x2, y2 = map(int, box)\n",
        "                        found_match = False\n",
        "                        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "                            top, right, bottom, left = top * 4, right * 4, bottom * 4, left * 4\n",
        "                            face_center_x, face_center_y = (left + right) // 2, (top + bottom) // 2\n",
        "\n",
        "                            if x1 <= face_center_x <= x2 and y1 <= face_center_y <= y2:\n",
        "                                matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding, tolerance=0.55)\n",
        "                                name = \"Unknown\"\n",
        "                                if True in matches:\n",
        "                                    best_match_index = np.argmin(face_recognition.face_distance(self.known_face_encodings, face_encoding))\n",
        "                                    if matches[best_match_index]:\n",
        "                                        name = self.known_face_names[best_match_index]\n",
        "\n",
        "                                self.tracked_faces[track_id] = {'name': name, 'cooldown': self.recognition_cooldown}\n",
        "                                found_match = True\n",
        "                                break\n",
        "                        \n",
        "                        if not found_match:\n",
        "                            self.tracked_faces[track_id] = {'name': 'No Face', 'cooldown': self.recognition_cooldown}\n",
        "\n",
        "                if track_id in self.tracked_faces:\n",
        "                    face_info = self.tracked_faces[track_id]\n",
        "                    name = face_info['name']\n",
        "                    if name == \"Unknown\":\n",
        "                        label, color = \"Unknown (ALARM!)\", (0, 0, 255)\n",
        "                        unknown_person_count += 1\n",
        "                    elif name == \"No Face\":\n",
        "                        label, color = \"Person (No Face)\", (255, 192, 203) # Pink\n",
        "                    else:\n",
        "                        label, color = f\"{name} (Known)\", (0, 255, 0)\n",
        "                    \n",
        "                    if face_info['cooldown'] > 0:\n",
        "                        self.tracked_faces[track_id]['cooldown'] -= 1\n",
        "\n",
        "            annotator.box_label(box, label=label, color=color)\n",
        "\n",
        "        self._handle_alarm_logic(unknown_person_count)\n",
        "\n",
        "        plot_im = annotator.result()\n",
        "        self.display_output(plot_im) \n",
        "\n",
        "        # Return the SolutionResults with the correct flags and counts\n",
        "        return SolutionResults(\n",
        "            plot_im=plot_im, \n",
        "            # im0=im0,\n",
        "            total_tracks=len(getattr(self, 'track_ids', [])), \n",
        "            email_sent=self.email_sent,\n",
        "            sound_played=self.sound_played,\n",
        "        )\n",
        "\n",
        "\n",
        "# --- 3. Main Execution Block ---\n",
        "\n",
        "# Open video\n",
        "# cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "cap = cv2.VideoCapture(\"media_files/theaf_surveillance/1093628701-preview.mp4\")\n",
        "assert cap.isOpened(), \"‚ùå Error: Cannot read video file.\"\n",
        "\n",
        "# Video writer setup\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Security Alarm setup: USE THE EXTENDED CLASS\n",
        "# records=3 means alarm will trigger if 3 or more UNKNOWN persons are detected.\n",
        "securityalarm = FaceRecognitionAlarm(\n",
        "    show=True, \n",
        "    model=\"yolo11m.pt\", # Use a valid and fast model\n",
        "    records=1,\n",
        "    # classes=[0, 2],        # Only detect 'person' (ID 0) and 'bicycle' (ID 2) for face recognition\n",
        "    face_data_path=KNOWN_FACES_DIR,\n",
        "    conf=0.5\n",
        ")\n",
        "\n",
        "# Optional: Email setup\n",
        "from_email = \"deveansari@gmail.com\"\n",
        "password = \"ddgl yjef dlaw tuzg\" \n",
        "to_email = \"rahatansari.tpu@gmail.com\"\n",
        "\n",
        "# securityalarm.authenticate(from_email, password, to_email) # Uncomment and fix password/email\n",
        "\n",
        "# --- PROCESS VIDEO ---\n",
        "print(\"\\n--- Starting Video Processing. Press 'q' to terminate. ---\")\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        print(\"‚úÖ Video processing completed.\")\n",
        "        break\n",
        "\n",
        "    # Run Detection and Alarm Logic\n",
        "    results = securityalarm(frame)\n",
        "    # video_writer.write(results.plot_im)  # write the processed frame.\n",
        "    # cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "    \n",
        "    # Check for 'q' key press to terminate\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        print(\"üõë Termination key 'q' pressed. Stopping...\")\n",
        "        break\n",
        "    \n",
        "    # Allow pygame to process events\n",
        "    # pygame.event.pump() \n",
        "\n",
        "# Cleanup\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "pygame.mixer.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e250b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import pygame\n",
        "from ultralytics import solutions\n",
        "# from ultralytics.engine.results import Results\n",
        "from ultralytics.utils import LOGGER\n",
        "\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "from ultralytics.engine.results import Results\n",
        "from ultralytics.utils.plotting import colors\n",
        "from typing import Any, Dict, List, Tuple\n",
        "# ========== üîä SOUND SETUP ==========\n",
        "pygame.mixer.init()\n",
        "ALARM_FILE = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(ALARM_FILE):\n",
        "    pygame.mixer.music.load(ALARM_FILE)\n",
        "else:\n",
        "    print(f\"[WARNING] Alarm file '{ALARM_FILE}' not found.\")\n",
        "\n",
        "\n",
        "# ========== üß† KNOWN FACE ENCODING LOADER ==========\n",
        "KNOWN_FACE_DIR = \"family_members/\"\n",
        "known_face_encodings, known_face_names = [], []\n",
        "\n",
        "if os.path.exists(KNOWN_FACE_DIR):\n",
        "    for name in os.listdir(KNOWN_FACE_DIR):\n",
        "        person_dir = os.path.join(KNOWN_FACE_DIR, name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        for filename in os.listdir(person_dir):\n",
        "            path = os.path.join(person_dir, filename)\n",
        "            try:\n",
        "                img = face_recognition.load_image_file(path)\n",
        "                enc = face_recognition.face_encodings(img)\n",
        "                if enc:\n",
        "                    known_face_encodings.append(enc[0])\n",
        "                    known_face_names.append(name)\n",
        "                    print(f\"[INFO] Loaded face for {name} from {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] Failed loading {path}: {e}\")\n",
        "else:\n",
        "    print(\"[WARNING] No known_faces directory found.\")\n",
        "\n",
        "# ...existing code...\n",
        "def update_labels_info(label: dict[str, Any]) -> dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Normalize and augment a detection/segmentation label dict so you can\n",
        "    draw a custom label containing a stable track id (or a bbox-based fallback).\n",
        "\n",
        "    Expected/optional keys in `label`:\n",
        "      - 'box' : [x1, y1, x2, y2]  (xyxy)\n",
        "      - 'cls'  : int class id\n",
        "      - 'conf' : float confidence\n",
        "      - 'track_id' or 'id' : tracker id (preferred)\n",
        "      - 'name' or 'cls_name' : human-readable class/name\n",
        "      - 'custom_prefix' : optional prefix for the displayed label (default 'person')\n",
        "\n",
        "    Returns same dict with new keys:\n",
        "      - 'track_id' (guaranteed)\n",
        "      - 'display_name' (string to pass to annotator.box_label)\n",
        "    \"\"\"\n",
        "    # ensure keys exist\n",
        "    track_id = label.get(\"track_id\") or label.get(\"id\") or label.get(\"track\") or None\n",
        "\n",
        "    # fallback: derive stable id from bbox center if no track id provided\n",
        "    if track_id is None and label.get(\"box\") is not None:\n",
        "        try:\n",
        "            x1, y1, x2, y2 = map(int, label[\"box\"])\n",
        "            track_id = f\"{(x1 + x2)//2}_{(y1 + y2)//2}\"\n",
        "        except Exception:\n",
        "            track_id = \"0\"\n",
        "\n",
        "    # readable name\n",
        "    name = label.get(\"name\") or label.get(\"cls_name\") or \"\"\n",
        "    if not name and label.get(\"cls\") is not None and hasattr(label.get(\"cls\"), \"__int__\"):\n",
        "        # optional mapping: if you have model.names available you can set it externally on label\n",
        "        name = label.get(\"label\") or \"\"\n",
        "\n",
        "    conf = label.get(\"conf\")\n",
        "    prefix = str(label.get(\"custom_prefix\", \"\"))\n",
        "\n",
        "    # build display text\n",
        "    base = name if name else f\"class_{label.get('cls','?')}\"\n",
        "    if conf is not None:\n",
        "        # display = f\"{prefix}_{track_id} {base} ({float(conf):.2f})\"\n",
        "        display = f\"{prefix}{track_id} {base} ({float(conf):.2f})\"\n",
        "    else:\n",
        "        # display = f\"{prefix}_{track_id} {base}\"\n",
        "        display = f\"{prefix}{track_id} {base}\"\n",
        "        \n",
        "    # label[\"cls\"] = cls\n",
        "    label[\"track_id\"] = track_id\n",
        "    label[\"display_name\"] = display\n",
        "    return label\n",
        "# ...existing code...\n",
        "# ========== üëÅÔ∏è FACE-RECOGNITION ALARM (REVISED & OPTIMIZED) ==========\n",
        "class FaceRecognitionAlarm(solutions.SecurityAlarm):\n",
        "    def __init__(self, *args, known_face_encodings=None, known_face_names=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.known_face_encodings = known_face_encodings or []\n",
        "        self.known_face_names = known_face_names or []\n",
        "        self.sound_played = False\n",
        "        # Best practice: Set face recognition tolerance during initialization\n",
        "        self.face_tolerance = 0.55\n",
        "        \n",
        "        self.show_conf = self.CFG.get(\"show_conf\", True)\n",
        "        self.show_labels = self.CFG.get(\"show_labels\", True)\n",
        "        self.show_boxes = self.CFG.get(\"show_boxes\", True)\n",
        "        \n",
        "   \n",
        "    def play_sound(self):\n",
        "        \"\"\"Plays the alarm sound if it's not already playing.\"\"\"\n",
        "        if not self.sound_played:\n",
        "            if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                pygame.mixer.music.play()\n",
        "                self.sound_played = True\n",
        "                LOGGER.info(\"üö® Alarm Triggered: Unknown person count reached threshold.\")\n",
        "\n",
        "    def reset_sound(self):\n",
        "        \"\"\"Stops the alarm sound and resets the state.\"\"\"\n",
        "        if self.sound_played:\n",
        "            if pygame.mixer.get_init():\n",
        "                pygame.mixer.music.stop()\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm Reset: Area clear.\")\n",
        "\n",
        "    def __call__(self, im0):\n",
        "        \"\"\"\n",
        "        Processes a single frame for person detection and face recognition.\n",
        "        This implementation follows best practices for accuracy and performance.\n",
        "        \"\"\"\n",
        "        # 1. Get person detections from the base class\n",
        "        self.extract_tracks(im0)\n",
        "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "         # plot_im = annotator.result()\n",
        "        self.masks = getattr(self.tracks[0], \"masks\", None)\n",
        "\n",
        "        # Annotation for segmentation masks\n",
        "        # Iterate over detected classes, track IDs, and segmentation masks\n",
        "        if self.masks is None:\n",
        "            self.LOGGER.warning(\"No masks detected! Ensure you're using a supported Ultralytics segmentation model.\")\n",
        "            plot_im = im0\n",
        "        else:\n",
        "            results = Results(im0, path=None, names=self.names, boxes=self.track_data.data, masks=self.masks.data)\n",
        "            plot_im = results.plot(\n",
        "                line_width=self.line_width,\n",
        "                boxes=self.show_boxes,\n",
        "                conf=self.show_conf,\n",
        "                labels=self.show_labels,\n",
        "                color_mode=\"instance\"  \n",
        "            )\n",
        "       \n",
        "\n",
        "        # self.display_output(plot_im)\n",
        "        # return SolutionResults(plot_im=plot_im, total_tracks=len(self.track_ids))\n",
        "        # Display the annotated output using the base class function\n",
        "\n",
        "        unknown_person_count = 0\n",
        "\n",
        "        # 2. Optimize by finding all faces in the frame at once (on a smaller version)\n",
        "        # This is much faster than processing crops for each person.\n",
        "        h, w, _ = im0.shape\n",
        "        small_frame = cv2.resize(im0, (0, 0), fx=0.25, fy=0.25)\n",
        "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "        # 3. Iterate through detected PERSONS from YOLO\n",
        "        for i, (box, conf, cls) in enumerate(zip(self.boxes, self.confs, self.clss)):\n",
        "            if int(cls) != 0:  # Skip if not a person\n",
        "                continue\n",
        "\n",
        "            name = \"Unknown\"\n",
        "            is_known = False\n",
        "            \n",
        "            # 4. Associate faces with person boxes\n",
        "            # Check if any detected face is inside this person's bounding box\n",
        "            person_box_left, person_box_top, person_box_right, person_box_bottom = map(int, box)\n",
        "            \n",
        "            for (face_top, face_right, face_bottom, face_left), face_encoding in zip(face_locations, face_encodings):\n",
        "                # Scale face locations back to original image size\n",
        "                face_top *= 8\n",
        "                face_right *= 8\n",
        "                face_bottom *= 8\n",
        "                face_left *= 8\n",
        "\n",
        "                # Check if the center of the face is inside the person's box\n",
        "                face_center_x = (face_left + face_right) // 2\n",
        "                face_center_y = (face_top + face_bottom) // 2\n",
        "\n",
        "                if (person_box_left <= face_center_x <= person_box_right and\n",
        "                    person_box_top <= face_center_y <= person_box_bottom):\n",
        "                    \n",
        "                    # 5. Use robust face matching for the associated face\n",
        "                    if self.known_face_encodings:\n",
        "                        face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "                        best_match_index = np.argmin(face_distances)\n",
        "                        \n",
        "                        if face_distances[best_match_index] < self.face_tolerance:\n",
        "                            name = self.known_face_names[best_match_index]\n",
        "                            is_known = True\n",
        "                    \n",
        "                    # Once a face is matched to this person, stop checking other faces\n",
        "                    break \n",
        "            \n",
        "            # 6. Update counter and draw labels\n",
        "            if not is_known:\n",
        "                unknown_person_count += 1\n",
        "                color = (0, 0, 255) # Red for Unknown\n",
        "                # label = f\"Unknown ({conf:.2f})\"\n",
        "                label = f\"Unknown (person)\"\n",
        "                # label = f\"person_{int(id)}\"\n",
        "                # custom_string = \"Custom Text: \"\n",
        "                # label = f'{custom_string}{f\"person_{int(id)}\"} {self.names[int(cls)]} {conf:.2f}'\n",
        "                print(\"‚ö†Ô∏è Unknown Person Detected!\")\n",
        "            else:\n",
        "                color = (0, 255, 0) # Green for Known\n",
        "                # label = f\"{name} ({conf:.2f})\"\n",
        "                label = f\"{name}\"\n",
        "                print(f\"‚úÖ Known Person Detected: {name}\")\n",
        "            \n",
        "            # annotator = SolutionAnnotator(plot_im, line_width=self.line_width)\n",
        "            # annotator.box_label.txt_color = self.get_txt_color(self.color, self.txt_color)\n",
        "            # annotator.box_label(box, label, color)\n",
        "            # annotator.box_label\n",
        "                        # ...existing code...\n",
        "            # inside your frame processing loop / FaceRecognitionAlarm.process after you decide color/known status\n",
        "            label_dict = {\n",
        "                \"box\": box,                 # (x1,y1,x2,y2) from detection\n",
        "                \"cls\": int(cls),\n",
        "                \"conf\": float(conf),\n",
        "                \"track_id\": None,           # try prefer self.track_ids mapping below\n",
        "                \"name\": name,               # resolved person name or \"Unknown\"\n",
        "                \"custom_prefix\": \"id:\"      # optional change to \"intruder\", etc.\n",
        "            }\n",
        "\n",
        "            # resolve track_id from solution's track_ids list when available\n",
        "            if hasattr(self, \"track_ids\") and isinstance(self.track_ids, (list, tuple)):\n",
        "                # find corresponding index - i should be available if iterating with enumerate\n",
        "                try:\n",
        "                    label_dict[\"track_id\"] = self.track_ids[i]\n",
        "                except Exception:\n",
        "                    # fallback left to update_labels_info\n",
        "                    pass\n",
        "\n",
        "            # label_dict = update_labels_info(label_dict)\n",
        "            # annotator.box_label(box, label=label_dict[\"display_name\"], color=color)\n",
        "            # annotator.box_label(box, label=label_dict[\"display_name\"])\n",
        "            # ...existing code...\n",
        "            annotator.box_label(box, label, color)\n",
        "            \n",
        "\n",
        "        # 7. Trigger alarm based on the COUNT of unknown people and the 'records' threshold\n",
        "        if unknown_person_count >= self.records:\n",
        "            self.play_sound()\n",
        "        else:\n",
        "            self.reset_sound()\n",
        "\n",
        "        plot_im = annotator.result()\n",
        "        # plot_im = SolutionAnnotator(im0=plot_im, line_width=self.line_width)\n",
        "\n",
        "        \n",
        "        # Display track count on the frame\n",
        "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
        "        cv2.putText(plot_im, f\"Tracks: {total_tracks}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        return SolutionResults(im0=im0, plot_im=plot_im)\n",
        "\n",
        "\n",
        "# ========== üé• MAIN LOOP ==========\n",
        "if __name__ == \"__main__\":\n",
        "    cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    assert cap.isOpened(), \"Error: video not found or cannot be opened.\"\n",
        "\n",
        "    w, h, fps = (int(cap.get(x)) for x in\n",
        "                 (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "    writer = cv2.VideoWriter(\"security_output.avi\",\n",
        "                             cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "       \n",
        "    face_alarm = FaceRecognitionAlarm(\n",
        "        show=True,\n",
        "        model=\"yolo11m.pt\",\n",
        "        records=1,\n",
        "        # classes=[0],  # person\n",
        "        known_face_encodings=known_face_encodings,\n",
        "        known_face_names=known_face_names,\n",
        "        conf=0.3,\n",
        "        iou=0.5,\n",
        "        # persist=True,\n",
        "        # tracker=\"./ultralytics/cfg/trackers/bytetrack.yaml\",\n",
        "    )\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, im0 = cap.read()\n",
        "        if not ret:\n",
        "            print(\"[INFO] Video finished or empty frame.\")\n",
        "            break\n",
        "\n",
        "        results = face_alarm(im0)\n",
        "        # writer.write(results.plot_im)\n",
        "        cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "        # pygame.event.pump()\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    pygame.quit()\n",
        "    print(\"[INFO] Surveillance session ended.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e02a275",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ...existing code...\n",
        "# \"\"\"\n",
        "# Face-recognition aware Security Alarm using Ultralytics solutions (yolo11m-seg.pt or yolo11m.pt).\n",
        "# Includes update_labels_info() and example main loop.\n",
        "# Run: python d:\\Projects\\ultralytics\\security_face_alarm.py\n",
        "# \"\"\"\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import pygame\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "from ultralytics import solutions\n",
        "from ultralytics.solutions.solutions import SolutionAnnotator, SolutionResults\n",
        "from ultralytics.utils.plotting import colors\n",
        "from ultralytics.utils import LOGGER\n",
        "# from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "from ultralytics.engine.results import Results\n",
        "# from ultralytics.utils.plotting import colors\n",
        "\n",
        "# -----------------------\n",
        "# Configuration\n",
        "# -----------------------\n",
        "MODEL = \"yolo11l.pt\"         # set to yolo11m-seg.pt for segmentation support or yolo11m.pt\n",
        "VIDEO_SOURCE = \"./media_files/animal_surveillance/goru-churi.mp4\"\n",
        "# VIDEO_SOURCE = 0              # 0 for webcam, or path to video file\n",
        "KNOWN_FACES_DIR = \"family_members\"   # directory structured as family_members/<name>/*.jpg\n",
        "ALARM_SOUND = \"pols-aagyi-pols.mp3\"\n",
        "FACE_TOLERANCE = 0.55               # lower = stricter\n",
        "RECOGNITION_SCALE = 0.25            # scale for face detection (speed)\n",
        "RECOGNITION_INTERVAL = 5            # run face recognition every N frames\n",
        "RECORDS_THRESHOLD = 3               # number of unknown persons to trigger alarm\n",
        "\n",
        "# -----------------------\n",
        "# Utility: update_labels_info\n",
        "# -----------------------\n",
        "def update_labels_info(label: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Normalize/augment a detection/segmentation label dict for stable display.\n",
        "    Expected keys (optional): box, cls, conf, track_id/id, name/cls_name, custom_prefix.\n",
        "    Adds/ensures: 'track_id' and 'display_name'.\n",
        "    \"\"\"\n",
        "    # track id fallback\n",
        "    track_id = label.get(\"track_id\") or label.get(\"id\") or label.get(\"track\") or None\n",
        "    if track_id is None and label.get(\"box\") is not None:\n",
        "        try:\n",
        "            x1, y1, x2, y2 = map(int, label[\"box\"])\n",
        "            track_id = f\"{(x1 + x2)//2}_{(y1 + y2)//2}\"\n",
        "        except Exception:\n",
        "            track_id = \"0\"\n",
        "\n",
        "    # readable class/name\n",
        "    name = label.get(\"name\") or label.get(\"cls_name\") or \"\"\n",
        "    if not name and label.get(\"cls\") is not None:\n",
        "        cls_val = label.get(\"cls\")\n",
        "        # label may include 'names' externally, user can set label['name'] before calling\n",
        "        name = label.get(\"label\") or f\"class_{int(cls_val)}\"\n",
        "\n",
        "    conf = label.get(\"conf\")\n",
        "    prefix = str(label.get(\"custom_prefix\", \"person\"))\n",
        "\n",
        "    base = name if name else f\"class_{label.get('cls','?')}\"\n",
        "    if conf is not None:\n",
        "        try:\n",
        "            display = f\"{prefix}_{track_id} {base} ({float(conf):.2f})\"\n",
        "        except Exception:\n",
        "            display = f\"{prefix}_{track_id} {base}\"\n",
        "    else:\n",
        "        display = f\"{prefix}_{track_id} {base}\"\n",
        "\n",
        "    label[\"track_id\"] = track_id\n",
        "    label[\"display_name\"] = display\n",
        "    return label\n",
        "\n",
        "# -----------------------\n",
        "# Face recognition loader\n",
        "# -----------------------\n",
        "def load_known_faces(known_dir: str) -> Tuple[List[np.ndarray], List[str]]:\n",
        "    encs: List[np.ndarray] = []\n",
        "    names: List[str] = []\n",
        "    if not os.path.exists(known_dir):\n",
        "        LOGGER.warning(\"Known faces dir '%s' not found.\", known_dir)\n",
        "        return encs, names\n",
        "\n",
        "    for person in os.listdir(known_dir):\n",
        "        person_dir = os.path.join(known_dir, person)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        for fname in os.listdir(person_dir):\n",
        "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                path = os.path.join(person_dir, fname)\n",
        "                try:\n",
        "                    img = face_recognition.load_image_file(path)\n",
        "                    fe = face_recognition.face_encodings(img)\n",
        "                    if fe:\n",
        "                        encs.append(fe[0])\n",
        "                        names.append(person)\n",
        "                        LOGGER.info(\"Loaded face '%s' from %s\", person, fname)\n",
        "                except Exception as e:\n",
        "                    LOGGER.warning(\"Failed load face %s: %s\", path, e)\n",
        "    LOGGER.info(\"Loaded %d face encodings for %d people\", len(encs), len(set(names)))\n",
        "    return encs, names\n",
        "\n",
        "# -----------------------\n",
        "# FaceRecognitionAlarm class\n",
        "# -----------------------\n",
        "class FaceRecognitionAlarm(solutions.SecurityAlarm):\n",
        "    \"\"\"\n",
        "    SecurityAlarm subclass that performs face recognition and updates annotation labels\n",
        "    using update_labels_info(). Triggers alarm sound when unknown person count >= records.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, face_data_path: str = KNOWN_FACES_DIR, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.known_face_encodings, self.known_face_names = load_known_faces(face_data_path)\n",
        "        self.face_tolerance = FACE_TOLERANCE\n",
        "        self.frame_idx = 0\n",
        "        self.recognition_interval = RECOGNITION_INTERVAL\n",
        "        self.sound_played = False\n",
        "        self.show_conf = self.CFG.get(\"show_conf\", True)\n",
        "        self.show_labels = self.CFG.get(\"show_labels\", True)\n",
        "        self.show_boxes = self.CFG.get(\"show_boxes\", True)\n",
        "        # init pygame mixer for alarm sound (optional)\n",
        "        try:\n",
        "            pygame.mixer.init()\n",
        "            if os.path.exists(ALARM_SOUND):\n",
        "                pygame.mixer.music.load(ALARM_SOUND)\n",
        "        except Exception as e:\n",
        "            LOGGER.warning(\"pygame init/load sound failed: %s\", e)\n",
        "\n",
        "    def play_sound(self):\n",
        "        if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "            try:\n",
        "                pygame.mixer.music.play()\n",
        "                self.sound_played = True\n",
        "                LOGGER.info(\"Playing alarm sound\")\n",
        "            except Exception as e:\n",
        "                LOGGER.warning(\"Could not play sound: %s\", e)\n",
        "\n",
        "    def reset_sound(self):\n",
        "        if pygame.mixer.get_init() and pygame.mixer.music.get_busy():\n",
        "            try:\n",
        "                pygame.mixer.music.stop()\n",
        "            except Exception:\n",
        "                pass\n",
        "        self.sound_played = False\n",
        "\n",
        "    def __call__(self, im0):\n",
        "        \"\"\"\n",
        "        Process a frame: extract_tracks (base), run intermittent face detection on a small frame,\n",
        "        associate faces with person boxes, build label_dict for each detection and draw via annotator.\n",
        "        Returns SolutionResults(plot_im=...) similar to base.\n",
        "        \"\"\"\n",
        "        self.frame_idx += 1\n",
        "        # ensure model has run once: extract_tracks populates self.boxes,self.clss,self.confs,self.track_ids\n",
        "        self.extract_tracks(im0)\n",
        "        # self.extract_tracks(im0)\n",
        "        # annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "         # plot_im = annotator.result()\n",
        "        self.masks = getattr(self.tracks[0], \"masks\", None)\n",
        "\n",
        "        # Annotation for segmentation masks\n",
        "        # Iterate over detected classes, track IDs, and segmentation masks\n",
        "        if self.masks is None:\n",
        "            self.LOGGER.warning(\"No masks detected! Ensure you're using a supported Ultralytics segmentation model.\")\n",
        "            plot_im = im0\n",
        "        else:\n",
        "            results = Results(im0, path=None, names=self.names, boxes=self.track_data.data, masks=self.masks.data)\n",
        "            plot_im = results.plot(\n",
        "                line_width=self.line_width,\n",
        "                boxes=self.show_boxes,\n",
        "                conf=self.show_conf,\n",
        "                labels=self.show_labels,\n",
        "                color_mode=\"instance\",\n",
        "            )\n",
        "\n",
        "        annotator = SolutionAnnotator(plot_im, line_width=self.line_width)\n",
        "\n",
        "        # run face detection/encodings on interval\n",
        "        face_locations = []\n",
        "        face_encodings = []\n",
        "        if self.frame_idx % self.recognition_interval == 0:\n",
        "            small = cv2.resize(im0, (0, 0), fx=RECOGNITION_SCALE, fy=RECOGNITION_SCALE)\n",
        "            rgb_small = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
        "            face_locations = face_recognition.face_locations(rgb_small)\n",
        "            face_encodings = face_recognition.face_encodings(rgb_small, face_locations)\n",
        "\n",
        "        unknown_count = 0\n",
        "        person_cls_id = 0  # COCO 'person'\n",
        "\n",
        "        # iterate detections\n",
        "        for i, (box, conf, cls) in enumerate(zip(self.boxes, self.confs, self.clss)):\n",
        "            try:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "            except Exception:\n",
        "                # box may be a tensor or other structure\n",
        "                b = np.array(box).astype(int)\n",
        "                x1, y1, x2, y2 = int(b[0]), int(b[1]), int(b[2]), int(b[3])\n",
        "\n",
        "            label_name = self.names[int(cls)] if hasattr(self, \"names\") else f\"class_{int(cls)}\"\n",
        "            color = colors(int(cls), True)\n",
        "            is_known = False\n",
        "            name = label_name\n",
        "\n",
        "            if int(cls) == person_cls_id and face_encodings:\n",
        "                # find any face whose center lies within the box (scale face locations back)\n",
        "                for (top, right, bottom, left), f_enc in zip(face_locations, face_encodings):\n",
        "                    top *= int(1/RECOGNITION_SCALE)\n",
        "                    right *= int(1/RECOGNITION_SCALE)\n",
        "                    bottom *= int(1/RECOGNITION_SCALE)\n",
        "                    left *= int(1/RECOGNITION_SCALE)\n",
        "                    center_x = (left + right) // 2\n",
        "                    center_y = (top + bottom) // 2\n",
        "                    if x1 <= center_x <= x2 and y1 <= center_y <= y2:\n",
        "                        # compare\n",
        "                        if self.known_face_encodings:\n",
        "                            dists = face_recognition.face_distance(self.known_face_encodings, f_enc)\n",
        "                            best = np.argmin(dists)\n",
        "                            if dists[best] < self.face_tolerance:\n",
        "                                name = self.known_face_names[best]\n",
        "                                is_known = True\n",
        "                                # print(f\"‚úÖ Known face detected: {name} (dist={dists[best]:.2f})\")\n",
        "                                print(f\"‚úÖ Known Person Detected: {name}\")\n",
        "                                color = (0, 255, 0)\n",
        "                                \n",
        "                            else:\n",
        "                                name = \"Unknown\"\n",
        "                                is_known = False\n",
        "                                color = (0, 0, 255)\n",
        "                                # print(f\" ‚ö†Ô∏è Unknown face detected: {name} (dist={dists[best]:.2f})\")\n",
        "                                print(f\"‚ö†Ô∏è Unknown Person Detected!\")\n",
        "                        else:\n",
        "                            name = \"Unknown\"\n",
        "                            is_known = False\n",
        "                            color = (0, 0, 255)\n",
        "                        break\n",
        "                else:\n",
        "                    # no face matched inside box\n",
        "                    name = f\"{label_name} (No Face)\"\n",
        "                    color = colors(int(cls), True)\n",
        "\n",
        "            # build label dict and draw using update_labels_info\n",
        "            label_dict = {\n",
        "                \"box\": [x1, y1, x2, y2],\n",
        "                \"cls\": int(cls),\n",
        "                \"conf\": float(conf) if conf is not None else None,\n",
        "                \"track_id\": None,\n",
        "                \"name\": name,\n",
        "                \"colors\":color,\n",
        "                \"custom_prefix\": \"ID:\" if int(cls) == person_cls_id else label_name,\n",
        "            }\n",
        "\n",
        "            # resolve track id if available\n",
        "            if hasattr(self, \"track_ids\") and isinstance(self.track_ids, (list, tuple)):\n",
        "                try:\n",
        "                    label_dict[\"track_id\"] = self.track_ids[i]\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            label_dict = update_labels_info(label_dict)\n",
        "            annotator.box_label(label_dict[\"box\"], label=label_dict[\"display_name\"], color=colors(cls, True))\n",
        "            # annotator.box_label(label_dict[\"box\"], label=self.names[cls], color=colors(cls, True))\n",
        "\n",
        "            if int(cls) == person_cls_id and not is_known:\n",
        "                unknown_count += 1\n",
        "\n",
        "        # alarm control\n",
        "        if unknown_count >= self.records:\n",
        "            if not self.sound_played:\n",
        "                self.play_sound()\n",
        "        else:\n",
        "            if self.sound_played:\n",
        "                self.reset_sound()\n",
        "\n",
        "        plot_im = annotator.result()\n",
        "        # draw track count\n",
        "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
        "        cv2.putText(plot_im, f\"Tracks: {total_tracks}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
        "\n",
        "        return SolutionResults(im0=im0, plot_im=plot_im)\n",
        "\n",
        "# -----------------------\n",
        "# Main\n",
        "# -----------------------\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "    assert cap.isOpened(), f\"Cannot open video source: {VIDEO_SOURCE}\"\n",
        "\n",
        "    # create instance\n",
        "    alarm = FaceRecognitionAlarm(\n",
        "        face_data_path=KNOWN_FACES_DIR,\n",
        "        show=True,\n",
        "        model=MODEL,\n",
        "        records=RECORDS_THRESHOLD,\n",
        "        # classes=[0],   # person only\n",
        "        conf=0.3,\n",
        "        # iou=0.5,\n",
        "    )\n",
        "\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 20.0\n",
        "    out = cv2.VideoWriter(\"security_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "    print(\"Starting surveillance. Press q to quit.\")\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            results = alarm(frame)\n",
        "            plot = results.plot_im if hasattr(results, \"plot_im\") else frame\n",
        "            out.write(plot)\n",
        "            cv2.imshow(\"Security\", plot)\n",
        "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        try:\n",
        "            pygame.mixer.quit()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "# ...existing code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1c30c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================== üõ°Ô∏è AI SURVEILLANCE GUARD APP ==========================\n",
        "# Real-time Security System using YOLO + Face Recognition + Email Alert + Alarm\n",
        "# Author: Rahat Ansari | 2025 | Open Source for Educational Use\n",
        "# ===============================================================================\n",
        "\n",
        "# ---------- Imports ----------\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import smtplib\n",
        "import time\n",
        "import pygame\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "from deepface import DeepFace\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "FAMILY_DIR = \"family_members\"\n",
        "YOLO_MODEL_PATH = \"yolo11m.pt\"  # or yolov8s.pt for better accuracy\n",
        "ALARM_SOUND_PATH = \"pols-aagyi-pols.mp3\" # Place a simple alarm sound file\n",
        "EMAIL_SENDER = \"your_email@gmail.com\"\n",
        "EMAIL_PASSWORD = \"your_app_password\"\n",
        "EMAIL_RECEIVER = \"receiver_email@gmail.com\"\n",
        "\n",
        "# Initialize YOLO\n",
        "model = YOLO(YOLO_MODEL_PATH)\n",
        "\n",
        "# Initialize Alarm\n",
        "pygame.mixer.init()\n",
        "def play_alarm():\n",
        "    pygame.mixer.music.load(ALARM_SOUND_PATH)\n",
        "    pygame.mixer.music.play()\n",
        "\n",
        "# ---------- Helper Functions ----------\n",
        "def send_email_alert(image_path, subject=\"üö® Security Alert! Unauthorized Person Detected\"):\n",
        "    \"\"\"Send email with image attachment when intruder detected.\"\"\"\n",
        "    try:\n",
        "        msg = MIMEMultipart()\n",
        "        msg[\"From\"] = EMAIL_SENDER\n",
        "        msg[\"To\"] = EMAIL_RECEIVER\n",
        "        msg[\"Subject\"] = subject\n",
        "\n",
        "        body = \"An unauthorized person was detected.\\nSee attached snapshot for details.\"\n",
        "        msg.attach(MIMEText(body, \"plain\"))\n",
        "\n",
        "        with open(image_path, \"rb\") as attachment:\n",
        "            part = MIMEBase(\"application\", \"octet-stream\")\n",
        "            part.set_payload(attachment.read())\n",
        "        encoders.encode_base64(part)\n",
        "        part.add_header(\"Content-Disposition\", f\"attachment; filename={os.path.basename(image_path)}\")\n",
        "        msg.attach(part)\n",
        "\n",
        "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "            server.login(EMAIL_SENDER, EMAIL_PASSWORD)\n",
        "            server.sendmail(EMAIL_SENDER, EMAIL_RECEIVER, msg.as_string())\n",
        "        print(\"üìß Email alert sent successfully!\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Email sending failed:\", e)\n",
        "\n",
        "def is_authorized_face(frame):\n",
        "    \"\"\"Check if face matches any authorized family member.\"\"\"\n",
        "    for member in os.listdir(FAMILY_DIR):\n",
        "        member_path = os.path.join(FAMILY_DIR, member)\n",
        "        if not os.path.isdir(member_path):\n",
        "            continue\n",
        "        for img_name in os.listdir(member_path):\n",
        "            ref_path = os.path.join(member_path, img_name)\n",
        "            try:\n",
        "                result = DeepFace.verify(frame, ref_path, model_name=\"Facenet\", enforce_detection=False)\n",
        "                if result[\"verified\"]:\n",
        "                    return member  # Authorized person found\n",
        "            except Exception:\n",
        "                continue\n",
        "    return None\n",
        "\n",
        "def log_event(event_type, name=\"Unknown\"):\n",
        "    \"\"\"Log detection events.\"\"\"\n",
        "    with open(\"event_log.txt\", \"a\") as log:\n",
        "        log.write(f\"[{datetime.now()}] {event_type}: {name}\\n\")\n",
        "\n",
        "# ---------- Main Surveillance ----------\n",
        "def start_surveillance():\n",
        "    print(\"üöÄ Starting AI Surveillance System...\")\n",
        "    cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    unauthorized_detected = False\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run YOLO Detection\n",
        "        results = model(frame)\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                cls = int(box.cls[0])\n",
        "                label = model.names[cls]\n",
        "                if label == \"person\":\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    person_crop = frame[y1:y2, x1:x2]\n",
        "\n",
        "                    name = is_authorized_face(person_crop)\n",
        "                    if name:\n",
        "                        cv2.putText(frame, f\"Authorized: {name}\", (x1, y1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "                        unauthorized_detected = False\n",
        "                    else:\n",
        "                        cv2.putText(frame, \"Unauthorized!\", (x1, y1 - 10),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "                        if not unauthorized_detected:\n",
        "                            unauthorized_detected = True\n",
        "                            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                            image_path = f\"intruder_{timestamp}.jpg\"\n",
        "                            # cv2.imwrite(image_path, frame)\n",
        "                            play_alarm()\n",
        "                            # send_email_alert(image_path)\n",
        "                            log_event(\"Unauthorized Person Detected\")\n",
        "\n",
        "        cv2.imshow(\"AI Security Guard\", frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# ---------- Run the App ----------\n",
        "if __name__ == \"__main__\":\n",
        "    start_surveillance()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473597ca",
      "metadata": {},
      "source": [
        "# Vision Eye is an AI-powered surveillance solution that leverages advanced computer vision techniques to monitor and analyze video feeds in real-time. It is designed to enhance security and safety in various environments, such as homes, offices, and public spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3261a21",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "from ultralytics import solutions\n",
        "\n",
        "cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "# cap = cv2.VideoCapture(\"media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Video writer\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "video_writer = cv2.VideoWriter(\"visioneye_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# Initialize vision eye object\n",
        "visioneye = solutions.VisionEye(\n",
        "    show=True,  # display the output\n",
        "    model=\"yolo11m.pt\",  # use any model that Ultralytics support, i.e, YOLOv10\n",
        "    # classes=[0, 19],  # generate visioneye view for specific classes\n",
        "    vision_point=(50, 50), # the point, where vision will view objects and draw tracks\n",
        "    records=3,\n",
        "    conf=0.5,\n",
        ")\n",
        "\n",
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    results = visioneye(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    # video_writer.write(results.plot_im)  # write the video file\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()  # destroy all opened windows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c54987",
      "metadata": {},
      "source": [
        "trying with vision eye"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4b7ac5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "[INFO] Loaded face for robin from image1.jpg\n",
            "Ultralytics Solutions:  {'source': None, 'model': 'yolo11m.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': None, 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (50, 50), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 2, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.5, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n",
            "\n",
            "0: 384x640 5 cows, 65.9ms\n",
            "Speed: 2.3ms preprocess, 65.9ms inference, 126.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 26.6ms\n",
            "Speed: 2.2ms preprocess, 26.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.5ms\n",
            "Speed: 2.1ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.8ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.4ms\n",
            "Speed: 1.5ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 26.1ms\n",
            "Speed: 1.6ms preprocess, 26.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 26.5ms\n",
            "Speed: 1.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 26.7ms\n",
            "Speed: 1.6ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 2.7ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 6 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 5 cows, 23.9ms\n",
            "Speed: 2.2ms preprocess, 23.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 6 cows, 23.9ms\n",
            "Speed: 1.4ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 6 cows, 23.5ms\n",
            "Speed: 2.7ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 7 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 5 cows, 25.5ms\n",
            "Speed: 1.9ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 22.9ms\n",
            "Speed: 1.6ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 25.0ms\n",
            "Speed: 2.3ms preprocess, 25.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 24.2ms\n",
            "Speed: 1.8ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 26.5ms\n",
            "Speed: 2.2ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.8ms\n",
            "Speed: 3.7ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.1ms\n",
            "Speed: 1.7ms preprocess, 23.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 6 cows, 23.2ms\n",
            "Speed: 3.1ms preprocess, 23.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 6 cows, 25.5ms\n",
            "Speed: 2.1ms preprocess, 25.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 22.4ms\n",
            "Speed: 1.5ms preprocess, 22.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.1ms\n",
            "Speed: 2.1ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.3ms\n",
            "Speed: 1.6ms preprocess, 24.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.1ms\n",
            "Speed: 1.8ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 23.5ms\n",
            "Speed: 1.5ms preprocess, 23.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 23.9ms\n",
            "Speed: 1.4ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.9ms\n",
            "Speed: 2.1ms preprocess, 23.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.4ms preprocess, 23.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.1ms\n",
            "Speed: 2.2ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.1ms\n",
            "Speed: 1.9ms preprocess, 23.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.2ms\n",
            "Speed: 1.6ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 2.3ms preprocess, 23.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.9ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 22.4ms\n",
            "Speed: 1.8ms preprocess, 22.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 23.1ms\n",
            "Speed: 1.5ms preprocess, 23.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 2.0ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 22.5ms\n",
            "Speed: 1.6ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.1ms\n",
            "Speed: 1.5ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.7ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.9ms preprocess, 23.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.1ms\n",
            "Speed: 1.7ms preprocess, 23.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.4ms preprocess, 23.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 22.1ms\n",
            "Speed: 1.6ms preprocess, 22.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.7ms\n",
            "Speed: 1.5ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.2ms\n",
            "Speed: 1.6ms preprocess, 23.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.3ms\n",
            "Speed: 1.6ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.7ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 2.3ms preprocess, 23.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 22.5ms\n",
            "Speed: 1.9ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.8ms preprocess, 23.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.4ms\n",
            "Speed: 2.3ms preprocess, 24.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.0ms\n",
            "Speed: 1.7ms preprocess, 24.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 27.0ms\n",
            "Speed: 2.0ms preprocess, 27.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.7ms\n",
            "Speed: 1.7ms preprocess, 23.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.1ms\n",
            "Speed: 2.1ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.0ms\n",
            "Speed: 2.3ms preprocess, 23.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 2.0ms preprocess, 23.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.7ms\n",
            "Speed: 1.5ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 2.6ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 25.6ms\n",
            "Speed: 2.4ms preprocess, 25.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 26.3ms\n",
            "Speed: 2.1ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 5 cows, 23.7ms\n",
            "Speed: 1.9ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 2.3ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.7ms\n",
            "Speed: 1.5ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.5ms\n",
            "Speed: 2.3ms preprocess, 26.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 27.1ms\n",
            "Speed: 2.1ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 2.3ms preprocess, 24.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 2.4ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.0ms\n",
            "Speed: 1.8ms preprocess, 24.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.5ms\n",
            "Speed: 1.5ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.6ms\n",
            "Speed: 2.4ms preprocess, 25.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.9ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.4ms\n",
            "Speed: 1.8ms preprocess, 25.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 2.0ms preprocess, 24.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 2.4ms preprocess, 24.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.9ms\n",
            "Speed: 2.6ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 26.3ms\n",
            "Speed: 1.8ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 26.6ms\n",
            "Speed: 1.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.8ms\n",
            "Speed: 2.4ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 5 cows, 24.0ms\n",
            "Speed: 1.9ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.6ms\n",
            "Speed: 1.9ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.9ms\n",
            "Speed: 1.9ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.5ms preprocess, 23.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.5ms\n",
            "Speed: 2.2ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 25.3ms\n",
            "Speed: 1.8ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.5ms\n",
            "Speed: 1.8ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.5ms\n",
            "Speed: 1.6ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.9ms\n",
            "Speed: 2.2ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 23.4ms\n",
            "Speed: 1.6ms preprocess, 23.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.6ms\n",
            "Speed: 2.3ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 25.4ms\n",
            "Speed: 1.6ms preprocess, 25.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.2ms\n",
            "Speed: 1.7ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 6 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 5 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 25.4ms\n",
            "Speed: 1.5ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 6 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 5 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 26.4ms\n",
            "Speed: 1.4ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 24.3ms\n",
            "Speed: 1.4ms preprocess, 24.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.9ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.6ms\n",
            "Speed: 1.7ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.4ms\n",
            "Speed: 2.1ms preprocess, 25.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 26.3ms\n",
            "Speed: 2.0ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 2.6ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.9ms\n",
            "Speed: 1.8ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.0ms\n",
            "Speed: 2.3ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 2.4ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.9ms\n",
            "Speed: 2.7ms preprocess, 26.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 2.8ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.6ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.7ms\n",
            "Speed: 2.2ms preprocess, 23.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.5ms\n",
            "Speed: 2.3ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.3ms\n",
            "Speed: 1.7ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.0ms\n",
            "Speed: 1.4ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.6ms preprocess, 24.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 2.2ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.3ms\n",
            "Speed: 1.5ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.9ms preprocess, 24.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.9ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.1ms\n",
            "Speed: 1.4ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 1.7ms preprocess, 24.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.3ms\n",
            "Speed: 2.0ms preprocess, 25.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.1ms\n",
            "Speed: 2.0ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.8ms\n",
            "Speed: 1.5ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 2.3ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.6ms preprocess, 24.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.5ms preprocess, 25.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 25.4ms\n",
            "Speed: 1.6ms preprocess, 25.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 1.9ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.4ms\n",
            "Speed: 2.0ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.5ms\n",
            "Speed: 1.6ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.2ms\n",
            "Speed: 2.2ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.4ms\n",
            "Speed: 1.7ms preprocess, 24.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 5 cows, 24.5ms\n",
            "Speed: 1.7ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 25.6ms\n",
            "Speed: 1.7ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 1.7ms preprocess, 24.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 26.1ms\n",
            "Speed: 1.7ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 5 cows, 23.8ms\n",
            "Speed: 2.9ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 2.1ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.7ms\n",
            "Speed: 1.5ms preprocess, 23.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.1ms\n",
            "Speed: 1.4ms preprocess, 24.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.7ms\n",
            "Speed: 2.1ms preprocess, 24.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.5ms\n",
            "Speed: 1.5ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.4ms\n",
            "Speed: 1.6ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 25.4ms\n",
            "Speed: 1.8ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.9ms\n",
            "Speed: 2.3ms preprocess, 26.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.2ms\n",
            "Speed: 1.8ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.9ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 1.8ms preprocess, 24.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.7ms\n",
            "Speed: 1.9ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.3ms\n",
            "Speed: 2.5ms preprocess, 26.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.6ms\n",
            "Speed: 1.9ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 26.3ms\n",
            "Speed: 1.6ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 25.2ms\n",
            "Speed: 2.3ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.5ms\n",
            "Speed: 1.8ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 (no detections), 24.3ms\n",
            "Speed: 1.6ms preprocess, 24.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 26.2ms\n",
            "Speed: 1.6ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 3 cows, 23.1ms\n",
            "Speed: 1.7ms preprocess, 23.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.4ms\n",
            "Speed: 1.9ms preprocess, 23.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 1.8ms preprocess, 24.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.4ms\n",
            "Speed: 1.5ms preprocess, 23.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 1.7ms preprocess, 24.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 (no detections), 22.3ms\n",
            "Speed: 1.5ms preprocess, 22.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.9ms\n",
            "Speed: 2.4ms preprocess, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.7ms\n",
            "Speed: 3.0ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.4ms\n",
            "Speed: 2.1ms preprocess, 22.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.9ms\n",
            "Speed: 1.8ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.2ms\n",
            "Speed: 1.9ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 23.2ms\n",
            "Speed: 1.5ms preprocess, 23.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 23.1ms\n",
            "Speed: 2.3ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 22.7ms\n",
            "Speed: 1.7ms preprocess, 22.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 23.3ms\n",
            "Speed: 1.9ms preprocess, 23.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 (no detections), 23.2ms\n",
            "Speed: 1.4ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 21.9ms\n",
            "Speed: 1.6ms preprocess, 21.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 1.6ms preprocess, 23.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.7ms\n",
            "Speed: 2.0ms preprocess, 22.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 3 cows, 22.3ms\n",
            "Speed: 1.9ms preprocess, 22.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 22.0ms\n",
            "Speed: 1.5ms preprocess, 22.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.4ms\n",
            "Speed: 1.6ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.5ms\n",
            "Speed: 3.0ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 22.8ms\n",
            "Speed: 1.6ms preprocess, 22.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 22.7ms\n",
            "Speed: 1.9ms preprocess, 22.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 22.2ms\n",
            "Speed: 1.7ms preprocess, 22.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 22.7ms\n",
            "Speed: 1.6ms preprocess, 22.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 21.6ms\n",
            "Speed: 1.7ms preprocess, 21.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.8ms\n",
            "Speed: 1.5ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 2.9ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.3ms\n",
            "Speed: 2.4ms preprocess, 25.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.8ms\n",
            "Speed: 2.1ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.1ms\n",
            "Speed: 1.5ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.9ms\n",
            "Speed: 1.7ms preprocess, 23.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.7ms\n",
            "Speed: 2.0ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 1.9ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.8ms preprocess, 23.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.9ms\n",
            "Speed: 2.7ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 2.1ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.7ms\n",
            "Speed: 2.1ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 1.6ms preprocess, 24.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.9ms preprocess, 23.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.9ms preprocess, 23.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 2.0ms preprocess, 25.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 2.2ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 26.9ms\n",
            "Speed: 1.4ms preprocess, 26.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.7ms\n",
            "Speed: 2.0ms preprocess, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 21.9ms\n",
            "Speed: 1.4ms preprocess, 21.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.0ms\n",
            "Speed: 2.1ms preprocess, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.3ms\n",
            "Speed: 1.7ms preprocess, 23.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.4ms\n",
            "Speed: 1.7ms preprocess, 22.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 21.6ms\n",
            "Speed: 1.7ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.1ms\n",
            "Speed: 1.8ms preprocess, 22.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.3ms\n",
            "Speed: 1.6ms preprocess, 22.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.4ms\n",
            "Speed: 2.2ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 20.9ms\n",
            "Speed: 1.7ms preprocess, 20.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 20.9ms\n",
            "Speed: 2.5ms preprocess, 20.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.0ms\n",
            "Speed: 1.9ms preprocess, 22.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 21.5ms\n",
            "Speed: 1.6ms preprocess, 21.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 21.8ms\n",
            "Speed: 1.6ms preprocess, 21.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 20.7ms\n",
            "Speed: 1.5ms preprocess, 20.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 20.7ms\n",
            "Speed: 1.6ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 20.8ms\n",
            "Speed: 2.4ms preprocess, 20.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 20.9ms\n",
            "Speed: 2.0ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 22.8ms\n",
            "Speed: 1.4ms preprocess, 22.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 20.6ms\n",
            "Speed: 1.8ms preprocess, 20.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 20.8ms\n",
            "Speed: 1.7ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 21.3ms\n",
            "Speed: 1.3ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 cow, 20.7ms\n",
            "Speed: 1.6ms preprocess, 20.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 21.8ms\n",
            "Speed: 1.5ms preprocess, 21.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 21.4ms\n",
            "Speed: 1.6ms preprocess, 21.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 21.8ms\n",
            "Speed: 1.7ms preprocess, 21.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 20.9ms\n",
            "Speed: 1.9ms preprocess, 20.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 20.6ms\n",
            "Speed: 1.9ms preprocess, 20.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 horse, 1 cow, 21.9ms\n",
            "Speed: 1.6ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 horse, 22.6ms\n",
            "Speed: 1.4ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 2 cows, 22.5ms\n",
            "Speed: 1.4ms preprocess, 22.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.0ms\n",
            "Speed: 1.4ms preprocess, 23.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 22.8ms\n",
            "Speed: 1.5ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.0ms\n",
            "Speed: 1.7ms preprocess, 26.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 24.2ms\n",
            "Speed: 2.0ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 (no detections), 26.2ms\n",
            "Speed: 1.6ms preprocess, 26.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.0ms\n",
            "Speed: 1.4ms preprocess, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.4ms\n",
            "Speed: 2.2ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 22.9ms\n",
            "Speed: 2.2ms preprocess, 22.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.2ms\n",
            "Speed: 1.7ms preprocess, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 22.1ms\n",
            "Speed: 1.7ms preprocess, 22.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 23.1ms\n",
            "Speed: 1.6ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 2 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 22.6ms\n",
            "Speed: 1.7ms preprocess, 22.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.2ms\n",
            "Speed: 2.0ms preprocess, 23.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 21.8ms\n",
            "Speed: 1.5ms preprocess, 21.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 21.9ms\n",
            "Speed: 1.7ms preprocess, 21.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 21.9ms\n",
            "Speed: 1.7ms preprocess, 21.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.9ms\n",
            "Speed: 1.9ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 22.8ms\n",
            "Speed: 1.5ms preprocess, 22.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.5ms\n",
            "Speed: 1.3ms preprocess, 23.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 22.3ms\n",
            "Speed: 1.7ms preprocess, 22.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.0ms\n",
            "Speed: 2.7ms preprocess, 23.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 21.9ms\n",
            "Speed: 1.9ms preprocess, 21.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.3ms\n",
            "Speed: 2.4ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.0ms\n",
            "Speed: 2.6ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.4ms\n",
            "Speed: 2.3ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.9ms\n",
            "Speed: 1.4ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.0ms\n",
            "Speed: 1.8ms preprocess, 25.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 25.1ms\n",
            "Speed: 1.4ms preprocess, 25.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 27.2ms\n",
            "Speed: 3.2ms preprocess, 27.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.3ms\n",
            "Speed: 2.3ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.2ms\n",
            "Speed: 1.5ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.4ms\n",
            "Speed: 1.4ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.5ms\n",
            "Speed: 2.5ms preprocess, 23.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.8ms\n",
            "Speed: 1.4ms preprocess, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.0ms\n",
            "Speed: 2.2ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 24.9ms\n",
            "Speed: 1.9ms preprocess, 24.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.3ms\n",
            "Speed: 1.4ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 23.5ms\n",
            "Speed: 2.0ms preprocess, 23.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 23.9ms\n",
            "Speed: 2.0ms preprocess, 23.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.1ms\n",
            "Speed: 1.7ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.8ms\n",
            "Speed: 2.5ms preprocess, 23.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.3ms\n",
            "Speed: 1.7ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.3ms\n",
            "Speed: 1.6ms preprocess, 24.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.3ms\n",
            "Speed: 1.9ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 cow, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 23.8ms\n",
            "Speed: 2.1ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 2 cows, 23.5ms\n",
            "Speed: 2.0ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 cow, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 cow, 25.6ms\n",
            "Speed: 1.7ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 3 cows, 23.9ms\n",
            "Speed: 2.2ms preprocess, 23.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 23.0ms\n",
            "Speed: 1.5ms preprocess, 23.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 26.7ms\n",
            "Speed: 1.8ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 27.3ms\n",
            "Speed: 1.9ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.6ms\n",
            "Speed: 3.0ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.0ms\n",
            "Speed: 1.7ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.7ms\n",
            "Speed: 2.1ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.4ms\n",
            "Speed: 1.8ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.7ms\n",
            "Speed: 2.1ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.4ms\n",
            "Speed: 1.5ms preprocess, 25.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 1.3ms preprocess, 24.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 5 cows, 25.0ms\n",
            "Speed: 1.3ms preprocess, 25.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.7ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.5ms\n",
            "Speed: 2.4ms preprocess, 23.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.4ms\n",
            "Speed: 2.1ms preprocess, 24.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 25.3ms\n",
            "Speed: 1.6ms preprocess, 25.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.5ms\n",
            "Speed: 1.4ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.6ms\n",
            "Speed: 1.5ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.6ms\n",
            "Speed: 2.0ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 cow, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 23.5ms\n",
            "Speed: 2.2ms preprocess, 23.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 person, 1 cow, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 1 cow, 23.5ms\n",
            "Speed: 1.8ms preprocess, 23.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 26.0ms\n",
            "Speed: 1.7ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.2ms\n",
            "Speed: 1.4ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.4ms\n",
            "Speed: 1.4ms preprocess, 24.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.5ms\n",
            "Speed: 1.9ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.2ms\n",
            "Speed: 1.7ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.8ms\n",
            "Speed: 1.4ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.9ms\n",
            "Speed: 1.4ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.4ms preprocess, 24.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.4ms\n",
            "Speed: 2.0ms preprocess, 25.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.1ms\n",
            "Speed: 2.3ms preprocess, 24.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.6ms\n",
            "Speed: 1.8ms preprocess, 23.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.8ms\n",
            "Speed: 1.4ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.0ms\n",
            "Speed: 2.3ms preprocess, 26.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.4ms\n",
            "Speed: 2.3ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.3ms\n",
            "Speed: 1.7ms preprocess, 25.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 2.0ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.2ms\n",
            "Speed: 1.5ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.9ms\n",
            "Speed: 1.6ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.1ms\n",
            "Speed: 2.6ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.8ms\n",
            "Speed: 1.4ms preprocess, 24.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 2.4ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 2.6ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.7ms\n",
            "Speed: 1.3ms preprocess, 23.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.0ms\n",
            "Speed: 1.4ms preprocess, 24.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.3ms\n",
            "Speed: 1.6ms preprocess, 24.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 2.4ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.6ms\n",
            "Speed: 3.0ms preprocess, 26.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.5ms\n",
            "Speed: 2.0ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.6ms\n",
            "Speed: 1.6ms preprocess, 24.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 1.3ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.4ms\n",
            "Speed: 1.6ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.4ms\n",
            "Speed: 1.5ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.1ms\n",
            "Speed: 2.4ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.7ms\n",
            "Speed: 1.9ms preprocess, 25.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.7ms\n",
            "Speed: 2.2ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.9ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.0ms\n",
            "Speed: 1.7ms preprocess, 24.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.0ms\n",
            "Speed: 2.9ms preprocess, 27.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.1ms\n",
            "Speed: 1.9ms preprocess, 24.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.1ms\n",
            "Speed: 1.9ms preprocess, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.4ms\n",
            "Speed: 1.7ms preprocess, 23.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.7ms\n",
            "Speed: 2.1ms preprocess, 24.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.6ms\n",
            "Speed: 1.9ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.8ms\n",
            "Speed: 2.2ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 bird, 2 cows, 24.8ms\n",
            "Speed: 3.9ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 bird, 2 cows, 24.3ms\n",
            "Speed: 1.8ms preprocess, 24.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.2ms\n",
            "Speed: 1.6ms preprocess, 26.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.3ms\n",
            "Speed: 1.6ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 2.8ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 1.4ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.5ms\n",
            "Speed: 1.8ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.1ms\n",
            "Speed: 2.1ms preprocess, 26.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.1ms\n",
            "Speed: 1.9ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.6ms\n",
            "Speed: 1.8ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.7ms\n",
            "Speed: 2.3ms preprocess, 23.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.8ms\n",
            "Speed: 2.3ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 25.4ms\n",
            "Speed: 2.4ms preprocess, 25.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 1.4ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 4 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 cows, 25.6ms\n",
            "Speed: 1.6ms preprocess, 25.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 25.7ms\n",
            "Speed: 1.6ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.3ms\n",
            "Speed: 1.5ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 24.8ms\n",
            "Speed: 2.2ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 4 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 23.4ms\n",
            "Speed: 1.5ms preprocess, 23.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 cows, 24.0ms\n",
            "Speed: 1.4ms preprocess, 24.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 24.5ms\n",
            "Speed: 2.2ms preprocess, 24.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 26.4ms\n",
            "Speed: 1.8ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.7ms\n",
            "Speed: 2.0ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.3ms\n",
            "Speed: 1.4ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 4 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.1ms\n",
            "Speed: 1.6ms preprocess, 26.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.6ms\n",
            "Speed: 2.2ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.0ms\n",
            "Speed: 2.1ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.9ms\n",
            "Speed: 2.2ms preprocess, 24.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.9ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.3ms\n",
            "Speed: 1.9ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.3ms\n",
            "Speed: 1.4ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.5ms\n",
            "Speed: 1.6ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.4ms\n",
            "Speed: 1.5ms preprocess, 23.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.2ms\n",
            "Speed: 1.7ms preprocess, 24.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.5ms\n",
            "Speed: 1.4ms preprocess, 23.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 1.4ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.7ms\n",
            "Speed: 2.4ms preprocess, 24.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.2ms\n",
            "Speed: 2.0ms preprocess, 26.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.0ms\n",
            "Speed: 1.7ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.3ms\n",
            "Speed: 1.7ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 2.5ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 2.4ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 2.5ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.2ms\n",
            "Speed: 1.9ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 2.2ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.7ms\n",
            "Speed: 1.5ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.2ms\n",
            "Speed: 1.6ms preprocess, 24.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 24.9ms\n",
            "Speed: 1.9ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 25.7ms\n",
            "Speed: 2.1ms preprocess, 25.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 25.9ms\n",
            "Speed: 2.5ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.1ms\n",
            "Speed: 1.4ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.9ms\n",
            "Speed: 2.8ms preprocess, 24.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 24.5ms\n",
            "Speed: 1.8ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 25.6ms\n",
            "Speed: 1.6ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.8ms\n",
            "Speed: 1.4ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.1ms\n",
            "Speed: 1.5ms preprocess, 25.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 5 cows, 26.1ms\n",
            "Speed: 1.4ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.6ms\n",
            "Speed: 1.6ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.2ms\n",
            "Speed: 1.6ms preprocess, 26.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.4ms\n",
            "Speed: 1.5ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.5ms\n",
            "Speed: 1.6ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 26.7ms\n",
            "Speed: 1.7ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 5 cows, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=7)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.7ms\n",
            "Speed: 1.4ms preprocess, 24.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 26.2ms\n",
            "Speed: 2.0ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.3ms\n",
            "Speed: 2.2ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 23.7ms\n",
            "Speed: 1.8ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.9ms\n",
            "Speed: 1.6ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.3ms\n",
            "Speed: 2.0ms preprocess, 24.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.4ms\n",
            "Speed: 1.9ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.3ms\n",
            "Speed: 1.7ms preprocess, 25.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.5ms\n",
            "Speed: 1.7ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.7ms\n",
            "Speed: 1.4ms preprocess, 25.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.0ms\n",
            "Speed: 1.6ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 1.7ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.0ms\n",
            "Speed: 2.1ms preprocess, 23.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.5ms\n",
            "Speed: 2.0ms preprocess, 23.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.0ms\n",
            "Speed: 1.8ms preprocess, 24.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.1ms\n",
            "Speed: 1.6ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 23.4ms\n",
            "Speed: 1.4ms preprocess, 23.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.8ms\n",
            "Speed: 2.3ms preprocess, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.6ms\n",
            "Speed: 1.8ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.0ms\n",
            "Speed: 2.1ms preprocess, 25.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.3ms\n",
            "Speed: 2.9ms preprocess, 26.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.8ms\n",
            "Speed: 1.9ms preprocess, 23.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 1.4ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.7ms\n",
            "Speed: 1.4ms preprocess, 24.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.4ms\n",
            "Speed: 1.7ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.1ms\n",
            "Speed: 1.4ms preprocess, 24.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 1.7ms preprocess, 24.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 2.2ms preprocess, 25.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 2.0ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.0ms\n",
            "Speed: 1.5ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.1ms\n",
            "Speed: 1.8ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 2.2ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.7ms\n",
            "Speed: 2.5ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.7ms\n",
            "Speed: 2.7ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.8ms\n",
            "Speed: 1.5ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.4ms\n",
            "Speed: 1.8ms preprocess, 24.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.6ms\n",
            "Speed: 1.5ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 24.5ms\n",
            "Speed: 2.1ms preprocess, 24.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.7ms\n",
            "Speed: 1.4ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.8ms\n",
            "Speed: 1.5ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.6ms\n",
            "Speed: 1.8ms preprocess, 23.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.5ms\n",
            "Speed: 1.4ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.5ms\n",
            "Speed: 1.4ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.3ms\n",
            "Speed: 1.3ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 1.6ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.3ms\n",
            "Speed: 1.8ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 24.9ms\n",
            "Speed: 3.0ms preprocess, 24.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.1ms\n",
            "Speed: 1.7ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.3ms\n",
            "Speed: 2.0ms preprocess, 25.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 25.2ms\n",
            "Speed: 2.1ms preprocess, 25.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.8ms\n",
            "Speed: 1.5ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.9ms\n",
            "Speed: 2.2ms preprocess, 23.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.3ms\n",
            "Speed: 2.3ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.3ms\n",
            "Speed: 1.4ms preprocess, 23.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 24.7ms\n",
            "Speed: 2.3ms preprocess, 24.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.6ms\n",
            "Speed: 2.3ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.3ms\n",
            "Speed: 1.4ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.6ms\n",
            "Speed: 1.4ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 2.2ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.7ms\n",
            "Speed: 1.6ms preprocess, 26.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.0ms\n",
            "Speed: 1.4ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.3ms\n",
            "Speed: 1.6ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.4ms preprocess, 25.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 1.9ms preprocess, 25.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.0ms\n",
            "Speed: 1.5ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.5ms\n",
            "Speed: 2.3ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.8ms\n",
            "Speed: 2.4ms preprocess, 23.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.9ms\n",
            "Speed: 1.9ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.5ms\n",
            "Speed: 1.3ms preprocess, 25.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.7ms\n",
            "Speed: 1.9ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.0ms\n",
            "Speed: 1.5ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.2ms\n",
            "Speed: 2.3ms preprocess, 25.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.8ms\n",
            "Speed: 1.5ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.1ms\n",
            "Speed: 1.6ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 26.1ms\n",
            "Speed: 1.6ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.9ms\n",
            "Speed: 2.4ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.7ms\n",
            "Speed: 2.0ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.7ms\n",
            "Speed: 2.0ms preprocess, 23.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.7ms\n",
            "Speed: 2.3ms preprocess, 23.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 27.2ms\n",
            "Speed: 2.7ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.6ms\n",
            "Speed: 1.7ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.3ms\n",
            "Speed: 2.3ms preprocess, 26.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 27.8ms\n",
            "Speed: 2.4ms preprocess, 27.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 27.4ms\n",
            "Speed: 3.1ms preprocess, 27.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.8ms\n",
            "Speed: 1.9ms preprocess, 26.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 23.8ms\n",
            "Speed: 2.7ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.5ms\n",
            "Speed: 2.4ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.0ms\n",
            "Speed: 2.3ms preprocess, 26.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 24.6ms\n",
            "Speed: 1.6ms preprocess, 24.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 1.8ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 1.3ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.5ms\n",
            "Speed: 2.3ms preprocess, 23.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 26.7ms\n",
            "Speed: 2.1ms preprocess, 26.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.0ms\n",
            "Speed: 1.9ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.7ms\n",
            "Speed: 1.8ms preprocess, 22.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.4ms\n",
            "Speed: 1.5ms preprocess, 22.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 21.6ms\n",
            "Speed: 1.4ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 21.9ms\n",
            "Speed: 1.4ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.5ms\n",
            "Speed: 2.1ms preprocess, 22.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.3ms\n",
            "Speed: 1.5ms preprocess, 22.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.5ms\n",
            "Speed: 2.2ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.9ms\n",
            "Speed: 1.6ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.5ms\n",
            "Speed: 1.5ms preprocess, 22.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.6ms\n",
            "Speed: 1.4ms preprocess, 22.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.2ms\n",
            "Speed: 1.5ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.9ms\n",
            "Speed: 1.7ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.5ms\n",
            "Speed: 1.4ms preprocess, 22.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.1ms\n",
            "Speed: 1.8ms preprocess, 23.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 22.7ms\n",
            "Speed: 2.2ms preprocess, 22.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.2ms\n",
            "Speed: 2.1ms preprocess, 22.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.7ms\n",
            "Speed: 1.8ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.3ms\n",
            "Speed: 1.7ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.2ms\n",
            "Speed: 1.6ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.9ms\n",
            "Speed: 1.5ms preprocess, 23.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 cows, 25.7ms\n",
            "Speed: 1.7ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.6ms\n",
            "Speed: 1.3ms preprocess, 23.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 26.4ms\n",
            "Speed: 1.5ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 26.9ms\n",
            "Speed: 1.9ms preprocess, 26.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 26.3ms\n",
            "Speed: 2.3ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 (no detections), 26.7ms\n",
            "Speed: 1.5ms preprocess, 26.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 27.0ms\n",
            "Speed: 1.5ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.7ms\n",
            "Speed: 1.9ms preprocess, 23.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 2 cows, 25.8ms\n",
            "Speed: 1.8ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 24.4ms\n",
            "Speed: 1.6ms preprocess, 24.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.6ms\n",
            "Speed: 1.7ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.4ms\n",
            "Speed: 2.0ms preprocess, 23.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.5ms\n",
            "Speed: 1.5ms preprocess, 24.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.7ms\n",
            "Speed: 1.4ms preprocess, 22.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 23.2ms\n",
            "Speed: 1.8ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.8ms\n",
            "Speed: 1.4ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 23.3ms\n",
            "Speed: 2.0ms preprocess, 23.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 23.8ms\n",
            "Speed: 2.3ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 3 cows, 23.5ms\n",
            "Speed: 1.4ms preprocess, 23.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 3 cows, 23.3ms\n",
            "Speed: 1.7ms preprocess, 23.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.6ms\n",
            "Speed: 2.6ms preprocess, 24.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.3ms\n",
            "Speed: 2.4ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.9ms\n",
            "Speed: 1.6ms preprocess, 25.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.2ms\n",
            "Speed: 2.9ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 27.0ms\n",
            "Speed: 1.3ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.8ms\n",
            "Speed: 1.9ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 cows, 25.7ms\n",
            "Speed: 1.6ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.4ms\n",
            "Speed: 1.6ms preprocess, 24.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.7ms\n",
            "Speed: 1.9ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 23.2ms\n",
            "Speed: 1.5ms preprocess, 23.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.0ms\n",
            "Speed: 1.9ms preprocess, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 4 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 4 cows, 26.4ms\n",
            "Speed: 1.4ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 cows, 26.4ms\n",
            "Speed: 2.2ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 cows, 24.7ms\n",
            "Speed: 2.9ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 26.2ms\n",
            "Speed: 2.4ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 4 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 cows, 26.9ms\n",
            "Speed: 1.6ms preprocess, 26.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=2)\n",
            "\n",
            "0: 384x640 2 cows, 1 bowl, 25.1ms\n",
            "Speed: 1.8ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 (no detections), 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 27.0ms\n",
            "Speed: 1.8ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 cow, 26.6ms\n",
            "Speed: 1.4ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 cow, 25.6ms\n",
            "Speed: 2.0ms preprocess, 25.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.3ms\n",
            "Speed: 2.9ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.0ms\n",
            "Speed: 1.5ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.4ms\n",
            "Speed: 2.0ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.2ms\n",
            "Speed: 1.7ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.5ms\n",
            "Speed: 1.4ms preprocess, 24.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.4ms\n",
            "Speed: 1.8ms preprocess, 24.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 23.0ms\n",
            "Speed: 1.7ms preprocess, 23.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 24.3ms\n",
            "Speed: 1.9ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 23.4ms\n",
            "Speed: 2.2ms preprocess, 23.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 2.3ms preprocess, 24.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.9ms\n",
            "Speed: 1.5ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.8ms\n",
            "Speed: 2.4ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.5ms\n",
            "Speed: 1.8ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.9ms\n",
            "Speed: 1.8ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 22.6ms\n",
            "Speed: 2.4ms preprocess, 22.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.0ms\n",
            "Speed: 1.5ms preprocess, 23.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.5ms\n",
            "Speed: 1.5ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.3ms\n",
            "Speed: 1.5ms preprocess, 24.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.4ms\n",
            "Speed: 1.4ms preprocess, 24.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 23.7ms\n",
            "Speed: 1.8ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.2ms\n",
            "Speed: 1.5ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.2ms\n",
            "Speed: 1.5ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.0ms\n",
            "Speed: 1.5ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.3ms\n",
            "Speed: 1.9ms preprocess, 25.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.9ms\n",
            "Speed: 1.7ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.1ms\n",
            "Speed: 1.9ms preprocess, 25.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.0ms\n",
            "Speed: 2.0ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.6ms\n",
            "Speed: 1.3ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.0ms\n",
            "Speed: 1.8ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.3ms preprocess, 25.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.9ms\n",
            "Speed: 2.2ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.4ms\n",
            "Speed: 1.7ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 26.8ms\n",
            "Speed: 1.8ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.2ms\n",
            "Speed: 2.7ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.5ms\n",
            "Speed: 2.0ms preprocess, 24.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.9ms\n",
            "Speed: 1.7ms preprocess, 24.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.9ms\n",
            "Speed: 1.4ms preprocess, 23.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.6ms\n",
            "Speed: 1.7ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.8ms\n",
            "Speed: 1.6ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.1ms\n",
            "Speed: 2.1ms preprocess, 24.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 27.1ms\n",
            "Speed: 1.8ms preprocess, 27.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.8ms\n",
            "Speed: 1.7ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 27.0ms\n",
            "Speed: 1.5ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 24.1ms\n",
            "Speed: 2.3ms preprocess, 24.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 25.9ms\n",
            "Speed: 1.6ms preprocess, 25.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.6ms\n",
            "Speed: 1.5ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 27.0ms\n",
            "Speed: 1.8ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 26.0ms\n",
            "Speed: 1.6ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 2.2ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.0ms\n",
            "Speed: 3.2ms preprocess, 26.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 1.6ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.5ms\n",
            "Speed: 1.6ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.9ms\n",
            "Speed: 1.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.4ms\n",
            "Speed: 2.1ms preprocess, 25.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.0ms\n",
            "Speed: 1.7ms preprocess, 25.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 24.8ms\n",
            "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.6ms\n",
            "Speed: 1.6ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.1ms\n",
            "Speed: 1.6ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.3ms\n",
            "Speed: 2.9ms preprocess, 25.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.1ms\n",
            "Speed: 1.8ms preprocess, 25.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.2ms\n",
            "Speed: 1.6ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.3ms\n",
            "Speed: 1.7ms preprocess, 25.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.5ms\n",
            "Speed: 1.5ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.8ms\n",
            "Speed: 1.5ms preprocess, 26.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.4ms\n",
            "Speed: 1.7ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.1ms\n",
            "Speed: 1.6ms preprocess, 24.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 23.9ms\n",
            "Speed: 1.6ms preprocess, 23.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 26.3ms\n",
            "Speed: 1.5ms preprocess, 26.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 2.3ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 24.5ms\n",
            "Speed: 1.7ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.2ms\n",
            "Speed: 1.8ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.7ms\n",
            "Speed: 1.6ms preprocess, 25.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 26.1ms\n",
            "Speed: 1.6ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 26.4ms\n",
            "Speed: 1.6ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 2 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 26.1ms\n",
            "Speed: 2.4ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 27.1ms\n",
            "Speed: 2.6ms preprocess, 27.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 3 persons, 3 cows, 25.5ms\n",
            "Speed: 1.7ms preprocess, 25.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.1ms\n",
            "Speed: 1.9ms preprocess, 25.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.0ms\n",
            "Speed: 2.1ms preprocess, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 3.3ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.7ms preprocess, 24.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.3ms\n",
            "Speed: 1.6ms preprocess, 25.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.1ms\n",
            "Speed: 1.5ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.7ms\n",
            "Speed: 1.9ms preprocess, 25.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.9ms\n",
            "Speed: 2.3ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.3ms\n",
            "Speed: 2.3ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.2ms\n",
            "Speed: 2.1ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 4 cows, 25.6ms\n",
            "Speed: 1.6ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=6)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 27.0ms\n",
            "Speed: 1.6ms preprocess, 27.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.1ms\n",
            "Speed: 1.7ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 (no detections), 26.9ms\n",
            "Speed: 1.6ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.7ms\n",
            "Speed: 1.5ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 1.4ms preprocess, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 2 persons, 1 cow, 23.9ms\n",
            "Speed: 2.3ms preprocess, 23.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.1ms\n",
            "Speed: 1.5ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 2.0ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.9ms\n",
            "Speed: 2.3ms preprocess, 23.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.6ms\n",
            "Speed: 1.5ms preprocess, 22.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.4ms\n",
            "Speed: 1.6ms preprocess, 23.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.6ms\n",
            "Speed: 2.9ms preprocess, 22.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.1ms\n",
            "Speed: 1.3ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.8ms\n",
            "Speed: 2.3ms preprocess, 23.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.8ms\n",
            "Speed: 1.6ms preprocess, 22.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.3ms\n",
            "Speed: 2.1ms preprocess, 22.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.6ms\n",
            "Speed: 1.8ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 21.2ms\n",
            "Speed: 1.7ms preprocess, 21.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 21.2ms\n",
            "Speed: 1.4ms preprocess, 21.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.9ms\n",
            "Speed: 1.8ms preprocess, 22.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.7ms\n",
            "Speed: 1.5ms preprocess, 22.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 21.6ms\n",
            "Speed: 1.5ms preprocess, 21.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.4ms\n",
            "Speed: 2.4ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.3ms\n",
            "Speed: 1.6ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.6ms preprocess, 23.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.6ms\n",
            "Speed: 2.1ms preprocess, 25.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.6ms\n",
            "Speed: 2.2ms preprocess, 24.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.8ms preprocess, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.7ms\n",
            "Speed: 1.6ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.5ms preprocess, 23.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.1ms\n",
            "Speed: 1.6ms preprocess, 23.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.8ms preprocess, 23.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.2ms\n",
            "Speed: 1.4ms preprocess, 23.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 1.3ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.8ms\n",
            "Speed: 1.8ms preprocess, 23.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.3ms\n",
            "Speed: 2.8ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 (no detections), 23.8ms\n",
            "Speed: 2.1ms preprocess, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.0ms\n",
            "Speed: 2.2ms preprocess, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.1ms\n",
            "Speed: 2.1ms preprocess, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.0ms\n",
            "Speed: 1.7ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.4ms preprocess, 23.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.9ms\n",
            "Speed: 1.4ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.9ms\n",
            "Speed: 1.5ms preprocess, 22.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 1.3ms preprocess, 24.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.4ms\n",
            "Speed: 1.9ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 22.7ms\n",
            "Speed: 1.8ms preprocess, 22.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.9ms\n",
            "Speed: 1.5ms preprocess, 23.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 1.5ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.5ms\n",
            "Speed: 1.5ms preprocess, 23.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.6ms\n",
            "Speed: 1.8ms preprocess, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 2.6ms preprocess, 24.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 21.9ms\n",
            "Speed: 1.8ms preprocess, 21.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.5ms\n",
            "Speed: 1.4ms preprocess, 23.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.8ms\n",
            "Speed: 1.7ms preprocess, 23.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.9ms\n",
            "Speed: 1.5ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.2ms\n",
            "Speed: 1.4ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.8ms\n",
            "Speed: 1.6ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.0ms\n",
            "Speed: 1.6ms preprocess, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.2ms\n",
            "Speed: 1.4ms preprocess, 24.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.5ms\n",
            "Speed: 1.4ms preprocess, 25.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.0ms\n",
            "Speed: 1.5ms preprocess, 24.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.1ms\n",
            "Speed: 1.5ms preprocess, 25.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.5ms\n",
            "Speed: 1.6ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.2ms\n",
            "Speed: 1.9ms preprocess, 23.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.6ms\n",
            "Speed: 2.7ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.5ms\n",
            "Speed: 1.7ms preprocess, 26.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.7ms\n",
            "Speed: 1.4ms preprocess, 24.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.1ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 24.8ms\n",
            "Speed: 2.1ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 27.3ms\n",
            "Speed: 1.7ms preprocess, 27.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 25.4ms\n",
            "Speed: 1.4ms preprocess, 25.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 2.5ms preprocess, 25.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.3ms\n",
            "Speed: 1.8ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.5ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.4ms preprocess, 25.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.8ms\n",
            "Speed: 1.4ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 1.4ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.4ms preprocess, 25.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 27.8ms\n",
            "Speed: 1.4ms preprocess, 27.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 1.5ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 1.5ms preprocess, 24.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.6ms\n",
            "Speed: 1.9ms preprocess, 25.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.6ms\n",
            "Speed: 1.4ms preprocess, 25.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.3ms\n",
            "Speed: 1.8ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.0ms\n",
            "Speed: 1.5ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.2ms\n",
            "Speed: 1.7ms preprocess, 25.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 3 cows, 25.3ms\n",
            "Speed: 1.5ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.9ms\n",
            "Speed: 2.1ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.1ms\n",
            "Speed: 2.0ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.4ms\n",
            "Speed: 1.4ms preprocess, 24.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.8ms\n",
            "Speed: 1.7ms preprocess, 24.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.3ms\n",
            "Speed: 2.0ms preprocess, 25.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 3.0ms preprocess, 24.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.4ms\n",
            "Speed: 1.5ms preprocess, 24.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.7ms\n",
            "Speed: 1.8ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.2ms\n",
            "Speed: 1.7ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.7ms\n",
            "Speed: 1.7ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.1ms\n",
            "Speed: 2.3ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.3ms\n",
            "Speed: 1.7ms preprocess, 24.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.5ms\n",
            "Speed: 1.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 1.6ms preprocess, 24.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.6ms\n",
            "Speed: 1.4ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 1.8ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 26.5ms\n",
            "Speed: 2.0ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 1.8ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.4ms\n",
            "Speed: 1.7ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.7ms\n",
            "Speed: 1.9ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.3ms\n",
            "Speed: 1.5ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.6ms\n",
            "Speed: 1.7ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.0ms\n",
            "Speed: 1.9ms preprocess, 25.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.4ms\n",
            "Speed: 1.7ms preprocess, 24.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.3ms\n",
            "Speed: 1.4ms preprocess, 24.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.1ms\n",
            "Speed: 1.5ms preprocess, 24.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 25.8ms\n",
            "Speed: 1.6ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.7ms\n",
            "Speed: 1.4ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.6ms\n",
            "Speed: 1.5ms preprocess, 24.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 27.9ms\n",
            "Speed: 1.6ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.8ms preprocess, 25.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 26.1ms\n",
            "Speed: 2.2ms preprocess, 26.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 27.3ms\n",
            "Speed: 1.5ms preprocess, 27.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.6ms\n",
            "Speed: 1.4ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 27.6ms\n",
            "Speed: 2.5ms preprocess, 27.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 23.6ms\n",
            "Speed: 2.0ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.0ms\n",
            "Speed: 1.6ms preprocess, 25.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 22.7ms\n",
            "Speed: 1.4ms preprocess, 22.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.9ms\n",
            "Speed: 1.5ms preprocess, 25.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 (no detections), 25.5ms\n",
            "Speed: 2.7ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 (no detections), 23.1ms\n",
            "Speed: 2.1ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "WARNING no tracks found!\n",
            "SolutionResults()\n",
            "\n",
            "0: 384x640 1 person, 24.4ms\n",
            "Speed: 2.3ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 1 person, 23.3ms\n",
            "Speed: 1.4ms preprocess, 23.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=1)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.8ms\n",
            "Speed: 2.7ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 24.2ms\n",
            "Speed: 1.6ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.4ms\n",
            "Speed: 1.4ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=4)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 1.6ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 23.7ms\n",
            "Speed: 1.4ms preprocess, 23.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 26.6ms\n",
            "Speed: 2.7ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.8ms\n",
            "Speed: 1.5ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 2 persons, 3 cows, 24.9ms\n",
            "Speed: 1.7ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=5)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.5ms\n",
            "Speed: 2.0ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Reset: Area clear.\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 25.5ms\n",
            "Speed: 1.5ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.2ms\n",
            "Speed: 1.8ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 1 person, 2 cows, 24.9ms\n",
            "Speed: 1.4ms preprocess, 24.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "SolutionResults(total_tracks=3)\n",
            "\n",
            "0: 384x640 2 persons, 2 cows, 25.2ms\n",
            "Speed: 1.5ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            " Alarm Triggered: Unknown person count reached threshold.\n",
            "SolutionResults(total_tracks=4)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from numpy import source\n",
        "\n",
        "from ultralytics import solutions\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import pygame\n",
        "from ultralytics import solutions\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.solutions.config import SolutionConfig\n",
        "from ultralytics.utils import LOGGER\n",
        "\n",
        "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
        "from ultralytics.utils.plotting import colors\n",
        "\n",
        "# ========== üîä SOUND SETUP ==========\n",
        "pygame.mixer.init()\n",
        "ALARM_FILE = \"security_alarm2.mp3\"\n",
        "if os.path.exists(ALARM_FILE):\n",
        "    pygame.mixer.music.load(ALARM_FILE)\n",
        "else:\n",
        "    print(f\"[WARNING] Alarm file '{ALARM_FILE}' not found.\")\n",
        "\n",
        "\n",
        "# ========== üß† KNOWN FACE ENCODING LOADER ==========\n",
        "KNOWN_FACE_DIR = \"family_members\"\n",
        "known_face_encodings, known_face_names = [], []\n",
        "\n",
        "if os.path.exists(KNOWN_FACE_DIR):\n",
        "    for name in os.listdir(KNOWN_FACE_DIR):\n",
        "        person_dir = os.path.join(KNOWN_FACE_DIR, name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "        for filename in os.listdir(person_dir):\n",
        "            path = os.path.join(person_dir, filename)\n",
        "            try:\n",
        "                img = face_recognition.load_image_file(path)\n",
        "                enc = face_recognition.face_encodings(img)\n",
        "                if enc:\n",
        "                    known_face_encodings.append(enc[0])\n",
        "                    known_face_names.append(name)\n",
        "                    print(f\"[INFO] Loaded face for {name} from {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[ERROR] Failed loading {path}: {e}\")\n",
        "else:\n",
        "    print(\"[WARNING] No known_faces directory found.\")\n",
        "\n",
        "\n",
        "# ========== üëÅÔ∏è FACE-RECOGNITION ALARM (REVISED & OPTIMIZED) ==========\n",
        "class FaceRecognitionAlarmVisionEye(solutions.VisionEye):\n",
        "    def __init__(self, *args, known_face_encodings=None, known_face_names=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.known_face_encodings = known_face_encodings or []\n",
        "        self.known_face_names = known_face_names or []\n",
        "        self.sound_played = False\n",
        "        # Best practice: Set face recognition tolerance during initialization\n",
        "        self.face_tolerance = 0.55\n",
        "        self.vision_point = self.CFG[\"vision_point\"]\n",
        "        self.records = self.CFG.get(\"records\", 1)\n",
        "        # self.show = self.CFG.get(\"show\", True)\n",
        "    \n",
        "    def play_sound(self):\n",
        "        \"\"\"Plays the alarm sound if it's not already playing.\"\"\"\n",
        "        if not self.sound_played:\n",
        "            if pygame.mixer.get_init() and not pygame.mixer.music.get_busy():\n",
        "                pygame.mixer.music.play()\n",
        "                self.sound_played = True\n",
        "                LOGGER.info(\"üö® Alarm Triggered: Unknown person count reached threshold.\")\n",
        "\n",
        "    def reset_sound(self):\n",
        "        \"\"\"Stops the alarm sound and resets the state.\"\"\"\n",
        "        if self.sound_played:\n",
        "            if pygame.mixer.get_init():\n",
        "                pygame.mixer.music.stop()\n",
        "            self.sound_played = False\n",
        "            LOGGER.info(\"üü¢ Alarm Reset: Area clear.\")\n",
        "\n",
        "    def __call__(self, im0):\n",
        "        \"\"\"\n",
        "        Processes a single frame for person detection and face recognition.\n",
        "        This implementation follows best practices for accuracy and performance.\n",
        "        \"\"\"\n",
        "        # 1. Get person detections from the base class\n",
        "        self.extract_tracks(im0)\n",
        "        annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "        \n",
        "        unknown_person_count = 0\n",
        "\n",
        "        # 2. Optimize by finding all faces in the frame at once (on a smaller version)\n",
        "        # This is much faster than processing crops for each person.\n",
        "        h, w, _ = im0.shape\n",
        "        small_frame = cv2.resize(im0, (0, 0), fx=0.25, fy=0.25)\n",
        "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "        # 3. Iterate through detected PERSONS from YOLO\n",
        "        for box, conf, cls, t_id in zip(self.boxes, self.confs, self.clss, self.track_ids):\n",
        "            if int(cls) == 0:  # Skip if not a person\n",
        "                \n",
        "\n",
        "                name = \"Unknown\"\n",
        "                is_known = False\n",
        "                \n",
        "                # 4. Associate faces with person boxes\n",
        "                # Check if any detected face is inside this person's bounding box\n",
        "                person_box_left, person_box_top, person_box_right, person_box_bottom = map(int, box)\n",
        "                \n",
        "                for (face_top, face_right, face_bottom, face_left), face_encoding in zip(face_locations, face_encodings):\n",
        "                    # Scale face locations back to original image size\n",
        "                    face_top *= 4\n",
        "                    face_right *= 4\n",
        "                    face_bottom *= 4\n",
        "                    face_left *= 4\n",
        "\n",
        "                    # Check if the center of the face is inside the person's box\n",
        "                    face_center_x = (face_left + face_right) // 2\n",
        "                    face_center_y = (face_top + face_bottom) // 2\n",
        "\n",
        "                    if (person_box_left <= face_center_x <= person_box_right and\n",
        "                        person_box_top <= face_center_y <= person_box_bottom):\n",
        "                        \n",
        "                        # 5. Use robust face matching for the associated face\n",
        "                        if self.known_face_encodings:\n",
        "                            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
        "                            best_match_index = np.argmin(face_distances)\n",
        "                            \n",
        "                            if face_distances[best_match_index] < self.face_tolerance:\n",
        "                                name = self.known_face_names[best_match_index]\n",
        "                                is_known = True\n",
        "                        \n",
        "                        # Once a face is matched to this person, stop checking other faces\n",
        "                        break \n",
        "                \n",
        "                # 6. Update counter and draw labels\n",
        "                if not is_known:\n",
        "                    unknown_person_count += 1\n",
        "                    color = (0, 0, 255) # Red for Unknown\n",
        "                    # label = f\"Unknown ({conf:.2f})\"\n",
        "                    label = f\"Unknown\"\n",
        "                else:\n",
        "                    color = (0, 255, 0) # Green for Known\n",
        "                    label = f\"{name}\"\n",
        "                    # label = f\"{name} ({conf:.2f})\"\n",
        "                \n",
        "                # annotator.box_label(box, label, color=color)\n",
        "                \n",
        "            \n",
        "                # annotator.box_label(box, label=self.adjust_box_label(cls, conf, t_id), color=colors(int(t_id), True))\n",
        "                # annotator.visioneye(box, self.vision_point)\n",
        "                # ...existing code...\n",
        "        \n",
        "                # Annotate the image with bounding boxes, labels, and vision mapping\n",
        "                # annotator.box_label(box, label=self.adjust_box_label(cls, conf, t_id), color=colors(int(t_id), True))\n",
        "                # annotator.visioneye(box, self.vision_point)\n",
        "                # build base label from the existing adjust_box_label()\n",
        "                base_label = self.adjust_box_label(int(cls), float(conf) if conf is not None else 0.0, t_id)\n",
        "\n",
        "                # custom label for 'person' class (COCO id 0). Use CFG override if provided.\n",
        "                if int(cls) == 0:\n",
        "                    prefix = str(self.CFG.get(\"person_label_prefix\", label))\n",
        "                    custom_label = f\"{prefix}:\"\n",
        "                    # if base_label exists, concat both for full display\n",
        "                    final_label = f\"{custom_label} {base_label}\" if base_label else custom_label\n",
        "                else:\n",
        "                    final_label = base_label\n",
        "\n",
        "                # draw final label and vision eye mapping\n",
        "                annotator.box_label(box, label=final_label, color=colors(int(t_id), True))\n",
        "            else:\n",
        "                # For non-person classes, use default labeling\n",
        "                annotator.box_label(box, label=self.adjust_box_label(cls, conf, t_id), color=colors(int(t_id), True))\n",
        "            \n",
        "            annotator.visioneye(box, self.vision_point) \n",
        "\n",
        "        # 7. Trigger alarm based on the COUNT of unknown people and the 'records' threshold\n",
        "        if unknown_person_count >= self.records:\n",
        "            self.play_sound()\n",
        "        else:\n",
        "            self.reset_sound()\n",
        "\n",
        "        plot_im = annotator.result()\n",
        "        self.display_output(plot_im) \n",
        "        \n",
        "        \n",
        "        # Display track count on the frame\n",
        "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
        "        cv2.putText(plot_im, f\"Tracks: {total_tracks}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        return SolutionResults(plot_im=plot_im, total_tracks=len(self.track_ids))\n",
        "\n",
        "    # # ...existing code...\n",
        "    # def __call__(self, im0):\n",
        "    #     # Safe defaults and config\n",
        "    #     scale = float(self.CFG.get(\"recognition_scale\", 0.25))\n",
        "    #     rec_interval = int(self.CFG.get(\"recognition_interval\", 3))\n",
        "    #     person_cls_id = int(self.CFG.get(\"person_class\", 0))\n",
        "    #     person_prefix = str(self.CFG.get(\"person_label_prefix\", \"person_\"))\n",
        "\n",
        "    #     # Prepare annotator and tracks\n",
        "    #     self.extract_tracks(im0)\n",
        "    #     annotator = SolutionAnnotator(im0, line_width=self.line_width)\n",
        "\n",
        "    #     # Intermittent face detection for performance\n",
        "    #     if not hasattr(self, \"_frame_idx\"):\n",
        "    #         self._frame_idx = 0\n",
        "    #     self._frame_idx += 1\n",
        "    #     face_locations, face_encodings = [], []\n",
        "    #     if self._frame_idx % rec_interval == 0:\n",
        "    #         small = cv2.resize(im0, (0, 0), fx=scale, fy=scale)\n",
        "    #         rgb_small = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
        "    #         face_locations = face_recognition.face_locations(rgb_small)\n",
        "    #         face_encodings = face_recognition.face_encodings(rgb_small, face_locations)\n",
        "\n",
        "    #     unknown_count = 0\n",
        "    #     rescale = int(1.0 / scale) if scale > 0 else 1\n",
        "\n",
        "    #     # Iterate detections\n",
        "    #     for i, (box, conf, cls) in enumerate(zip(self.boxes, self.confs, self.clss)):\n",
        "    #         try:\n",
        "    #             x1, y1, x2, y2 = map(int, box)\n",
        "    #         except Exception:\n",
        "    #             b = np.array(box).astype(int)\n",
        "    #             x1, y1, x2, y2 = int(b[0]), int(b[1]), int(b[2]), int(b[3])\n",
        "\n",
        "    #         # default label/color\n",
        "    #         name = self.names[int(cls)] if hasattr(self, \"names\") else f\"class_{int(cls)}\"\n",
        "    #         color = colors(int(cls), True)\n",
        "\n",
        "    #         # non-person: annotate and continue\n",
        "    #         if int(cls) != person_cls_id:\n",
        "    #             annotator.box_label([x1, y1, x2, y2], label=self.adjust_box_label(cls, conf, (self.track_ids[i] if i < len(self.track_ids) else None)), color=color)\n",
        "    #             # optional vision mapping for all classes\n",
        "    #             if getattr(self, \"vision_point\", None):\n",
        "    #                 annotator.visioneye([x1, y1, x2, y2], tuple(self.CFG.get(\"vision_point\", self.vision_point)))\n",
        "    #             continue\n",
        "\n",
        "    #         # associate face inside person box (if we have face encodings)\n",
        "    #         matched_name = None\n",
        "    #         if face_encodings:\n",
        "    #             for (ftop, fright, fbottom, fleft), fenc in zip(face_locations, face_encodings):\n",
        "    #                 # scale face coords back to original\n",
        "    #                 ftop, fright, fbottom, fleft = int(ftop * rescale), int(fright * rescale), int(fbottom * rescale), int(fleft * rescale)\n",
        "    #                 cx, cy = (fleft + fright) // 2, (ftop + fbottom) // 2\n",
        "    #                 if x1 <= cx <= x2 and y1 <= cy <= y2:\n",
        "    #                     if self.known_face_encodings:\n",
        "    #                         dists = face_recognition.face_distance(self.known_face_encodings, fenc)\n",
        "    #                         best = int(np.argmin(dists))\n",
        "    #                         if dists[best] < getattr(self, \"face_tolerance\", 0.55):\n",
        "    #                             matched_name = self.known_face_names[best]\n",
        "    #                     break\n",
        "\n",
        "    #         if matched_name:\n",
        "    #             label = f\"{matched_name}\"\n",
        "    #             color = (0, 255, 0)\n",
        "    #         else:\n",
        "    #             unknown_count += 1\n",
        "    #             track_id = (self.track_ids[i] if i < len(self.track_ids) else None)\n",
        "    #             prefix = f\"{person_prefix}{track_id} \" if track_id is not None else f\"{person_prefix}\"\n",
        "    #             base_label = self.adjust_box_label(cls, conf, track_id) or \"\"\n",
        "    #             label = f\"{prefix}{base_label}\".strip()\n",
        "    #             color = (0, 0, 255)\n",
        "\n",
        "    #         # safe color: if track id present use it else use cls\n",
        "    #         tid = self.track_ids[i] if (hasattr(self, \"track_ids\") and i < len(self.track_ids)) else None\n",
        "    #         try:\n",
        "    #             draw_color = colors(int(tid), True) if tid is not None else color\n",
        "    #         except Exception:\n",
        "    #             draw_color = color\n",
        "\n",
        "    #         annotator.box_label([x1, y1, x2, y2], label=label, color=draw_color)\n",
        "    #         if getattr(self, \"vision_point\", None):\n",
        "    #             annotator.visioneye([x1, y1, x2, y2], tuple(self.CFG.get(\"vision_point\", self.vision_point)))\n",
        "\n",
        "    #     # alarm handling (existing methods)\n",
        "    #     if unknown_count >= getattr(self, \"records\", 1):\n",
        "    #         self.play_sound()\n",
        "    #     else:\n",
        "    #         self.reset_sound()\n",
        "\n",
        "    #     plot_im = annotator.result()\n",
        "    #     self.display_output(plot_im)\n",
        "    #     return SolutionResults(plot_im=plot_im, total_tracks=len(getattr(self, \"track_ids\", [])))\n",
        "    # # ...existing code...\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # cap = cv2.VideoCapture(\"media_files/person/bappi/WIN_20251122_20_23_39_Pro.mp4\")\n",
        "    cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "    # cap = cv2.VideoCapture(0)\n",
        "    assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "    # Video writer\n",
        "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "    video_writer = cv2.VideoWriter(\"visioneye_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "\n",
        "\n",
        "    # face_alarm = FaceRecognitionAlarm(\n",
        "    #         show=True,\n",
        "    #         model=\"yolo11l.pt\",\n",
        "    #         records=1,\n",
        "    #         # classes=[0, 19],  # person\n",
        "    #         known_face_encodings=known_face_encodings, \n",
        "    #         known_face_names=known_face_names,\n",
        "    #         conf=0.5,\n",
        "    #     )\n",
        "    # Initialize vision eye object\n",
        "    visioneyeInterface = FaceRecognitionAlarmVisionEye(\n",
        "        show=True,  # display the output\n",
        "        model=\"yolo11m.pt\",  # use any model that Ultralytics support, i.e, YOLOv10\n",
        "        # classes=[0, 19],  # generate visioneye view for specific classes\n",
        "        vision_point=(50, 50),  # the point, where vision will view objects and draw tracks\n",
        "        known_face_encodings=known_face_encodings, \n",
        "        known_face_names=known_face_names,\n",
        "        records=2,\n",
        "        conf=0.5,\n",
        "        # show_labels=True,\n",
        "    )\n",
        "\n",
        "    # # Process video\n",
        "    # while cap.isOpened():\n",
        "    #     success, im0 = cap.read()\n",
        "\n",
        "    #     if not success:\n",
        "    #         print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "    #         break\n",
        "\n",
        "    #         results = visioneyeInterface(im0)\n",
        "\n",
        "    #         # if not success:\n",
        "    #         #     print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "    #         #     break\n",
        "\n",
        "    #         # results = visioneye(im0)\n",
        "    #         # results = visioneyeInterface(frame)\n",
        "\n",
        "    #         # print(results)  # access the output\n",
        "\n",
        "    #         # video_writer.write(results.plot_im)  # write the video file\n",
        "    #         # cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "    #         print(results)  # access the output\n",
        "\n",
        "    #         # video_writer.write(results.plot_im)  # write the video file\n",
        "\n",
        "    # cap.release()\n",
        "    # video_writer.release()\n",
        "    # cv2.destroyAllWindows()  # destroy all opened windows\n",
        "# # Initialize vision eye object properly by instantiating the custom class\n",
        "# visioneye = FaceRecognitionAlarmVisionEye(\n",
        "#     show=True,  # display the output\n",
        "#     model=\"yolo11m.pt\",  # use any model that Ultralytics support, i.e, YOLOv10\n",
        "#     # classes=[0, 19],  # generate visioneye view for specific classes\n",
        "#     vision_point=(50, 50),  # the point, where vision will view objects and draw tracks\n",
        "#     known_face_encodings=known_face_encodings,\n",
        "#     known_face_names=known_face_names,\n",
        "#     records=3,\n",
        "#     conf=0.5,\n",
        "# )\n",
        "\n",
        "# Open a video source (try webcam first, fall back to sample file)\n",
        "# cap = cv2.VideoCapture(0)\n",
        "# if not cap.isOpened():\n",
        "# cap = cv2.VideoCapture(\"media_files/animal_surveillance/goru-churi.mp4\")\n",
        "# if not cap.isOpened():\n",
        "#     raise RuntimeError(\"Failed to open webcam or fallback video file. Please provide a valid video source.\")\n",
        "\n",
        "# # Create a video writer to save output\n",
        "# w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
        "# video_writer = cv2.VideoWriter(\"visioneye_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
        "\n",
        "# # Process video frames\n",
        "# while True:\n",
        "#     success, im0 = cap.read()\n",
        "#     if not success:\n",
        "#         print(\"[INFO] Video finished or empty frame.\")\n",
        "#         break\n",
        "\n",
        "#     results = visioneye(im0)\n",
        "\n",
        "#     # Print/inspect the results object\n",
        "#     print(results)\n",
        "\n",
        "#     # # Write result frame if available\n",
        "#     # if getattr(results, \"plot_im\", None) is not None:\n",
        "#     #     video_writer.write(results.plot_im)\n",
        "\n",
        "#     # # Optionally show the frame (respects visioneye.show)\n",
        "#     # if getattr(visioneye, \"show\", False):\n",
        "#     #     cv2.imshow(\"Face Recognition Security Alarm\", results.plot_im)\n",
        "#     #     if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "#     #         break\n",
        "\n",
        "# cap.release()\n",
        "# video_writer.release()\n",
        "# cv2.destroyAllWindows()\n",
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    results = visioneyeInterface(im0)\n",
        "\n",
        "    print(results)  # access the output\n",
        "\n",
        "    # video_writer.write(results.plot_im)  # write the video file\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16483881",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics.data.annotator import auto_annotate\n",
        "\n",
        "auto_annotate(\n",
        "    data=\"dog.jpeg\",\n",
        "    det_model=\"yolo11n.pt\",\n",
        "    sam_model=\"mobile_sam.pt\",\n",
        "    device=\"cuda\",\n",
        "    output_dir=\"output_dir\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c6937a",
      "metadata": {},
      "source": [
        "# chatgpt solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c36c31a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import mediapipe as mp\n",
        "from ultralytics import YOLO\n",
        "import smtplib\n",
        "import pygame\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize MediaPipe Face Detection\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "def detect_faces_mediapipe(frame):\n",
        "    \"\"\"\n",
        "    Detect faces using MediaPipe\n",
        "    Returns list of face bounding boxes in format [x, y, w, h]\n",
        "    \"\"\"\n",
        "    face_boxes = []\n",
        "    \n",
        "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
        "        # Convert BGR to RGB for MediaPipe\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_detection.process(rgb_frame)\n",
        "        \n",
        "        if results.detections:\n",
        "            h, w, _ = frame.shape\n",
        "            for detection in results.detections:\n",
        "                bbox = detection.location_data.relative_bounding_box\n",
        "                x = int(bbox.xmin * w)\n",
        "                y = int(bbox.ymin * h)\n",
        "                width = int(bbox.width * w)\n",
        "                height = int(bbox.height * h)\n",
        "                face_boxes.append([x, y, width, height])\n",
        "    \n",
        "    return face_boxes\n",
        "\n",
        "# Initialize YOLO model for object detection\n",
        "# model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
        "model = YOLO(\"yolo11m.pt\")\n",
        "\n",
        "# Initialize MediaPipe for pose detection (not directly used for the requested features but kept for completeness)\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "# Load known faces\n",
        "known_face_encodings = []\n",
        "known_face_names = []\n",
        "\n",
        "known_faces_dir = \"family_members\" \n",
        "if os.path.exists(known_faces_dir):\n",
        "    for person_name in os.listdir(known_faces_dir):\n",
        "        person_dir = os.path.join(known_faces_dir, person_name)\n",
        "        if os.path.isdir(person_dir):\n",
        "            for image_name in os.listdir(person_dir):\n",
        "                image_path = os.path.join(person_dir, image_name)\n",
        "                try:\n",
        "                    image = face_recognition.load_image_file(image_path)\n",
        "                    face_encodings = face_recognition.face_encodings(image)\n",
        "                    if face_encodings:\n",
        "                        known_face_encodings.append(face_encodings[0])\n",
        "                        known_face_names.append(person_name)\n",
        "                        print(f\"Loaded face: {person_name} from {image_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading {image_path}: {e}\")\n",
        "\n",
        "if known_face_encodings:\n",
        "    print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
        "else:\n",
        "    print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
        "\n",
        "# Setup alarm sound\n",
        "pygame.mixer.init()\n",
        "alarm_file = \"pols-aagyi-pols.mp3\"\n",
        "if os.path.exists(alarm_file):\n",
        "    pygame.mixer.music.load(alarm_file)\n",
        "else:\n",
        "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
        "\n",
        "# Create log directory\n",
        "log_dir = \"security_logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "def log_event(event_type, details=\"\"):\n",
        "    \"\"\"Log security events to file\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    log_file = os.path.join(log_dir, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
        "    with open(log_file, \"a\") as f:\n",
        "        f.write(f\"{timestamp} - {event_type}: {details}\\n\")\n",
        "\n",
        "# This function is not fully implemented for actual email sending, but logs the intent.\n",
        "def send_email_alert(person_status, person_name=\"N/A\", objects_detected=None):\n",
        "    \"\"\"Function to simulate sending email alert when a person is detected.\"\"\"\n",
        "    if objects_detected is None:\n",
        "        objects_detected = []\n",
        "    \n",
        "    objects_str = \", \".join(objects_detected) if objects_detected else \"None\"\n",
        "\n",
        "    if person_status == \"KNOWN\":\n",
        "        subject = f\"Security Alert: Known Person Detected - {person_name}\"\n",
        "        body = f\"A known person, {person_name}, was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
        "               f\"Objects detected: {objects_str}\"\n",
        "        print(f\"Simulating email alert for KNOWN person: {person_name} with objects: {objects_str}\")\n",
        "        log_event(\"EMAIL_ALERT_KNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
        "    elif person_status == \"UNKNOWN\":\n",
        "        subject = f\"URGENT Security Alert: Unknown Person Detected!\"\n",
        "        body = f\"An UNKNOWN person was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
        "               f\"Objects detected: {objects_str}\"\n",
        "        print(f\"Simulating email alert for UNKNOWN person with objects: {objects_str}\")\n",
        "        log_event(\"EMAIL_ALERT_UNKNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
        "    \n",
        "    # In a real application, you would add smtplib code here to send the email.\n",
        "    # For example:\n",
        "    # try:\n",
        "    #     server = smtplib.SMTP('smtp.your_email_provider.com', 587)\n",
        "    #     server.starttls()\n",
        "    #     server.login('your_email@example.com', 'your_password')\n",
        "    #     msg = f\"Subject: {subject}\\n\\n{body}\"\n",
        "    #     server.sendmail('your_email@example.com', 'security_team@example.com', msg)\n",
        "    #     server.quit()\n",
        "    #     log_event(\"EMAIL_SENT\", f\"Subject: {subject}\")\n",
        "    # except Exception as e:\n",
        "    #     log_event(\"EMAIL_ERROR\", f\"Failed to send email: {e}\")\n",
        "\n",
        "\n",
        "# Start Video Capture\n",
        "# cap = cv2.VideoCapture(0)\n",
        "cap = cv2.VideoCapture(\"./media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video capture device\")\n",
        "    exit()\n",
        "\n",
        "# Performance optimization variables\n",
        "frame_count = 0\n",
        "face_recognition_interval = 5  # Process face recognition every 5 frames\n",
        "last_alert_time = 0\n",
        "alert_cooldown = 10  # Seconds between alerts for the same type of event\n",
        "\n",
        "# Define objects of interest (subset of COCO classes that YOLO can detect)\n",
        "objects_of_interest = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"mouse\",\n",
        "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
        "    \"cell phone\", \"laptop\", \"book\", \"scissors\", \"knife\", \"face\"\n",
        "]\n",
        "\n",
        "print(\"Security monitoring started. Press 'q' to quit.\")\n",
        "log_event(\"SYSTEM_START\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        timer = cv2.getTickCount()\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to grab frame\")\n",
        "            break\n",
        "            \n",
        "        frame_count += 1\n",
        "        process_faces = frame_count % face_recognition_interval == 0\n",
        "        current_time = time.time()\n",
        "        \n",
        "        results = model(frame, conf=0.5, verbose=False)        \n",
        "        \n",
        "        detected_objects = []\n",
        "        \n",
        "        # Iterate through YOLO results\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            \n",
        "            for i, box in enumerate(boxes):\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                x1, y1 = max(0, x1), max(0, y1)\n",
        "                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
        "                \n",
        "                if x2 <= x1 or y2 <= y1:\n",
        "                    continue\n",
        "                \n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                class_name = result.names[cls]\n",
        "                \n",
        "                if class_name in objects_of_interest and class_name != \"person\":\n",
        "                    detected_objects.append(class_name)\n",
        "                    \n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2) # Cyan for other objects\n",
        "                    label = f\"{class_name}: {conf:.2f}\"\n",
        "                    cv2.putText(frame, label, (x1, y1 - 10), \n",
        "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
        "                \n",
        "                if class_name == \"person\":\n",
        "                    person_roi = frame[y1:y2, x1:x2]\n",
        "                    \n",
        "                    person_status = \"UNKNOWN\" # Default to unknown\n",
        "                    person_name = \"UNKNOWN\"\n",
        "                    \n",
        "                    if person_roi.size > 0 and person_roi.shape[0] > 0 and person_roi.shape[1] > 0:\n",
        "                        face_boxes = detect_faces_mediapipe(person_roi)\n",
        "                        \n",
        "                        for face_box in face_boxes:\n",
        "                            fx, fy, fw, fh = face_box\n",
        "                            face_x1 = x1 + fx\n",
        "                            face_y1 = y1 + fy\n",
        "                            face_x2 = face_x1 + fw\n",
        "                            face_y2 = face_y1 + fh\n",
        "                            \n",
        "                            cv2.rectangle(frame, (face_x1, face_y1), (face_x2, face_y2), (0, 0, 255), 2) # Red for face itself\n",
        "                            cv2.putText(frame, \"Face\", (face_x1 + 5, face_y1 - 5), \n",
        "                                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "                                \n",
        "                        if process_faces and face_boxes: # Only process face recognition if faces are detected by MediaPipe\n",
        "                            rgb_small_frame = cv2.cvtColor(cv2.resize(person_roi, (0, 0), fx=0.25, fy=0.25), cv2.COLOR_BGR2RGB)\n",
        "                            face_locations_small = face_recognition.face_locations(rgb_small_frame)\n",
        "                            \n",
        "                            if face_locations_small:\n",
        "                                face_encodings_small = face_recognition.face_encodings(rgb_small_frame, face_locations_small)\n",
        "                                \n",
        "                                for face_encoding in face_encodings_small:\n",
        "                                    if known_face_encodings:\n",
        "                                        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "                                        \n",
        "                                        if any(matches):\n",
        "                                            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "                                            best_match_index = np.argmin(face_distances)\n",
        "                                            if matches[best_match_index]:\n",
        "                                                person_name = known_face_names[best_match_index]\n",
        "                                                person_status = \"KNOWN\"\n",
        "                                                break # Found a known person, no need to check other faces in this ROI\n",
        "                                    \n",
        "                    # Draw person box based on status\n",
        "                    if person_status == \"KNOWN\":\n",
        "                        box_color = (0, 255, 0)  # Green for known\n",
        "                        label = f\"KNOWN: {person_name}\"\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
        "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
        "                        print(f\"‚úÖ Known Person Detected: {person_name}\")\n",
        "                        log_event(\"KNOWN_PERSON\", f\"Detected: {person_name} with objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
        "                        if current_time - last_alert_time > alert_cooldown:\n",
        "                            # send_email_alert(\"KNOWN\", person_name, detected_objects)\n",
        "                            last_alert_time = current_time\n",
        "                    else:\n",
        "                        box_color = (0, 165, 255) # Orange for unknown\n",
        "                        label = \"UNKNOWN\"\n",
        "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
        "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
        "                        print(\"‚ö†Ô∏è Unknown Person Detected!\")\n",
        "                        log_event(\"UNKNOWN_PERSON\", f\"With objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
        "                        if current_time - last_alert_time > alert_cooldown:\n",
        "                            if os.path.exists(alarm_file) and not pygame.mixer.music.get_busy():\n",
        "                                pygame.mixer.music.play()\n",
        "                            # send_email_alert(\"UNKNOWN\", objects_detected=detected_objects)\n",
        "                            last_alert_time = current_time\n",
        "        \n",
        "        # Display detected objects summary\n",
        "        if detected_objects:\n",
        "            objects_text = f\"Objects: {', '.join(set(detected_objects))}\"\n",
        "            cv2.putText(frame, objects_text, (20, 60), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
        "        \n",
        "        # Calculate and display FPS\n",
        "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
        "        cv2.putText(frame, f\"FPS: {int(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        \n",
        "        cv2.imshow('Security Monitoring', frame)\n",
        "        \n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    log_event(\"SYSTEM_ERROR\", str(e))\n",
        "finally:\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    pose.close()\n",
        "    pygame.mixer.quit()\n",
        "    log_event(\"SYSTEM_SHUTDOWN\")\n",
        "    print(\"Security monitoring stopped.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ENV_YOLO_WITH_FACE_RECOGNITION",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
