{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN1cAxdvd61e"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
    "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
    "\n",
    "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
    "\n",
    "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
    "  <a href=\"https://console.paperspace.com/github/ultralytics/ultralytics\"><img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/></a>\n",
    "  <a href=\"https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/object_tracking.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "  <a href=\"https://www.kaggle.com/models/ultralytics/yolo11\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
    "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
    "\n",
    "Welcome to the Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. This notebook serves as the starting point for exploring the various resources available to help you get started with YOLO11 and understand its features and capabilities.\n",
    "\n",
    "YOLO11 models are fast, accurate, and easy to use, making them ideal for various object detection and image segmentation tasks. They can be trained on large datasets and run on diverse hardware platforms, from CPUs to GPUs.\n",
    "\n",
    "We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/modes/track/\"> Tracking Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o68Sg1oOeZm2"
   },
   "source": [
    "# Setup\n",
    "\n",
    "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
    "\n",
    "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dSwz_uOReMI",
    "outputId": "ed8c2370-8fc7-4e4e-f669-d0bae4d944e9"
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7VkxQ2aeg7k"
   },
   "source": [
    "# Ultralytics Object Tracking\n",
    "\n",
    "[Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/) instance segmentation involves identifying and outlining individual objects in an image, providing a detailed understanding of spatial distribution. Unlike semantic segmentation, it uniquely labels and precisely delineates each object, crucial for tasks like object detection and medical imaging.\n",
    "\n",
    "There are two types of instance segmentation tracking available in the Ultralytics package:\n",
    "\n",
    "- **Instance Segmentation with Class Objects:** Each class object is assigned a unique color for clear visual separation.\n",
    "\n",
    "- **Instance Segmentation with Object Tracks:** Every track is represented by a distinct color, facilitating easy identification and tracking.\n",
    "\n",
    "## Samples\n",
    "\n",
    "|                                                          Instance Segmentation                                                          |                                                           Instance Segmentation + Object Tracking                                                            |\n",
    "|:---------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| ![Ultralytics Instance Segmentation](https://github.com/RizwanMunawar/ultralytics/assets/62513924/d4ad3499-1f33-4871-8fbc-1be0b2643aa2) | ![Ultralytics Instance Segmentation with Object Tracking](https://github.com/RizwanMunawar/ultralytics/assets/62513924/2e5c38cc-fd5c-4145-9682-fa94ae2010a0) |\n",
    "|                                                  Ultralytics Instance Segmentation üòç                                                   |                                                  Ultralytics Instance Segmentation with Object Tracking üî•                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZF9DM6e6gz0"
   },
   "source": [
    "## CLI\n",
    "\n",
    "Command-Line Interface (CLI) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XJqhOwo6iqT"
   },
   "outputs": [],
   "source": [
    "!yolo track source=\"../Test-Video -And-Images/istockphoto-1150749672-640_adpp_is.mp4\" show=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRcw0vIE6oNb"
   },
   "source": [
    "## Python\n",
    "\n",
    "Python Instance Segmentation and Object tracking example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Cx-u59HQdu2o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 cat, 1 dog, 1 chair, 85.0ms\n",
      "Speed: 2.2ms preprocess, 85.0ms inference, 156.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Annotator' object has no attribute 'seg_bbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Annotate each mask with its corresponding tracking ID and color\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m mask, track_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(masks, track_ids):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[43mannotator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseg_bbox\u001b[49m(mask=mask, mask_color=colors(\u001b[38;5;28mint\u001b[39m(track_id), \u001b[38;5;28;01mTrue\u001b[39;00m), label=\u001b[38;5;28mstr\u001b[39m(track_id))\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Write the annotated frame to the output video\u001b[39;00m\n\u001b[32m     47\u001b[39m out.write(im0)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Annotator' object has no attribute 'seg_bbox'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "# Dictionary to store tracking history with default empty lists\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Load the YOLO model with segmentation capabilities\n",
    "model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Retrieve video properties: width, height, and frames per second\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Initialize video writer to save the output video with the specified properties\n",
    "out = cv2.VideoWriter(\"instance-segmentation-object-tracking.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, im0 = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Create an annotator object to draw on the frame\n",
    "    annotator = Annotator(im0, line_width=2)\n",
    "\n",
    "    # Perform object tracking on the current frame\n",
    "    results = model.track(im0, persist=True)\n",
    "\n",
    "    # Check if tracking IDs and masks are present in the results\n",
    "    if results[0].boxes.id is not None and results[0].masks is not None:\n",
    "        # Extract masks and tracking IDs\n",
    "        masks = results[0].masks.xy\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Annotate each mask with its corresponding tracking ID and color\n",
    "        for mask, track_id in zip(masks, track_ids):\n",
    "            annotator.seg_bbox(mask=mask, mask_color=colors(int(track_id), True), label=str(track_id))\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(im0)\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"instance-segmentation-object-tracking\", im0)\n",
    "\n",
    "    # Exit the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video writer and capture objects, and close all OpenCV windows\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrlKg-y3fEyD"
   },
   "source": [
    "# Additional Resources\n",
    "\n",
    "## Community Support\n",
    "\n",
    "For more information on using tracking with Ultralytics, you can explore the comprehensive [Ultralytics Tracking Docs](https://docs.ultralytics.com/modes/track/). This guide covers everything from basic concepts to advanced techniques, ensuring you get the most out of tracking and visualization.\n",
    "\n",
    "## Ultralytics ‚ö° Resources\n",
    "\n",
    "At Ultralytics, we are committed to providing cutting-edge AI solutions. Here are some key resources to learn more about our company and get involved with our community:\n",
    "\n",
    "- [Ultralytics HUB](https://ultralytics.com/hub): Simplify your AI projects with Ultralytics HUB, our no-code tool for effortless YOLO training and deployment.\n",
    "- [Ultralytics Licensing](https://ultralytics.com/license): Review our licensing terms to understand how you can use our software in your projects.\n",
    "- [About Us](https://ultralytics.com/about): Discover our mission, vision, and the story behind Ultralytics.\n",
    "- [Join Our Team](https://ultralytics.com/work): Explore career opportunities and join our team of talented professionals.\n",
    "\n",
    "## YOLO11 üöÄ Resources\n",
    "\n",
    "YOLO11 is the latest evolution in the YOLO series, offering state-of-the-art performance in object detection and image segmentation. Here are some essential resources to help you get started with YOLO11:\n",
    "\n",
    "- [GitHub](https://github.com/ultralytics/ultralytics): Access the YOLO11 repository on GitHub, where you can find the source code, contribute to the project, and report issues.\n",
    "- [Docs](https://docs.ultralytics.com/): Explore the official documentation for YOLO11, including installation guides, tutorials, and detailed API references.\n",
    "- [Discord](https://ultralytics.com/discord): Join our Discord community to connect with other users, share your projects, and get help from the Ultralytics team.\n",
    "\n",
    "These resources are designed to help you leverage the full potential of Ultralytics' offerings and YOLO11. Whether you're a beginner or an experienced developer, you'll find the information and support you need to succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "video_path = \"../Test-Video -And-Images/istockphoto-1150749672-640_adpp_is.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        results = model.track(frame, persist=True)\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        annotated_frame = results[0].plot()\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))\n",
    "            if len(track) > 30:\n",
    "                track.pop(0)\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "        cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov11_ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
