{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd10ba9e",
   "metadata": {},
   "source": [
    "# Track object in Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3be7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "857c5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance segmentation using Ultralytics YOLO11\n",
    "!yolo solutions isegment show=True\n",
    "\n",
    "# Pass a source video\n",
    "!yolo solutions isegment source=\"path/to/video.mp4\"\n",
    "\n",
    "# Monitor the specific classes\n",
    "!yolo solutions isegment classes=\"[0, 5]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428b821",
   "metadata": {},
   "source": [
    "# Object Tracking in Zones (TrackZone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
   "id": "4cbfce98",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "!yolo solutions trackzone source=\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_15.mp4\" show=True"
=======
    "!yolo solutions trackzone source=\"./media_files/People walking/\" show=True"
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
<<<<<<< HEAD
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_15.mp4\")\n",
=======
    "from ultralytics import solutions\n",
    "# torch is already imported in cell 2, no need to import again\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/People walking/computer_vision_object_and_detection_tracking_people_walking_video_20250730_164537_36.mp4\")\n",
    "# cap = cv2.VideoCapture(\"./media_files/istockphoto-1138941116-640_adpp_is.mp4\")\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define region points\n",
    "region_points = [(150, 150), (1130, 150), (1130, 570), (150, 570)]\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init trackzone (object tracking in zones, not complete frame)\n",
    "trackzone = solutions.TrackZone(\n",
    "    show=True,  # display the output\n",
    "    region=region_points,  # pass region points\n",
<<<<<<< HEAD
    "    model=\"yolo11l.pt\",\n",
    "    conf=0.5,  # confidence threshold\n",
    "    iou=0.9,  # IoU threshold\n",
=======
    "    model=\"yolo11m.pt\",\n",
    "    conf=0.5,  # confidence threshold\n",
    "    # iou=0.99,  # IoU threshold\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "    verbose=True,  # print additional information\n",
    "    device=\"cuda:0\",  # use GPU if available\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    results = trackzone(im0)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
<<<<<<< HEAD
    "    if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15750bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('runs/detect/train3/weights/best.pt')  # Load your model\n",
    "video_path = './media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_13.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video's native resolution\n",
    "orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "aspect_ratio = orig_width / orig_height\n",
    "\n",
    "# Set your base dimension (choose one)\n",
    "base_width = 800  # Fixed width, auto height\n",
    "# base_height = 600  # Fixed height, auto width\n",
    "\n",
    "# Calculate dimensions (choose one method)\n",
    "# Option 1: Fixed width, auto height\n",
    "display_width = base_width\n",
    "display_height = int(base_width / aspect_ratio)\n",
    "\n",
    "# Option 2: Fixed height, auto width\n",
    "# display_height = base_height\n",
    "# display_width = int(base_height * aspect_ratio)\n",
    "\n",
    "window_name = \"YOLOv11x Inference\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(window_name, display_width, display_height)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Get annotated frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    print(f\"Annotated frame shape: {annotated_frame}\")\n",
    "    \n",
    "    # Show results\n",
    "    cv2.imshow(window_name, annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10338bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11l.pt\")\n",
    "\n",
    "# Open the video file\n",
    "# video_path = \"https://youtu.be/LNwODJXcvt4\"\n",
    "video_path = \"./media_files/people walking/computer_vision_object_and_detection_tracking_people_walking_video_20250819_173636_3.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "        result = model.track(frame, persist=True, conf=0.5, iou=0.89, classes=[0], tracker=\"botsort.yaml\")[0]\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        if result.boxes and result.boxes.is_track:\n",
    "            boxes = result.boxes.xywh.cpu()\n",
    "            track_ids = result.boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # Visualize the result on the frame\n",
    "            frame = result.plot()\n",
    "\n",
    "            # Plot the tracks\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))  # x, y center point\n",
    "                if len(track) > 30:  # retain 30 tracks for 30 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                # Draw the tracking lines\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLO11 Tracking\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5951a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\n",
    "\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import LOGGER\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "\n",
    "enable_gpu = True  # Set True if running with CUDA\n",
    "model_file = \"yolo11s.pt\"  # Path to model file\n",
    "show_fps = True  # If True, shows current FPS in top-left corner\n",
    "show_conf = False  # Display or hide the confidence score\n",
    "save_video = True  # Set True to save output video\n",
    "video_output_path = \"interactive_tracker_output.avi\"  # Output video file name\n",
    "\n",
    "\n",
    "conf = 0.3  # Min confidence for object detection (lower = more detections, possibly more false positives)\n",
    "iou = 0.3  # IoU threshold for NMS (higher = less overlap allowed)\n",
    "max_det = 20  # Maximum objects per im (increase for crowded scenes)\n",
    "\n",
    "tracker = \"bytetrack.yaml\"  # Tracker config: 'bytetrack.yaml', 'botsort.yaml', etc.\n",
    "track_args = {\n",
    "    \"persist\": True,  # Keep frames history as a stream for continuous tracking\n",
    "    \"verbose\": False,  # Print debug info from tracker\n",
    "}\n",
    "\n",
    "window_name = \"Ultralytics YOLO Interactive Tracking\"  # Output window name\n",
    "\n",
    "LOGGER.info(\"ðŸš€ Initializing model...\")\n",
    "if enable_gpu:\n",
    "    LOGGER.info(\"Using GPU...\")\n",
    "    model = YOLO(model_file)\n",
    "    model.to(\"cuda\")\n",
    "else:\n",
    "    LOGGER.info(\"Using CPU...\")\n",
    "    model = YOLO(model_file, task=\"detect\")\n",
    "\n",
    "classes = model.names  # Store model classes names\n",
    "\n",
    "# cap = cv2.VideoCapture(0)  # Replace with video path if needed\n",
    "cap = cv2.VideoCapture(\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_12.mp4\")  # Replace with video path if needed\n",
    "\n",
    "# Initialize video writer\n",
    "vw = None\n",
    "if save_video:\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    vw = cv2.VideoWriter(video_output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "selected_object_id = None\n",
    "selected_bbox = None\n",
    "selected_center = None\n",
    "\n",
    "\n",
    "def get_center(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Calculates the center point of a bounding box.\n",
    "\n",
    "    Args:\n",
    "        x1 (int): Top-left X coordinate.\n",
    "        y1 (int): Top-left Y coordinate.\n",
    "        x2 (int): Bottom-right X coordinate.\n",
    "        y2 (int): Bottom-right Y coordinate.\n",
    "\n",
    "    Returns:\n",
    "        (int, int): Center point (x, y) of the bounding box.\n",
    "    \"\"\"\n",
    "    return (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "\n",
    "def extend_line_from_edge(mid_x, mid_y, direction, img_shape):\n",
    "    \"\"\"\n",
    "    Calculates the endpoint to extend a line from the center toward an image edge.\n",
    "\n",
    "    Args:\n",
    "        mid_x (int): X-coordinate of the midpoint.\n",
    "        mid_y (int): Y-coordinate of the midpoint.\n",
    "        direction (str): Direction to extend ('left', 'right', 'up', 'down').\n",
    "        img_shape (tuple): Image shape in (height, width, channels).\n",
    "\n",
    "    Returns:\n",
    "        (int, int): Endpoint coordinate of the extended line.\n",
    "    \"\"\"\n",
    "    h, w = img_shape[:2]\n",
    "    if direction == \"left\":\n",
    "        return 0, mid_y\n",
    "    if direction == \"right\":\n",
    "        return w - 1, mid_y\n",
    "    if direction == \"up\":\n",
    "        return mid_x, 0\n",
    "    if direction == \"down\":\n",
    "        return mid_x, h - 1\n",
    "    return mid_x, mid_y\n",
    "\n",
    "\n",
    "def draw_tracking_scope(im, bbox, color):\n",
    "    \"\"\"\n",
    "    Draws tracking scope lines extending from the bounding box to image edges.\n",
    "\n",
    "    Args:\n",
    "        im (ndarray): Image array to draw on.\n",
    "        bbox (tuple): Bounding box coordinates (x1, y1, x2, y2).\n",
    "        color (tuple): Color in BGR format for drawing.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    mid_top = ((x1 + x2) // 2, y1)\n",
    "    mid_bottom = ((x1 + x2) // 2, y2)\n",
    "    mid_left = (x1, (y1 + y2) // 2)\n",
    "    mid_right = (x2, (y1 + y2) // 2)\n",
    "    cv2.line(im, mid_top, extend_line_from_edge(*mid_top, \"up\", im.shape), color, 2)\n",
    "    cv2.line(im, mid_bottom, extend_line_from_edge(*mid_bottom, \"down\", im.shape), color, 2)\n",
    "    cv2.line(im, mid_left, extend_line_from_edge(*mid_left, \"left\", im.shape), color, 2)\n",
    "    cv2.line(im, mid_right, extend_line_from_edge(*mid_right, \"right\", im.shape), color, 2)\n",
    "\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    \"\"\"\n",
    "    Handles mouse click events to select an object for focused tracking.\n",
    "\n",
    "    Args:\n",
    "        event (int): OpenCV mouse event type.\n",
    "        x (int): X-coordinate of the mouse event.\n",
    "        y (int): Y-coordinate of the mouse event.\n",
    "        flags (int): Any relevant flags passed by OpenCV.\n",
    "        param (any): Additional parameters (not used).\n",
    "    \"\"\"\n",
    "    global selected_object_id\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        detections = results[0].boxes.data if results[0].boxes is not None else []\n",
    "        if detections is not None:\n",
    "            min_area = float(\"inf\")\n",
    "            best_match = None\n",
    "            for track in detections:\n",
    "                track = track.tolist()\n",
    "                if len(track) >= 6:\n",
    "                    x1, y1, x2, y2 = map(int, track[:4])\n",
    "                    if x1 <= x <= x2 and y1 <= y <= y2:\n",
    "                        area = (x2 - x1) * (y2 - y1)\n",
    "                        if area < min_area:\n",
    "                            class_id = int(track[-1])\n",
    "                            track_id = int(track[4]) if len(track) == 7 else -1\n",
    "                            min_area = area\n",
    "                            best_match = (track_id, model.names[class_id])\n",
    "            if best_match:\n",
    "                selected_object_id, label = best_match\n",
    "                print(f\"ðŸ”µ TRACKING STARTED: {label} (ID {selected_object_id})\")\n",
    "\n",
    "\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.setMouseCallback(window_name, click_event)\n",
    "\n",
    "fps_counter, fps_timer, fps_display = 0, time.time(), 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    results = model.track(im, conf=conf, iou=iou, max_det=max_det, tracker=tracker, **track_args)\n",
    "    annotator = Annotator(im)\n",
    "    detections = results[0].boxes.data if results[0].boxes is not None else []\n",
    "    detected_objects = []\n",
    "    for track in detections:\n",
    "        track = track.tolist()\n",
    "        if len(track) < 6:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = map(int, track[:4])\n",
    "        class_id = int(track[6]) if len(track) >= 7 else int(track[5])\n",
    "        track_id = int(track[4]) if len(track) == 7 else -1\n",
    "        color = colors(track_id, True)\n",
    "        txt_color = annotator.get_txt_color(color)\n",
    "        label = f\"{classes[class_id]} ID {track_id}\" + (f\" ({float(track[5]):.2f})\" if show_conf else \"\")\n",
    "        if track_id == selected_object_id:\n",
    "            draw_tracking_scope(im, (x1, y1, x2, y2), color)\n",
    "            center = get_center(x1, y1, x2, y2)\n",
    "            cv2.circle(im, center, 6, color, -1)\n",
    "\n",
    "            # Pulsing circle for attention\n",
    "            pulse_radius = 8 + int(4 * abs(time.time() % 1 - 0.5))\n",
    "            cv2.circle(im, center, pulse_radius, color, 2)\n",
    "\n",
    "            annotator.box_label([x1, y1, x2, y2], label=f\"ACTIVE: TRACK {track_id}\", color=color)\n",
    "        else:\n",
    "            # Draw dashed box for other objects\n",
    "            for i in range(x1, x2, 10):\n",
    "                cv2.line(im, (i, y1), (i + 5, y1), color, 3)\n",
    "                cv2.line(im, (i, y2), (i + 5, y2), color, 3)\n",
    "            for i in range(y1, y2, 10):\n",
    "                cv2.line(im, (x1, i), (x1, i + 5), color, 3)\n",
    "                cv2.line(im, (x2, i), (x2, i + 5), color, 3)\n",
    "            # Draw label text with background\n",
    "            (tw, th), bl = cv2.getTextSize(label, 0, 0.7, 2)\n",
    "            cv2.rectangle(im, (x1 + 5 - 5, y1 + 20 - th - 5), (x1 + 5 + tw + 5, y1 + 20 + bl), color, -1)\n",
    "            cv2.putText(im, label, (x1 + 5, y1 + 20), 0, 0.7, txt_color, 1, cv2.LINE_AA)\n",
    "\n",
    "    if show_fps:\n",
    "        fps_counter += 1\n",
    "        if time.time() - fps_timer >= 1.0:\n",
    "            fps_display = fps_counter\n",
    "            fps_counter = 0\n",
    "            fps_timer = time.time()\n",
    "\n",
    "        # Draw FPS text with background\n",
    "        fps_text = f\"FPS: {fps_display}\"\n",
    "        cv2.putText(im, fps_text, (10, 25), 0, 0.7, (255, 255, 255), 1)\n",
    "        (tw, th), bl = cv2.getTextSize(fps_text, 0, 0.7, 2)\n",
    "        cv2.rectangle(im, (10 - 5, 25 - th - 5), (10 + tw + 5, 25 + bl), (255, 255, 255), -1)\n",
    "        cv2.putText(im, fps_text, (10, 25), 0, 0.7, (104, 31, 17), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(window_name, im)\n",
    "    if save_video and vw is not None:\n",
    "        vw.write(im)\n",
    "    # Terminal logging\n",
    "    LOGGER.info(f\"ðŸŸ¡ DETECTED {len(detections)} OBJECT(S): {' | '.join(detected_objects)}\")\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\"c\"):\n",
    "        LOGGER.info(\"ðŸŸ¢ TRACKING RESET\")\n",
    "        selected_object_id = None\n",
    "\n",
    "cap.release()\n",
    "if save_video and vw is not None:\n",
    "    vw.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11m.pt\")\n",
    "video_path = \"./media_files/people walking/102455-660253882_small.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if success:\n",
    "        results = model.track(frame, persist=True, conf=0.5, iou=0.5, classes=0, tracker='botsort.yaml')\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        annotated_frame = results[0].plot()\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))\n",
    "            if len(track) > 30:\n",
    "                track.pop(0)\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "        cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9970f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"path/to/video.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"instance-segmentation.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init InstanceSegmentation\n",
    "isegment = solutions.InstanceSegmentation(\n",
    "    show=True,  # display the output\n",
    "    model=\"yolo11n-seg.pt\",  # model=\"yolo11n-seg.pt\" for object segmentation using YOLO11.\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "    results = isegment(im0)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"./media_files/apple counting/computer_vision_object_and_detection_tracking_apple_counting_video_20250819_173636_1.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define points for a line or region of interest in the video frame\n",
    "line_points = [(20, 400), (1080, 400)]  # Line coordinates\n",
    "\n",
    "# Initialize the video writer to save the output video\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize the Object Counter with visualization options and other parameters\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  # Display the image during processing\n",
    "    region=line_points,  # Region of interest points\n",
    "    model=\"yolo11x.pt\",  # Ultralytics YOLO11 model file\n",
    "    line_width=2,  # Thickness of the lines and bounding boxes\n",
    ")\n",
    "\n",
    "# Process video frames in a loop\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Use the Object Counter to count objects in the frame and get the annotated image\n",
    "    results = counter(im0)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"./media_files/apple counting/computer_vision_object_and_detection_tracking_apple_counting_video_20250819_173636_1.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define points for a line or region of interest in the video frame\n",
    "# line_points = [(20, 400), (1080, 400)]  # Line coordinates\n",
    "line_points = [(200, 20), (200, 420)] # Line coordinates\n",
    "\n",
    "# Initialize the video writer to save the output video\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize the Object Counter with visualization options and other parameters\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  # Display the image during processing\n",
    "    region=line_points,  # Region of interest points\n",
    "    model=\"yolo11l.pt\",  # Ultralytics YOLO11 model file\n",
    "    line_width=2,  # Thickness of the lines and bounding boxes\n",
    ")\n",
    "\n",
    "# Process video frames in a loop\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Use the Object Counter to count objects in the frame and get the annotated image\n",
    "    results = counter(im0)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"./media_files/conveyer apple and bottle counting/istockphoto-1434955373-640_adpp_is.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps)\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define points for a line or region of interest in the video frame\n",
    "# line_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # Line coordinates\n",
    "line_points = [(200, 20), (200, 420)]  # Line coordinates\n",
    "\n",
    "# Initialize the video writer to save the output video\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize the Object Counter with visualization options and other parameters\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  # Display the image during processing\n",
    "    region=line_points,  # Region of interest points\n",
    "    model=\"yolo11l.pt\",  # Ultralytics YOLO11 model file\n",
    "    # line_width=2,  # Thickness of the lines and bounding boxes\n",
    ")\n",
    "\n",
    "# Process video frames in a loop\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Use the Object Counter to count objects in the frame and get the annotated image\n",
    "    results = counter(im0)\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a counting example\n",
    "!yolo solutions count show=True\n",
    "\n",
    "# Pass a source video\n",
    "!yolo solutions count source=\"path/to/video.mp4\"\n",
    "\n",
    "# Pass region coordinates\n",
    "!yolo solutions count region=\"[(20, 400), (1080, 400), (1080, 360), (20, 360)]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"path/to/video.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# region_points = [(20, 400), (1080, 400)]                                      # line counting\n",
    "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # rectangle region\n",
    "region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]# rectangle region\n",
    "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]   # polygon region\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize object counter object\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  # display the output\n",
    "    region=region_points,  # pass region points\n",
    "    model=\"yolo11n.pt\",  # model=\"yolo11n-obb.pt\" for object counting with OBB model.\n",
    "    # classes=[0, 2],  # count specific classes i.e. person and car with COCO pretrained model.\n",
    "    # tracker=\"botsort.yaml\",  # choose trackers i.e \"bytetrack.yaml\"\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "\n",
    "    results = counter(im0)\n",
    "\n",
    "    # print(results)  # access the output\n",
    "\n",
    "    video_writer.write(results.plot_im)  # write the processed frame.\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()  # destroy all opened windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/conveyer apple and bottle counting/istockphoto-911614972-640_adpp_is.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Pass region as list\n",
    "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]\n",
    "\n",
    "# Pass region as dictionary\n",
    "region_points = {\n",
    "    \"region-01\": [(50, 50), (250, 50), (250, 350), (50, 350)],\n",
    "    \"region-02\": [(640, 640), (780, 640), (780, 720), (640, 720)],\n",
    "}\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"region_counting.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize region counter object\n",
    "regioncounter = solutions.RegionCounter(\n",
    "    show=True,  # display the frame\n",
    "    region=region_points,  # pass region points\n",
    "    model=\"yolo11n.pt\",  # model for counting in regions i.e yolo11s.pt\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "\n",
    "    results = regioncounter(im0)\n",
    "\n",
    "    # print(results)  # access the output\n",
    "\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()  # destroy all opened windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85bdf61",
   "metadata": {},
   "source": [
    "### Trackzone Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988052a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_10.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define region points\n",
    "# region_points = [(150, 150), (1130, 150), (1130, 570), (150, 570)]\n",
    "region_points = [(0, 0), (1130, 0), (1130, 480), (0, 480)]\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init trackzone (object tracking in zones, not complete frame)\n",
    "trackzone = solutions.TrackZone(\n",
    "    show=True,  # display the output\n",
    "    region=region_points,  # pass region points\n",
    "    model=\"yolo11n.pt\",\n",
    "    classes=[0, 47],\n",
    "    conf=0.5,\n",
    "    iou=0.99,\n",
    "    tracker='bytetrack.yaml',\n",
    "    # track_high_thresh=0.5\n",
    "    \n",
    "    # tracker=\"bytetrack.yaml\",  # use ByteTrack for tracking\n",
    "    # track_high_thresh=0.5\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "    results = trackzone(im0)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37dcbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_11.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "        result = model.track(frame, persist=True, conf=0.5, iou=0.99, max_det=1000, classes=[0])[0]\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        if result.boxes and result.boxes.is_track:\n",
    "            boxes = result.boxes.xywh.cpu()\n",
    "            track_ids = result.boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # Visualize the result on the frame\n",
    "            frame = result.plot()\n",
    "\n",
    "            # Plot the tracks\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))  # x, y center point\n",
    "                if len(track) > 30:  # retain 30 tracks for 30 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                # Draw the tracking lines\n",
    "                points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLO11 Tracking\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_11.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"instance-segmentation.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init InstanceSegmentation\n",
    "isegment = solutions.InstanceSegmentation(\n",
    "    show=True,  # display the output\n",
    "    model=\"yolo11n-seg.pt\",  # model=\"yolo11n-seg.pt\" for object segmentation using YOLO11.\n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "    results = isegment(im0)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c160be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "cap = cv2.VideoCapture(\"./media_files/ice skatting object traking/computer_vision_object_and_detection_tracking_ice_skatting_object_traking_video_20250819_173636_11.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"instance-segmentation.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init InstanceSegmentation\n",
    "isegment = solutions.InstanceSegmentation(\n",
    "    show=True,  # display the output\n",
    "    model=\"yolo11n-seg.pt\",  # model=\"yolo11n-seg.pt\" for object segmentation using YOLO11.\n",
    "    classes=[0],\n",
    "    conf=0.5,\n",
    "    iou=0.99,\n",
    "    \n",
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or processing is complete.\")\n",
    "        break\n",
    "    results = isegment(im0)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
=======
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b8d00",
   "metadata": {},
   "source": [
    "# VisionEye Object Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor objects position with visioneye\n",
    "!yolo solutions visioneye show=True\n",
    "\n",
    "# Pass a source video\n",
    "!yolo solutions visioneye source=\"path/to/video.mp4\"\n",
    "\n",
    "# Monitor the specific classes\n",
    "!yolo solutions visioneye classes=\"[0, 5]\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfc7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
<<<<<<< HEAD
    "cap = cv2.VideoCapture(\"./media_files/people walking/computer_vision_object_and_detection_tracking_people_walking_video_20250811_121906_1.mp4\")\n",
=======
    "cap = cv2.VideoCapture(\"./media_files/istockphoto-1423119278-640_adpp_is.mp4\")\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Video writer\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "video_writer = cv2.VideoWriter(\"vision-eye-mapping.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init vision eye object\n",
    "visioneye = solutions.VisionEye(\n",
    "    show=True,  # display the output\n",
    "    model=\"yolo11m.pt\",  # use any model that Ultralytics support, i.e, YOLOv10\n",
<<<<<<< HEAD
    "    classes=[0, 2],  # generate visioneye view for specific classes\n",
    "    vision_point=(750, 350),  # pass region points\n",
    "    verbose=True,  # print additional information\n",
    "    conf=0.5,\n",
    "    iou=0.99\n",
=======
    "    # classes=[0, 2],  # generate visioneye view for specific classes\n",
    "    vision_point=(750, 350),  # pass region points\n",
    "    # verbose=True,  # print additional information\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    ")\n",
    "\n",
    "# Process video\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
<<<<<<< HEAD
    "    results = visioneye(im0)   #\n",
=======
    "    results = visioneye(im0)\n",
    "\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "    print(results)  # access the output\n",
    "\n",
    "    video_writer.write(results.plot_im)  # write the video file\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()  # destroy all opened windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d35ea2",
   "metadata": {},
   "source": [
    "# Object Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "\n",
    "def count_objects_in_region(video_path, output_video_path, model_path):\n",
    "    \"\"\"Count objects in a specific region within a video.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
<<<<<<< HEAD
    "    region_points = [(20, 260), (1080, 260), (1080, 220), (20, 220)]\n",
=======
    "    region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "    counter = solutions.ObjectCounter(show=True, region=region_points, model=model_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, im0 = cap.read()\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or processing is complete.\")\n",
    "            break\n",
    "        results = counter(im0)\n",
    "        video_writer.write(results.plot_im)\n",
    "\n",
    "    cap.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "count_objects_in_region(\"./media_files/apple counting/computer_vision_object_and_detection_tracking_apple_counting_video_20250819_173636_1.mp4\", \"output_video.avi\", \"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb30e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python examples/YOLOv8-Region-Counter/yolov8_region_counter.py"
=======
    "count_objects_in_region(\"path/to/video.mp4\", \"output_video.avi\", \"yolo11n.pt\")"
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59aaff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f289297c",
   "metadata": {},
   "source": [
    "## Promt: rename video files dynamically with preset string from a folder using python on jupyter notebook code\n",
    "### Deepseek understanding: Python script for dynamically renaming video files in a folder with a preset string pattern using Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def rename_videos(folder_path, preset_string, extension='.mp4'):\n",
    "    \"\"\"\n",
    "    Renames all video files in a folder with a preset string + timestamp.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing videos.\n",
    "        preset_string (str): Base name for files (e.g., \"Security_Footage\").\n",
    "        extension (str): File extension to filter (default: '.mp4').\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(extension)]\n",
    "    if not files:\n",
    "        print(f\"No {extension} files found in '{folder_path}'.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(files)} video files to rename:\")\n",
    "    \n",
    "    for idx, old_name in enumerate(files, 1):\n",
    "        # Generate new name: preset_string + timestamp + index + extension\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        new_name = f\"{preset_string}_{timestamp}_{idx}{extension}\"\n",
    "        \n",
    "        old_path = os.path.join(folder_path, old_name)\n",
    "        new_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed: '{old_name}' â†’ '{new_name}'\")\n",
    "    \n",
    "    print(\"Renaming complete!\")\n",
    "\n",
    "# Example Usage\n",
<<<<<<< HEAD
    "folder_path = \"./media_files/People walking\"  # Replace with your folder path\n",
    "preset_string = \"CV_face_detection_and_recognition_people_walking\"  # Customize this\n",
=======
    "# folder_path = \"./media_files/People walking\"  # Replace with your folder path\n",
    "# preset_string = \"CV_face_detection_and_recognition_people_walking\"  # Customize this\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "\n",
    "# folder_path = \"./media_files/People walking\"  # Replace with your folder path\n",
    "# preset_string = \"CV_object_detection_traking_road_side\"  # Customize this\n",
    "\n",
<<<<<<< HEAD
    "# folder_path = \"./media_files/Apple counting\"  # Replace with your folder path\n",
    "# preset_string = \"CV_object_detection_and_recognition_apple_counting\"  # Customize this\n",
=======
    "folder_path = \"./media_files/Apple counting\"  # Replace with your folder path\n",
    "preset_string = \"CV_object_detection_and_recognition_apple_counting\"  # Customize this\n",
>>>>>>> 302d2d26dbbece0806ee2341c3a90065f0fa928f
    "\n",
    "\n",
    "\n",
    "rename_videos(folder_path, preset_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b75cc",
   "metadata": {},
   "source": [
    "## Promt: regenerate above-given funcion for all kind of video and image files extension. add file type as preset string. inside media_files folder, folder path slug or name also add to preset string\n",
    "### Deepseek understanding: an enhanced Python function that dynamically renames all video and image files in a folder, incorporating the folder name into the preset string and categorizing by file type:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def rename_media_files(folder_path, preset_string, verbose=True):\n",
    "    \"\"\"\n",
    "    Renames all video and image files in a folder with a structured name:\n",
    "    {preset_string}_{file_type}_{timestamp}_{index}.{ext}\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing files.\n",
    "        preset_string (str): Base name for files (e.g., \"Event\").\n",
    "        verbose (bool): Print detailed logs if True.\n",
    "    \"\"\"\n",
    "    # Supported video and image extensions\n",
    "    VIDEO_EXTENSIONS = ('.mp4', '.mov', '.avi', '.mkv', '.flv', '.webm')\n",
    "    IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n",
    "    ALL_EXTENSIONS = VIDEO_EXTENSIONS + IMAGE_EXTENSIONS\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith(ALL_EXTENSIONS)]\n",
    "    if not files:\n",
    "        print(f\"No video/image files found in '{folder_path}'.\")\n",
    "        return\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Found {len(files)} files to rename:\")\n",
    "    \n",
    "    for idx, old_name in enumerate(files, 1):\n",
    "        # Extract file extension and determine type\n",
    "        ext = os.path.splitext(old_name)[1].lower()\n",
    "        file_type = \"VIDEO\" if ext in VIDEO_EXTENSIONS else \"IMAGE\"\n",
    "        \n",
    "        # Generate new name: preset + type + timestamp + index + ext\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        new_name = f\"{preset_string}_{file_type}_{timestamp}_{idx}{ext}\"\n",
    "        \n",
    "        old_path = os.path.join(folder_path, old_name)\n",
    "        new_path = os.path.join(folder_path, new_name)\n",
    "        \n",
    "        os.rename(old_path, new_path)\n",
    "        if verbose:\n",
    "            print(f\"Renamed: '{old_name}' â†’ '{new_name}'\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Renaming complete!\")\n",
    "\n",
    "# Example Usage\n",
    "# folder_path = \"./media_files/Apple counting\"  # Replace with your folder\n",
    "# preset_string = \"Computer_vision_apple_conveyer\"     # Customize this\n",
    "\n",
    "folder_path = \"./media_files/People walking\"  # Replace with your folder\n",
    "preset_string = \"Computer_vision_object_and_face_detection\"     # Customize this\n",
    "rename_media_files(folder_path, preset_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17127205",
   "metadata": {},
   "source": [
    "## Promt: inside media_files folder, there are multiple folders. folder name also add to preset string\n",
    "### Deepseek understanding: the enhanced Python function that processes all subfolders inside media_files, incorporating each folder's name into the preset string while categorizing files by type (video/image):\n",
    "### Keywords:Dynamic Multi-Folder Media File Renamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b51c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def rename_all_media_files(root_folder=\"media_files\", base_preset=\"Media\"):\n",
    "    \"\"\"\n",
    "    Renames all video/image files in all subfolders of root_folder with structure:\n",
    "    `{base_preset}_{parent_folder}_{file_type}_{timestamp}_{index}.ext`\n",
    "    \n",
    "    Supported formats:\n",
    "    - Videos: .mp4, .mov, .avi, .mkv, .flv, .webm\n",
    "    - Images: .jpg, .jpeg, .png, .gif, .bmp, .tiff\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Parent folder containing subfolders with media files.\n",
    "        base_preset (str): Base name for all files (default: \"Media\").\n",
    "    \"\"\"\n",
    "    if not os.path.exists(root_folder):\n",
    "        print(f\"Error: Folder '{root_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Supported extensions\n",
    "    VIDEO_EXTS = ('.mp4', '.mov', '.avi', '.mkv', '.flv', '.webm')\n",
    "    IMAGE_EXTS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n",
    "    \n",
    "    total_renamed = 0\n",
    "\n",
    "    # Process each subfolder\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        # Slugify folder name\n",
    "        folder_slug = folder_name.replace(\" \", \"_\").lower()\n",
    "        \n",
    "        # Get all media files\n",
    "        files = [f for f in os.listdir(folder_path) \n",
    "                 if f.lower().endswith(VIDEO_EXTS + IMAGE_EXTS)]\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"\\nNo media files found in '{folder_name}'.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing '{folder_name}' ({len(files)} files):\")\n",
    "        \n",
    "        for idx, old_name in enumerate(files, 1):\n",
    "            # Determine file type\n",
    "            ext = os.path.splitext(old_name)[1].lower()\n",
    "            file_type = \"video\" if ext in VIDEO_EXTS else \"image\"\n",
    "            \n",
    "            # Generate new name\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            new_name = f\"{base_preset}_{folder_slug}_{file_type}_{timestamp}_{idx}{ext}\"\n",
    "            \n",
    "            # Rename\n",
    "            old_path = os.path.join(folder_path, old_name)\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            \n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"  Renamed [{file_type.upper()}] {old_name} â†’ {new_name}\")\n",
    "            total_renamed += 1\n",
    "\n",
    "    print(f\"\\nTotal files renamed: {total_renamed}\")\n",
    "\n",
    "# Example Usage\n",
    "rename_all_media_files(\n",
    "    root_folder=\"./media_files\",\n",
    "    base_preset=\"computer_vision_object_and_detection_tracking\"  # Customize this base name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30511839",
   "metadata": {},
   "source": [
    "## Promt: inside media_files folder, there are multiple folders. folder name also add to preset string except \"person\" named folder\n",
    "### Deepseek understanding: the enhanced Python function that processes all subfolders inside media_files, skipping folders named \"person\", while incorporating other folder names into the preset string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def rename_media_files_except_person(root_folder=\"media_files\", base_preset=\"Media\"):\n",
    "    \"\"\"\n",
    "    Renames all video/image files in subfolders (except 'person' folders) with structure:\n",
    "    `{base_preset}_{folder_name}_{file_type}_{timestamp}_{index}.ext`\n",
    "    \n",
    "    Args:\n",
    "        root_folder (str): Parent folder containing subfolders.\n",
    "        base_preset (str): Base name for all files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(root_folder):\n",
    "        print(f\"Error: Folder '{root_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Supported extensions\n",
    "    VIDEO_EXTS = ('.mp4', '.mov', '.avi', '.mkv', '.flv', '.webm')\n",
    "    IMAGE_EXTS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n",
    "    \n",
    "    total_renamed = 0\n",
    "\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        \n",
    "        # Skip if not a folder or folder is named 'person' (case-insensitive)\n",
    "        if not os.path.isdir(folder_path) or folder_name.lower() == \"person\":\n",
    "            continue\n",
    "\n",
    "        # Slugify folder name\n",
    "        folder_slug = folder_name.replace(\" \", \"_\").lower()\n",
    "        \n",
    "        files = [f for f in os.listdir(folder_path) \n",
    "                if f.lower().endswith(VIDEO_EXTS + IMAGE_EXTS)]\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"\\nNo media files in '{folder_name}' (skipped 'person' folders)\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nProcessing '{folder_name}':\")\n",
    "        \n",
    "        for idx, old_name in enumerate(files, 1):\n",
    "            ext = os.path.splitext(old_name)[1].lower()\n",
    "            file_type = \"video\" if ext in VIDEO_EXTS else \"image\"\n",
    "            \n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            new_name = f\"{base_preset}_{folder_slug}_{file_type}_{timestamp}_{idx}{ext}\"\n",
    "            \n",
    "            old_path = os.path.join(folder_path, old_name)\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "            \n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"  Renamed: {old_name} â†’ {new_name}\")\n",
    "            total_renamed += 1\n",
    "\n",
    "    print(f\"\\nTotal renamed: {total_renamed} (skipped 'person' folders)\")\n",
    "\n",
    "# Usage\n",
    "rename_media_files_except_person(\n",
    "    root_folder=\"./media_files\",\n",
    "    base_preset=\"computer_vision_object_and_detection_tracking\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_YOLO_WITH_FACE_RECOGNITION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
