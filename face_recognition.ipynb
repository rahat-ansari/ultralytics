{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# Improved Face Recognition and Security Monitoring System\n",
    "# Enhanced for readability, maintainability, performance, and robustness\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "# Constants for better maintainability\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11l.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"/media_files/WIN_20251103_14_11_20_Pro.mp4\"\n",
    "    # VIDEO_SOURCE: str = 0\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    FACE_CONFIDENCE: float = 0.5\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "    \n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\", \n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\", \n",
    "        \"book\", \"scissors\", \"knife\"\n",
    "    ])\n",
    "    # New stricter recognition controls\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0\n",
    "\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Enhanced security monitoring system with face recognition and object detection.\n",
    "    \n",
    "    Features:\n",
    "    - Modular design with separate concerns\n",
    "    - Robust error handling\n",
    "    - Performance optimizations\n",
    "    - Comprehensive logging\n",
    "    - Configurable parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Config):\n",
    "        \"\"\"Initialize the security system with given configuration.\"\"\"\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "        \n",
    "        # Initialize models and resources\n",
    "        self.yolo_model = None\n",
    "        self.mp_face_detection = None\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "        self.alarm_loaded = False\n",
    "        \n",
    "        # State variables\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0\n",
    "        # detection history to reduce false positives per coarse person id\n",
    "        # { person_id: { 'name_counts': defaultdict(int), 'last_name': str, 'consecutive': int, 'last_update': float } }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "        \n",
    "        self._initialize_resources()\n",
    "    \n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        \"\"\"Setup logging configuration.\"\"\"\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Create logs directory\n",
    "        os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "        \n",
    "        # File handler\n",
    "        log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "        \n",
    "        logger.addHandler(file_handler)\n",
    "        return logger\n",
    "    \n",
    "    def _initialize_resources(self) -> None:\n",
    "        \"\"\"Initialize all required models and resources.\"\"\"\n",
    "        try:\n",
    "            # Initialize YOLO model\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "            \n",
    "            # Initialize MediaPipe\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0, \n",
    "                min_detection_confidence=self.config.FACE_CONFIDENCE\n",
    "            )\n",
    "            \n",
    "            # Load known faces\n",
    "            self._load_known_faces()\n",
    "            \n",
    "            # Setup alarm\n",
    "            self._setup_alarm()\n",
    "            \n",
    "            self.logger.info(\"System initialization completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize resources: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _load_known_faces(self) -> None:\n",
    "        \"\"\"Load known faces from directory with error handling.\"\"\"\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(f\"Known faces directory {self.config.KNOWN_FACES_DIR} not found\")\n",
    "            return\n",
    "        \n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "                \n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(self.config.KNOWN_FACES_DIR, person_name, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    \n",
    "                    if encodings:\n",
    "                        self.known_face_encodings.append(encodings[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                    else:\n",
    "                        self.logger.warning(f\"No faces found in {image_path}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error loading {image_path}: {e}\")\n",
    "        \n",
    "        unique_people = len(set(self.known_face_names))\n",
    "        self.logger.info(f\"Loaded {len(self.known_face_encodings)} face encodings for {unique_people} people\")\n",
    "    \n",
    "    def _setup_alarm(self) -> None:\n",
    "        \"\"\"Setup alarm sound system.\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm system initialized\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Alarm file {self.config.ALARM_FILE} not found\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to setup alarm: {e}\")\n",
    "    \n",
    "    def detect_objects(self, frame: np.ndarray) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect objects using YOLO model.\"\"\"\n",
    "        try:\n",
    "            results = self.yolo_model(frame, imgsz=640, verbose=False)\n",
    "            detections = []\n",
    "            \n",
    "            for result in results:\n",
    "                if result.boxes is None:\n",
    "                    continue\n",
    "                    \n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls]\n",
    "                    \n",
    "                    # Validate bounding box\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                        \n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'class_id': cls\n",
    "                    })\n",
    "            \n",
    "            return detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Object detection failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def detect_faces_mediapipe(self, roi: np.ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Detect faces in a region of interest using MediaPipe.\"\"\"\n",
    "        try:\n",
    "            rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb_roi)\n",
    "            \n",
    "            face_boxes = []\n",
    "            if results.detections:\n",
    "                h, w = roi.shape[:2]\n",
    "                for detection in results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x = int(bbox.xmin * w)\n",
    "                    y = int(bbox.ymin * h)\n",
    "                    width = int(bbox.width * w)\n",
    "                    height = int(bbox.height * h)\n",
    "                    face_boxes.append((x, y, width, height))\n",
    "            \n",
    "            return face_boxes\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face detection failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def recognize_face(self, face_roi: np.ndarray) -> Optional[str]:\n",
    "        \"\"\"Recognize face in given region of interest.\"\"\"\n",
    "        try:\n",
    "            if not self.known_face_encodings:\n",
    "                return None\n",
    "            \n",
    "            # Resize for performance\n",
    "            small_roi = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            rgb_small_roi = cv2.cvtColor(small_roi, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            face_locations = face_recognition.face_locations(rgb_small_roi)\n",
    "            if not face_locations:\n",
    "                return None\n",
    "            \n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_roi, face_locations)\n",
    "            if not face_encodings:\n",
    "                return None\n",
    "            \n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)\n",
    "                if any(matches):\n",
    "                    distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(distances)\n",
    "                    if matches[best_match_index]:\n",
    "                        return self.known_face_names[best_match_index]\n",
    "            \n",
    "            return \"Unknown\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face recognition failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def draw_detections(self, frame: np.ndarray, detections: List[Dict[str, Any]], \n",
    "                       person_results: List[Dict[str, Any]]) -> np.ndarray:\n",
    "        \"\"\"Draw detection results on frame.\"\"\"\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # Draw object detections\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != \"person\":\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display_frame, label, (x1, y1 - 10), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "        \n",
    "        # Draw person detections with recognition results\n",
    "        for person in person_results:\n",
    "            x1, y1, x2, y2 = person['bbox']\n",
    "            color = (0, 255, 0) if person.get('recognized') else (0, 0, 255)\n",
    "            \n",
    "            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            label = person.get('name', 'Person') if person.get('recognized') else \"UNKNOWN\"\n",
    "            cv2.putText(display_frame, label, (x1, y1 - 10), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "            # Draw face bounding boxes if available\n",
    "            for face_bbox in person.get('face_boxes', []):\n",
    "                fx1, fy1, fx2, fy2 = face_bbox\n",
    "                cv2.rectangle(display_frame, (fx1 + x1, fy1 + y1), (fx2 + x1, fy2 + y1), (255, 0, 0), 2)\n",
    "                cv2.putText(display_frame, \"Face\", (fx1 + x1 + 5, fy1 + y1 - 5), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        \n",
    "        return display_frame\n",
    "    \n",
    "    def process_alert(self, person_name: str, detected_objects: List[str]) -> None:\n",
    "        \"\"\"Handle alert logic with cooldown.\"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_alert_time > self.config.ALERT_COOLDOWN:\n",
    "            self._trigger_alert(person_name, detected_objects)\n",
    "            self.last_alert_time = current_time\n",
    "    \n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str]) -> None:\n",
    "        \"\"\"Trigger alert mechanisms.\"\"\"\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        \n",
    "        self.logger.info(f\"ALERT: Known person {person_name} detected with objects: {objects_str}\")\n",
    "        print(f\"✅ Known Person Detected: {person_name}\")\n",
    "        \n",
    "        # Play alarm if available\n",
    "        if self.alarm_loaded and not pygame.mixer.music.get_busy():\n",
    "            try:\n",
    "                pygame.mixer.music.play()\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed to play alarm: {e}\")\n",
    "        \n",
    "        # Email alert could be implemented here\n",
    "        # send_email_alert(person_name, detected_objects)\n",
    "    \n",
    "    # --- New helper methods for robust recognition ---\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        \"\"\"Compute a coarse person id from bbox center quantized to reduce jitter.\"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    def _update_detection_history(self, person_id: str, name: str) -> None:\n",
    "        \"\"\"Update per-person recent votes and consecutive counts.\"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            from collections import defaultdict\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        # Reset history if stale\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            from collections import defaultdict\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "\n",
    "        # Tally vote and consecutive\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        \"\"\"Decide whether the name is confirmed for the person_id using votes / consecutive frames / strict distance.\"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        # Quick accept if distance is very small (very confident)\n",
    "        if name != \"UNKNOWN\" and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        # Accept if enough votes in time window\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != \"UNKNOWN\" and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        # Accept if same name seen consecutively sufficient frames\n",
    "        if name != \"UNKNOWN\" and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face_from_roi(self, face_roi: np.ndarray, bbox: Tuple[int, int, int, int]) -> Optional[Tuple[str, float]]:\n",
    "        \"\"\"Attempt recognition for the face_roi. Returns (name, distance) if confirmed, else None.\"\"\"\n",
    "        try:\n",
    "            if not self.known_face_encodings:\n",
    "                return None\n",
    "            # resize & convert\n",
    "            small = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb)\n",
    "            if not face_locations:\n",
    "                return None\n",
    "            encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "            if not encodings:\n",
    "                return None\n",
    "            # Use first face encoding for person ROI (speed)\n",
    "            enc = encodings[0]\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, enc)\n",
    "            if distances is None or len(distances) == 0:\n",
    "                return None\n",
    "            best_idx = int(np.argmin(distances))\n",
    "            best_dist = float(distances[best_idx])\n",
    "            candidate_name = self.known_face_names[best_idx] if best_dist <= max(self.config.FACE_CONFIDENCE, self.config.RECOGNITION_DISTANCE_THRESHOLD) else \"UNKNOWN\"\n",
    "            person_id = self._get_person_id(bbox)\n",
    "            self._update_detection_history(person_id, candidate_name)\n",
    "            confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "            if confirmed and candidate_name != \"UNKNOWN\":\n",
    "                return candidate_name, best_dist\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"confirm_face_from_roi failed: {e}\")\n",
    "            return None\n",
    "    # --- end helpers ---\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Process a single frame and return annotated frame.\"\"\"\n",
    "        self.frame_count += 1\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # Detect objects\n",
    "        detections = self.detect_objects(frame)\n",
    "        \n",
    "        # Separate persons and objects\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections \n",
    "                          if d['class_name'] in self.config.OBJECTS_OF_INTEREST \n",
    "                          and d['class_name'] != 'person']\n",
    "        \n",
    "        person_results = []\n",
    "        \n",
    "        # Process each person\n",
    "        for person_det in person_detections:\n",
    "            x1, y1, x2, y2 = person_det['bbox']\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            result = {\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'recognized': False,\n",
    "                'name': None,\n",
    "                'face_boxes': []\n",
    "            }\n",
    "            \n",
    "            if person_roi.size > 0:\n",
    "                # Detect faces\n",
    "                face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "                result['face_boxes'] = face_boxes\n",
    "                \n",
    "                # Face recognition (interval-based)\n",
    "                if self.frame_count % self.config.FACE_RECOGNITION_INTERVAL == 0 and face_boxes:\n",
    "                    # pick first detected face for speed\n",
    "                    fx, fy, fw, fh = face_boxes[0]\n",
    "                    face_crop = person_roi[fy:fy+fh, fx:fx+fw]\n",
    "                    confirmed = self.confirm_face_from_roi(face_crop, (x1, y1, x2, y2))\n",
    "                    if confirmed:\n",
    "                        name, dist = confirmed\n",
    "                        result['recognized'] = True\n",
    "                        result['name'] = name\n",
    "                        \n",
    "                        self.process_alert(name, detected_objects)\n",
    "                    else:\n",
    "                        # not confirmed -> treat as unknown (do not trigger alert)\n",
    "                        self.logger.debug(\"Face not confirmed or unknown; skipping alert.\")\n",
    "            \n",
    "            person_results.append(result)  # ensure results are collected\n",
    "        \n",
    "        # Annotate frame\n",
    "        annotated_frame = self.draw_detections(frame, detections, person_results)\n",
    "        \n",
    "        # Add overlay information\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - cv2.getTickCount())\n",
    "        cv2.putText(annotated_frame, f\"FPS: {int(fps)}\", (20, 30), \n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        if detected_objects:\n",
    "            objects_text = f\"Objects: {', '.join(set(detected_objects))}\"\n",
    "            cv2.putText(annotated_frame, objects_text, (20, 60), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        \"\"\"Main execution loop.\"\"\"\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture device\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        \n",
    "        self.logger.info(\"Security monitoring started. Press 'q' to quit.\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                \n",
    "                # Process frame\n",
    "                annotated_frame = self.process_frame(frame)\n",
    "                \n",
    "                # Display\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated_frame)\n",
    "                \n",
    "                # Exit on 'q' press\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Monitoring interrupted by user\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Runtime error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "    \n",
    "    def _cleanup(self, cap) -> None:\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            pygame.mixer.quit()\n",
    "            self.logger.info(\"System shutdown completed\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Cleanup error: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    config = Config()\n",
    "    system = SecuritySystem(config)\n",
    "    system.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16268e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved known faces loader: multiple samples, CNN fallback, jittering and per-person averaging\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# Globals expected by other cells\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "known_faces_dir = \"family_members\"  # change if your folder is different\n",
    "\n",
    "def load_known_faces(known_faces_dir: str = \"family_members\", num_jitters: int = 5, use_cnn: bool = True):\n",
    "    \"\"\"Load known faces with higher accuracy:\n",
    "    - prefer CNN detector (more accurate) with fallback to HOG\n",
    "    - compute encodings with multiple jitters\n",
    "    - average multiple encodings per person into one template\n",
    "    \"\"\"\n",
    "    global known_face_encodings, known_face_names\n",
    "    encodings_map = {}  # person_name -> list of encodings\n",
    "\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        print(f\"Known faces directory '{known_faces_dir}' not found. Skipping load.\")\n",
    "        return\n",
    "\n",
    "    for person_name in sorted(os.listdir(known_faces_dir)):\n",
    "        person_dir = os.path.join(known_faces_dir, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "        encodings_map.setdefault(person_name, [])\n",
    "\n",
    "        for image_name in sorted(os.listdir(person_dir)):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            try:\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_locations = []\n",
    "\n",
    "                # Try CNN detector first for better accuracy, fallback to HOG on failure\n",
    "                if use_cnn:\n",
    "                    try:\n",
    "                        face_locations = face_recognition.face_locations(image, model=\"cnn\")\n",
    "                        if not face_locations:\n",
    "                            # fallback to hog if cnn finds nothing\n",
    "                            face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "                    except Exception:\n",
    "                        face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "                else:\n",
    "                    face_locations = face_recognition.face_locations(image, model=\"hog\")\n",
    "\n",
    "                if not face_locations:\n",
    "                    print(f\"No faces found in {image_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Use multiple jitters for more stable encodings (slower but better)\n",
    "                encs = face_recognition.face_encodings(image, face_locations, num_jitters=num_jitters)\n",
    "                if not encs:\n",
    "                    print(f\"Could not compute encodings for {image_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                for enc in encs:\n",
    "                    encodings_map[person_name].append(enc)\n",
    "\n",
    "                print(f\"Loaded {len(encs)} face(s) for '{person_name}' from {image_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "    # Average encodings per person to create a single robust template\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    for person_name, enc_list in encodings_map.items():\n",
    "        if not enc_list:\n",
    "            print(f\"Warning: No valid encodings collected for {person_name}\")\n",
    "            continue\n",
    "        enc_array = np.stack(enc_list)\n",
    "        if enc_array.shape[0] == 1:\n",
    "            averaged = enc_array[0]\n",
    "        else:\n",
    "            averaged = np.mean(enc_array, axis=0)\n",
    "        known_face_encodings.append(averaged)\n",
    "        known_face_names.append(person_name)\n",
    "\n",
    "    print(f\"Finished loading known faces. People loaded: {len(known_face_names)}. Total templates: {len(known_face_encodings)}\")\n",
    "\n",
    "# Run loader now so downstream cells can use the variables\n",
    "load_known_faces(known_faces_dir, num_jitters=5, use_cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef543fed",
   "metadata": {},
   "source": [
    "## Edited Nominal copy of face_recognition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9928ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Loaded face: robin from image1.jpg\n",
      "Loaded face: ruhama from image1.jpg\n",
      "Loaded face: ruhama from image2.jpg\n",
      "Loaded face: ruhama from image3.jpg\n",
      "Successfully loaded 4 face encodings for 2 people\n",
      "Security monitoring started. Press 'q' to quit.\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "✅ Known Person Detected: robin\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n",
      "⚠️ Unknown Person Detected!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import smtplib\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def detect_faces_mediapipe(frame):\n",
    "    \"\"\"\n",
    "    Detect faces using MediaPipe\n",
    "    Returns list of face bounding boxes in format [x, y, w, h]\n",
    "    \"\"\"\n",
    "    face_boxes = []\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        # Convert BGR to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(rgb_frame)\n",
    "        \n",
    "        if results.detections:\n",
    "            h, w, _ = frame.shape\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "                face_boxes.append([x, y, width, height])\n",
    "    \n",
    "    return face_boxes\n",
    "\n",
    "# Initialize YOLO model for object detection\n",
    "# model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Initialize MediaPipe for pose detection (not directly used for the requested features but kept for completeness)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Load known faces\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "known_faces_dir = \"family_members\" \n",
    "if os.path.exists(known_faces_dir):\n",
    "    for person_name in os.listdir(known_faces_dir):\n",
    "        person_dir = os.path.join(known_faces_dir, person_name)\n",
    "        if os.path.isdir(person_dir):\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    face_encodings = face_recognition.face_encodings(image)\n",
    "                    if face_encodings:\n",
    "                        known_face_encodings.append(face_encodings[0])\n",
    "                        known_face_names.append(person_name)\n",
    "                        print(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "if known_face_encodings:\n",
    "    print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
    "else:\n",
    "    print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
    "\n",
    "# Setup alarm sound\n",
    "pygame.mixer.init()\n",
    "alarm_file = \"pols-aagyi-pols.mp3\"\n",
    "if os.path.exists(alarm_file):\n",
    "    pygame.mixer.music.load(alarm_file)\n",
    "else:\n",
    "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
    "\n",
    "# Create log directory\n",
    "log_dir = \"security_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def log_event(event_type, details=\"\"):\n",
    "    \"\"\"Log security events to file\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_file = os.path.join(log_dir, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{timestamp} - {event_type}: {details}\\n\")\n",
    "\n",
    "# This function is not fully implemented for actual email sending, but logs the intent.\n",
    "def send_email_alert(person_status, person_name=\"N/A\", objects_detected=None):\n",
    "    \"\"\"Function to simulate sending email alert when a person is detected.\"\"\"\n",
    "    if objects_detected is None:\n",
    "        objects_detected = []\n",
    "    \n",
    "    objects_str = \", \".join(objects_detected) if objects_detected else \"None\"\n",
    "\n",
    "    if person_status == \"KNOWN\":\n",
    "        subject = f\"Security Alert: Known Person Detected - {person_name}\"\n",
    "        body = f\"A known person, {person_name}, was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
    "               f\"Objects detected: {objects_str}\"\n",
    "        print(f\"Simulating email alert for KNOWN person: {person_name} with objects: {objects_str}\")\n",
    "        log_event(\"EMAIL_ALERT_KNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
    "    elif person_status == \"UNKNOWN\":\n",
    "        subject = f\"URGENT Security Alert: Unknown Person Detected!\"\n",
    "        body = f\"An UNKNOWN person was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
    "               f\"Objects detected: {objects_str}\"\n",
    "        print(f\"Simulating email alert for UNKNOWN person with objects: {objects_str}\")\n",
    "        log_event(\"EMAIL_ALERT_UNKNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
    "    \n",
    "    # In a real application, you would add smtplib code here to send the email.\n",
    "    # For example:\n",
    "    # try:\n",
    "    #     server = smtplib.SMTP('smtp.your_email_provider.com', 587)\n",
    "    #     server.starttls()\n",
    "    #     server.login('your_email@example.com', 'your_password')\n",
    "    #     msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    #     server.sendmail('your_email@example.com', 'security_team@example.com', msg)\n",
    "    #     server.quit()\n",
    "    #     log_event(\"EMAIL_SENT\", f\"Subject: {subject}\")\n",
    "    # except Exception as e:\n",
    "    #     log_event(\"EMAIL_ERROR\", f\"Failed to send email: {e}\")\n",
    "\n",
    "\n",
    "# Start Video Capture\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"./media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture device\")\n",
    "    exit()\n",
    "\n",
    "# Performance optimization variables\n",
    "frame_count = 0\n",
    "face_recognition_interval = 5  # Process face recognition every 5 frames\n",
    "last_alert_time = 0\n",
    "alert_cooldown = 10  # Seconds between alerts for the same type of event\n",
    "\n",
    "# Define objects of interest (subset of COCO classes that YOLO can detect)\n",
    "objects_of_interest = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"mouse\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "    \"cell phone\", \"laptop\", \"book\", \"scissors\", \"knife\", \"face\"\n",
    "]\n",
    "\n",
    "print(\"Security monitoring started. Press 'q' to quit.\")\n",
    "log_event(\"SYSTEM_START\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        timer = cv2.getTickCount()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        process_faces = frame_count % face_recognition_interval == 0\n",
    "        current_time = time.time()\n",
    "        \n",
    "        results = model(frame, conf=0.5, verbose=False)        \n",
    "        \n",
    "        detected_objects = []\n",
    "        \n",
    "        # Iterate through YOLO results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            \n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "                \n",
    "                if x2 <= x1 or y2 <= y1:\n",
    "                    continue\n",
    "                \n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                class_name = result.names[cls]\n",
    "                \n",
    "                if class_name in objects_of_interest and class_name != \"person\":\n",
    "                    detected_objects.append(class_name)\n",
    "                    \n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2) # Cyan for other objects\n",
    "                    label = f\"{class_name}: {conf:.2f}\"\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                \n",
    "                if class_name == \"person\":\n",
    "                    person_roi = frame[y1:y2, x1:x2]\n",
    "                    \n",
    "                    person_status = \"UNKNOWN\" # Default to unknown\n",
    "                    person_name = \"UNKNOWN\"\n",
    "                    \n",
    "                    if person_roi.size > 0 and person_roi.shape[0] > 0 and person_roi.shape[1] > 0:\n",
    "                        face_boxes = detect_faces_mediapipe(person_roi)\n",
    "                        \n",
    "                        # for face_box in face_boxes:\n",
    "                        #     fx, fy, fw, fh = face_box\n",
    "                        #     face_x1 = x1 + fx\n",
    "                        #     face_y1 = y1 + fy\n",
    "                        #     face_x2 = face_x1 + fw\n",
    "                        #     face_y2 = face_y1 + fh\n",
    "                            \n",
    "                        #     cv2.rectangle(frame, (face_x1, face_y1), (face_x2, face_y2), (0, 255, 255), 2) # Red for face itself\n",
    "                        #     cv2.putText(frame, \"Face\", (face_x1 + 5, face_y1 - 5), \n",
    "                        #               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                                \n",
    "                        if process_faces and face_boxes: # Only process face recognition if faces are detected by MediaPipe\n",
    "                            rgb_small_frame = cv2.cvtColor(cv2.resize(person_roi, (0, 0), fx=0.25, fy=0.25), cv2.COLOR_BGR2RGB)\n",
    "                            face_locations_small = face_recognition.face_locations(rgb_small_frame)\n",
    "                            \n",
    "                            if face_locations_small:\n",
    "                                face_encodings_small = face_recognition.face_encodings(rgb_small_frame, face_locations_small)\n",
    "                                \n",
    "                                for face_encoding in face_encodings_small:\n",
    "                                    if known_face_encodings:\n",
    "                                        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                                        \n",
    "                                        if any(matches):\n",
    "                                            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                                            best_match_index = np.argmin(face_distances)\n",
    "                                            if matches[best_match_index]:\n",
    "                                                person_name = known_face_names[best_match_index]\n",
    "                                                person_status = \"KNOWN\"\n",
    "                                                break # Found a known person, no need to check other faces in this ROI\n",
    "                                    \n",
    "                    # Draw person box based on status\n",
    "                    if person_status == \"KNOWN\":\n",
    "                        box_color = (0, 255, 0)  # Green for known\n",
    "                        label = f\"KNOWN: {person_name}\"\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "                        print(f\"✅ Known Person Detected: {person_name}\")\n",
    "                        log_event(\"KNOWN_PERSON\", f\"Detected: {person_name} with objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "                        if current_time - last_alert_time > alert_cooldown:\n",
    "                            # send_email_alert(\"KNOWN\", person_name, detected_objects)\n",
    "                            last_alert_time = current_time\n",
    "                    else:\n",
    "                        box_color = (0, 165, 255) # Orange for unknown\n",
    "                        label = \"UNKNOWN\"\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "                        print(\"⚠️ Unknown Person Detected!\")\n",
    "                        log_event(\"UNKNOWN_PERSON\", f\"With objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "                        if current_time - last_alert_time > alert_cooldown:\n",
    "                            if os.path.exists(alarm_file) and not pygame.mixer.music.get_busy():\n",
    "                                pygame.mixer.music.play()\n",
    "                            # send_email_alert(\"UNKNOWN\", objects_detected=detected_objects)\n",
    "                            last_alert_time = current_time\n",
    "        \n",
    "        # Display detected objects summary\n",
    "        if detected_objects:\n",
    "            objects_text = f\"Objects: {', '.join(set(detected_objects))}\"\n",
    "            cv2.putText(frame, objects_text, (20, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # Calculate and display FPS\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Security Monitoring', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    log_event(\"SYSTEM_ERROR\", str(e))\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "    pygame.mixer.quit()\n",
    "    log_event(\"SYSTEM_SHUTDOWN\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecf50d",
   "metadata": {},
   "source": [
    "## Nominal copy of face_recognition.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import smtplib\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def detect_faces_mediapipe(frame):\n",
    "    \"\"\"\n",
    "    Detect faces using MediaPipe\n",
    "    Returns list of face bounding boxes in format [x, y, w, h]\n",
    "    \"\"\"\n",
    "    face_boxes = []\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        # Convert BGR to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(rgb_frame)\n",
    "        \n",
    "        if results.detections:\n",
    "            h, w, _ = frame.shape\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "                face_boxes.append([x, y, width, height])\n",
    "    \n",
    "    return face_boxes\n",
    "\n",
    "# Initialize YOLO model for object detection\n",
    "# model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "model = YOLO(\"yolo11m.pt\")\n",
    "\n",
    "# Initialize MediaPipe for pose detection (not directly used for the requested features but kept for completeness)\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Load known faces\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "known_faces_dir = \"family_members\"  # Create this directory and add images\n",
    "if os.path.exists(known_faces_dir):\n",
    "    for person_name in os.listdir(known_faces_dir):\n",
    "        person_dir = os.path.join(known_faces_dir, person_name)\n",
    "        if os.path.isdir(person_dir):\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    face_encodings = face_recognition.face_encodings(image)\n",
    "                    if face_encodings:\n",
    "                        known_face_encodings.append(face_encodings[0])\n",
    "                        known_face_names.append(person_name)\n",
    "                        print(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "if known_face_encodings:\n",
    "    print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
    "else:\n",
    "    print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
    "\n",
    "# Setup alarm sound\n",
    "pygame.mixer.init()\n",
    "alarm_file = \"pols-aagyi-pols.mp3\"\n",
    "if os.path.exists(alarm_file):\n",
    "    pygame.mixer.music.load(alarm_file)\n",
    "else:\n",
    "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
    "\n",
    "# Create log directory\n",
    "log_dir = \"security_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def log_event(event_type, details=\"\"):\n",
    "    \"\"\"Log security events to file\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_file = os.path.join(log_dir, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{timestamp} - {event_type}: {details}\\n\")\n",
    "\n",
    "# This function is not fully implemented for actual email sending, but logs the intent.\n",
    "def send_email_alert(person_status, person_name=\"N/A\", objects_detected=None):\n",
    "    \"\"\"Function to simulate sending email alert when a person is detected.\"\"\"\n",
    "    if objects_detected is None:\n",
    "        objects_detected = []\n",
    "    \n",
    "    objects_str = \", \".join(objects_detected) if objects_detected else \"None\"\n",
    "\n",
    "    if person_status == \"KNOWN\":\n",
    "        subject = f\"Security Alert: Known Person Detected - {person_name}\"\n",
    "        body = f\"A known person, {person_name}, was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
    "               f\"Objects detected: {objects_str}\"\n",
    "        print(f\"Simulating email alert for KNOWN person: {person_name} with objects: {objects_str}\")\n",
    "        log_event(\"EMAIL_ALERT_KNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
    "    elif person_status == \"UNKNOWN\":\n",
    "        subject = f\"URGENT Security Alert: Unknown Person Detected!\"\n",
    "        body = f\"An UNKNOWN person was detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\\n\" \\\n",
    "               f\"Objects detected: {objects_str}\"\n",
    "        print(f\"Simulating email alert for UNKNOWN person with objects: {objects_str}\")\n",
    "        log_event(\"EMAIL_ALERT_UNKNOWN\", f\"To: security_team@example.com, Subject: {subject}\")\n",
    "    \n",
    "    # In a real application, you would add smtplib code here to send the email.\n",
    "    # For example:\n",
    "    # try:\n",
    "    #     server = smtplib.SMTP('smtp.your_email_provider.com', 587)\n",
    "    #     server.starttls()\n",
    "    #     server.login('your_email@example.com', 'your_password')\n",
    "    #     msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    #     server.sendmail('your_email@example.com', 'security_team@example.com', msg)\n",
    "    #     server.quit()\n",
    "    #     log_event(\"EMAIL_SENT\", f\"Subject: {subject}\")\n",
    "    # except Exception as e:\n",
    "    #     log_event(\"EMAIL_ERROR\", f\"Failed to send email: {e}\")\n",
    "\n",
    "\n",
    "# Start Video Capture\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"./media_files/WIN_20251103_14_11_20_Pro.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture device\")\n",
    "    exit()\n",
    "\n",
    "# Performance optimization variables\n",
    "frame_count = 0\n",
    "face_recognition_interval = 5  # Process face recognition every 5 frames\n",
    "last_alert_time = 0\n",
    "alert_cooldown = 10  # Seconds between alerts for the same type of event\n",
    "\n",
    "# Define objects of interest (subset of COCO classes that YOLO can detect)\n",
    "objects_of_interest = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"mouse\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "    \"cell phone\", \"laptop\", \"book\", \"scissors\", \"knife\", \"face\"\n",
    "]\n",
    "\n",
    "print(\"Security monitoring started. Press 'q' to quit.\")\n",
    "log_event(\"SYSTEM_START\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        timer = cv2.getTickCount()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        process_faces = frame_count % face_recognition_interval == 0\n",
    "        current_time = time.time()\n",
    "        \n",
    "        results = model(frame, conf=0.5, verbose=False)        \n",
    "        \n",
    "        detected_objects = []\n",
    "        \n",
    "        # Iterate through YOLO results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            \n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "                \n",
    "                if x2 <= x1 or y2 <= y1:\n",
    "                    continue\n",
    "                \n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                class_name = result.names[cls]\n",
    "                \n",
    "                if class_name in objects_of_interest and class_name != \"person\":\n",
    "                    detected_objects.append(class_name)\n",
    "                    \n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2) # Cyan for other objects\n",
    "                    label = f\"{class_name}: {conf:.2f}\"\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                \n",
    "                if class_name == \"person\":\n",
    "                    person_roi = frame[y1:y2, x1:x2]\n",
    "                    \n",
    "                    person_status = \"UNKNOWN\" # Default to unknown\n",
    "                    person_name = \"UNKNOWN\"\n",
    "                    \n",
    "                    if person_roi.size > 0 and person_roi.shape[0] > 0 and person_roi.shape[1] > 0:\n",
    "                        face_boxes = detect_faces_mediapipe(person_roi)\n",
    "                        \n",
    "                        # for face_box in face_boxes:\n",
    "                        #     fx, fy, fw, fh = face_box\n",
    "                        #     face_x1 = x1 + fx\n",
    "                        #     face_y1 = y1 + fy\n",
    "                        #     face_x2 = face_x1 + fw\n",
    "                        #     face_y2 = face_y1 + fh\n",
    "                            \n",
    "                        #     cv2.rectangle(frame, (face_x1, face_y1), (face_x2, face_y2), (0, 255, 255), 2) # Red for face itself\n",
    "                        #     cv2.putText(frame, \"Chor\", (face_x1 + 5, face_y1 - 5), \n",
    "                        #               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                                \n",
    "                        if process_faces and face_boxes: # Only process face recognition if faces are detected by MediaPipe\n",
    "                            rgb_small_frame = cv2.cvtColor(cv2.resize(person_roi, (0, 0), fx=0.25, fy=0.25), cv2.COLOR_BGR2RGB)\n",
    "                            face_locations_small = face_recognition.face_locations(rgb_small_frame)\n",
    "                            \n",
    "                            if face_locations_small:\n",
    "                                face_encodings_small = face_recognition.face_encodings(rgb_small_frame, face_locations_small)\n",
    "                                \n",
    "                                for face_encoding in face_encodings_small:\n",
    "                                    if known_face_encodings:\n",
    "                                        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                                        \n",
    "                                        if any(matches):\n",
    "                                            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                                            best_match_index = np.argmin(face_distances)\n",
    "                                            if matches[best_match_index]:\n",
    "                                                person_name = known_face_names[best_match_index]\n",
    "                                                person_status = \"KNOWN\"\n",
    "                                                break # Found a known person, no need to check other faces in this ROI\n",
    "                                    \n",
    "                    # Draw person box based on status\n",
    "                    if person_status == \"KNOWN\":\n",
    "                        box_color = (0, 255, 0)  # Green for known\n",
    "                        label = f\"KNOWN: {person_name}\"\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "                        print(f\"✅ Known Person Detected: {person_name}\")\n",
    "                        log_event(\"KNOWN_PERSON\", f\"Detected: {person_name} with objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "                        if current_time - last_alert_time > alert_cooldown:\n",
    "                            # send_email_alert(\"KNOWN\", person_name, detected_objects)\n",
    "                            last_alert_time = current_time\n",
    "                    else:\n",
    "                        box_color = (0, 165, 255) # Orange for unknown\n",
    "                        label = \"UNKNOWN\"\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "                        print(\"⚠️ Unknown Person Detected!\")\n",
    "                        log_event(\"UNKNOWN_PERSON\", f\"With objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "                        if current_time - last_alert_time > alert_cooldown:\n",
    "                            if os.path.exists(alarm_file) and not pygame.mixer.music.get_busy():\n",
    "                                pygame.mixer.music.play()\n",
    "                            # send_email_alert(\"UNKNOWN\", objects_detected=detected_objects)\n",
    "                            last_alert_time = current_time\n",
    "        \n",
    "        # Display detected objects summary\n",
    "        if detected_objects:\n",
    "            objects_text = f\"Objects: {', '.join(set(detected_objects))}\"\n",
    "            cv2.putText(frame, objects_text, (20, 60), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # Calculate and display FPS\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Security Monitoring', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    log_event(\"SYSTEM_ERROR\", str(e))\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()\n",
    "    pygame.mixer.quit()\n",
    "    log_event(\"SYSTEM_SHUTDOWN\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb75ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa969b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11m.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    # use a neutral short filename to avoid word-checker flags\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"./media_files/WIN_20251103_14_11_20_Pro.mp4\"  # camera index or path\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    FACE_CONFIDENCE: float = 0.5\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "    \n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Enhanced security monitoring system with face recognition and object detection.\n",
    "\n",
    "    Features:\n",
    "    - Modular design with separate concerns\n",
    "    - Robust error handling\n",
    "    - Performance optimizations\n",
    "    - Comprehensive logging\n",
    "    - Configurable parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models and resources\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Per-person detection history to reduce false positives\n",
    "        # { person_id: { 'name_counts': defaultdict(int), 'last_name': str, 'consecutive': int, 'last_update': float } }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_CONFIDENCE\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "\n",
    "            self.logger.info(\"System initialization completed successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize resources: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        \"\"\"Load known faces from directory with error handling.\"\"\"\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(f\"Known faces directory {self.config.KNOWN_FACES_DIR} not found\")\n",
    "            return\n",
    "\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        self.known_face_encodings.append(encodings[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                    else:\n",
    "                        self.logger.warning(f\"No faces found in {image_path}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "        unique_people = len(set(self.known_face_names))\n",
    "        self.logger.info(f\"Loaded {len(self.known_face_encodings)} face encodings for {unique_people} people\")\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        \"\"\"Setup alarm sound system.\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm system initialized\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Alarm file {self.config.ALARM_FILE} not found\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to setup alarm: {e}\")\n",
    "\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect objects using YOLO model and return normalized detections.\"\"\"\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, imgsz=640, verbose=False)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'class_id': cls\n",
    "                    })\n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Object detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Detect faces in a region of interest using MediaPipe and return list of (x,y,w,h).\"\"\"\n",
    "        try:\n",
    "            rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb_roi)\n",
    "            face_boxes: List[Tuple[int, int, int, int]] = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for detection in results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x = int(bbox.xmin * w)\n",
    "                    y = int(bbox.ymin * h)\n",
    "                    width = int(bbox.width * w)\n",
    "                    height = int(bbox.height * h)\n",
    "                    face_boxes.append((x, y, width, height))\n",
    "            return face_boxes\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def recognize_face(self, face_roi: ndarray) -> Optional[str]:\n",
    "        \"\"\"Recognize face in given ROI; returns known name or 'Unknown' or None on failure.\"\"\"\n",
    "        try:\n",
    "            if not self.known_face_encodings:\n",
    "                return None\n",
    "            small_roi = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            rgb_small = cv2.cvtColor(small_roi, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_small)\n",
    "            if not face_locations:\n",
    "                return None\n",
    "            encodings = face_recognition.face_encodings(rgb_small, face_locations)\n",
    "            if not encodings:\n",
    "                return None\n",
    "            for enc in encodings:\n",
    "                matches = face_recognition.compare_faces(self.known_face_encodings, enc)\n",
    "                distances = face_recognition.face_distance(self.known_face_encodings, enc)\n",
    "                if len(distances) == 0:\n",
    "                    continue\n",
    "                best_index = int(np.argmin(distances))\n",
    "                if matches and matches[best_index]:\n",
    "                    return self.known_face_names[best_index]\n",
    "            return \"Unknown\"\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face recognition failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Robust recognition helpers (vote-based) to reduce false positives\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: float) -> None:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "    # def _update_detection_history(self, person_id: str, name: str, distance: Optional[float] = None) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Update per-person recent votes and consecutive counts.\n",
    "    #     Stores last_distance to avoid 'unused parameter' warnings and enable distance-aware logic.\n",
    "    #     \"\"\"\n",
    "    #     now = time.time()\n",
    "    #     entry = self.detection_history.get(person_id)\n",
    "    #     if entry is None:\n",
    "    #         entry = {\n",
    "    #             'name_counts': defaultdict(int),\n",
    "    #             'last_name': None,\n",
    "    #             'consecutive': 0,\n",
    "    #             'last_update': now,\n",
    "    #             'last_distance': None\n",
    "    #         }\n",
    "    #         self.detection_history[person_id] = entry\n",
    "\n",
    "    #     # Reset history if stale\n",
    "    #     if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "    #         entry['name_counts'] = defaultdict(int)\n",
    "    #         entry['last_name'] = None\n",
    "    #         entry['consecutive'] = 0\n",
    "    #         entry['last_distance'] = None\n",
    "\n",
    "    #     # Tally vote and consecutive\n",
    "    #     entry['name_counts'][name] += 1\n",
    "    #     if entry['last_name'] == name:\n",
    "    #         entry['consecutive'] += 1\n",
    "    #     else:\n",
    "    #         entry['last_name'] = name\n",
    "    #         entry['consecutive'] = 1\n",
    "    #     entry['last_update'] = now\n",
    "    #     entry['last_distance'] = distance\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        if name != \"UNKNOWN\" and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != \"UNKNOWN\" and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != \"UNKNOWN\" and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "    # def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "    #     \"\"\"\n",
    "    #     Decide whether the name is confirmed for the person_id using votes / consecutive frames / strict distance.\n",
    "    #     - For known names: accept if distance <= threshold OR votes/consecutive reached.\n",
    "    #     - For UNKNOWN: accept only if repeated UNKNOWN observations (votes or consecutive) indicate persistent unknown -> triggers alarm.\n",
    "    #     \"\"\"\n",
    "    #     now = time.time()\n",
    "    #     entry = self.detection_history.get(person_id)\n",
    "    #     if not entry:\n",
    "    #         return False\n",
    "    #     if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "    #         return False\n",
    "\n",
    "    #     # Confirm known persons by low distance OR votes / consecutive\n",
    "    #     if name != \"UNKNOWN\":\n",
    "    #         if distance is not None and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "    #             return True\n",
    "    #         votes = entry['name_counts'].get(name, 0)\n",
    "    #         if votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "    #             return True\n",
    "    #         if entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES and entry['last_name'] == name:\n",
    "    #             return True\n",
    "    #         return False\n",
    "\n",
    "    #     # Confirm UNKNOWN only by repeated observations (avoid single-frame false alarms)\n",
    "    #     # This prevents false alarms when a known person momentarily fails recognition.\n",
    "    #     unknown_votes = entry['name_counts'].get(\"UNKNOWN\", 0)\n",
    "    #     if unknown_votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "    #         return True\n",
    "    #     if entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES and entry['last_name'] == \"UNKNOWN\":\n",
    "    #         return True\n",
    "    #     return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"Return (name_or_None, confirmed_bool, distance_or_None).\"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"face_distance failed: {e}\")\n",
    "            return None, False, None\n",
    "        if distances is None or len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.FACE_CONFIDENCE else \"UNKNOWN\"\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != \"UNKNOWN\":\n",
    "            return candidate_name, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        \"\"\"Draw detection results on frame.\"\"\"\n",
    "        display = frame.copy()\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != \"person\":\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "        for person in person_results:\n",
    "            x1, y1, x2, y2 = person['bbox']\n",
    "            color = (0, 255, 0) if person.get('recognized') else (0, 165, 255)\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            label = person.get('name', 'Person') if person.get('recognized') else \"UNKNOWN\"\n",
    "            cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            for fx, fy, fw, fh in person.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), (255, 0, 0), 2)\n",
    "                cv2.putText(display, \"Face\", (x1 + fx + 5, y1 + fy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        return display\n",
    "\n",
    "    # def process_alert(self, person_name: str, detected_objects: List[str]) -> None:\n",
    "    #     current_time = time.time()\n",
    "    #     if current_time - self.last_alert_time > self.config.ALERT_COOLDOWN:\n",
    "    #         self._trigger_alert(person_name, detected_objects)\n",
    "    #         self.last_alert_time = current_time\n",
    "    def process_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Handle alert logic with cooldown.\n",
    "        Only triggers alarm sound for unknown persons (is_known == False).\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            # still in cooldown\n",
    "            return\n",
    "\n",
    "        # Only trigger alert for unknown persons to avoid false alarms for known people\n",
    "        if not is_known:\n",
    "            self._trigger_alert(person_name, detected_objects, is_known=False)\n",
    "            self.last_alert_time = current_time\n",
    "        else:\n",
    "            # Log known person detection but do not play alarm\n",
    "            self.logger.info(f\"Known person '{person_name}' detected. No alarm triggered.\")\n",
    "\n",
    "    # def _trigger_alert(self, person_name: str, detected_objects: List[str]) -> None:\n",
    "    #     objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "    #     self.logger.info(f\"ALERT: Known person {person_name} detected with objects: {objects_str}\")\n",
    "    #     if self.alarm_loaded and not pygame.mixer.music.get_busy():\n",
    "    #         try:\n",
    "    #             pygame.mixer.music.play()\n",
    "    #         except Exception as e:\n",
    "    #             self.logger.error(f\"Failed to play alarm: {e}\")\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Trigger alert mechanisms.\n",
    "        Plays alarm only when is_known is False.\n",
    "        \"\"\"\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            # Do not play alarm for verified known persons\n",
    "            self.logger.info(f\"ALERT(Logged only): Known person {person_name} detected with objects: {objects_str}\")\n",
    "            return\n",
    "\n",
    "        # Unknown person -> play alarm and log\n",
    "        self.logger.info(f\"ALERT: UNKNOWN person detected with objects: {objects_str}\")\n",
    "        try:\n",
    "            if self.alarm_loaded and not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to play alarm: {e}\")\n",
    "\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            result = {'bbox': (x1, y1, x2, y2), 'recognized': False, 'name': None, 'face_boxes': []}\n",
    "            if person_roi.size > 0:\n",
    "                face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "                result['face_boxes'] = face_boxes\n",
    "                if process_faces and face_boxes:\n",
    "                    # attempt recognition from the first face region for speed\n",
    "                    fx, fy, fw, fh = face_boxes[0]\n",
    "                    face_crop = person_roi[fy:fy+fh, fx:fx+fw]\n",
    "                    name = self.recognize_face(face_crop)\n",
    "                    if name:\n",
    "                        result['recognized'] = (name != \"Unknown\")\n",
    "                        result['name'] = name if name != \"Unknown\" else None\n",
    "                        if result['recognized'] and name:\n",
    "                            self.process_alert(name, detected_objects, is_known=True)\n",
    "                        else:\n",
    "                            self.process_alert(name, detected_objects, is_known=False)   \n",
    "                    # fx, fy, fw, fh = face_boxes[0]\n",
    "                    # # clamp coordinates to ROI bounds\n",
    "                    # h_roi, w_roi = person_roi.shape[:2]\n",
    "                    # x0 = max(0, fx); y0 = max(0, fy)\n",
    "                    # x1 = min(w_roi, fx + fw); y1 = min(h_roi, fy + fh)\n",
    "                    # if x1 > x0 and y1 > y0:\n",
    "                    #     face_crop = person_roi[y0:y1, x0:x1]\n",
    "                    #     name = self.recognize_face(face_crop)\n",
    "                    #     # if recognition failed (None), skip alerting\n",
    "                    #     if name is None:\n",
    "                    #         pass\n",
    "                    #     else:\n",
    "                    #         result['recognized'] = (name != \"Unknown\")\n",
    "                    #         result['name'] = name if name != \"Unknown\" else None\n",
    "                    #         self.process_alert(name, detected_objects, is_known=result['recognized']) \n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        if detected_objects:\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        return annotated\n",
    "    \n",
    "    # def process_frame(self, frame: ndarray) -> ndarray:\n",
    "    #     \"\"\"\n",
    "    #     Process a single frame and return annotated frame.\n",
    "    #     Updated to:\n",
    "    #       - confirm known faces and avoid alarms for them\n",
    "    #       - detect persistent UNKNOWN faces and trigger alarm only when unknown confirmed by voting/consecutive frames\n",
    "    #     \"\"\"\n",
    "    #     self.frame_count += 1\n",
    "    #     timer = cv2.getTickCount()\n",
    "    #     detections = self.detect_objects(frame)\n",
    "    #     person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "    #     detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "    #     person_results: List[Dict[str, Any]] = []\n",
    "    #     process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "    #     for det in person_detections:\n",
    "    #         x1, y1, x2, y2 = det['bbox']\n",
    "    #         person_roi = frame[y1:y2, x1:x2]\n",
    "    #         result = {'bbox': (x1, y1, x2, y2), 'recognized': False, 'name': None, 'face_boxes': []}\n",
    "\n",
    "    #         if person_roi.size > 0:\n",
    "    #             face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "    #             result['face_boxes'] = face_boxes\n",
    "\n",
    "    #             if process_faces and face_boxes:\n",
    "    #                 fx, fy, fw, fh = face_boxes[0]\n",
    "    #                 face_crop = person_roi[fy:fy+fh, fx:fx+fw]\n",
    "\n",
    "    #                 # Try to confirm a known person from face ROI\n",
    "    #                 confirmed = self.confirm_face_from_roi(face_crop, (x1, y1, x2, y2))\n",
    "    #                 person_id = self._get_person_id((x1, y1, x2, y2))\n",
    "\n",
    "    #                 if confirmed:\n",
    "    #                     # confirmed is (name, distance)\n",
    "    #                     name, dist = confirmed\n",
    "    #                     result['recognized'] = True\n",
    "    #                     result['name'] = name\n",
    "    #                     # update history already done in confirm_face_from_roi; ensure no alarm\n",
    "    #                     self.logger.info(f\"Recognized: {name} (dist={dist:.3f}) at id={person_id}\")\n",
    "    #                     # log but do not play alarm\n",
    "    #                     self.process_alert(name, detected_objects, is_known=True)\n",
    "    #                 else:\n",
    "    #                     # Not confirmed as known -> mark UNKNOWN in history and check if UNKNOWN is persistent\n",
    "    #                     # Use a placeholder distance value (e.g., large)\n",
    "    #                     placeholder_distance = 1.0\n",
    "    #                     self._update_detection_history(person_id, \"UNKNOWN\", placeholder_distance)\n",
    "\n",
    "    #                     # If UNKNOWN is confirmed by voting/consecutive then trigger alarm\n",
    "    #                     if self._confirm_recognition(person_id, \"UNKNOWN\", placeholder_distance):\n",
    "    #                         self.logger.info(f\"Persistent UNKNOWN detected at id={person_id} -> triggering alert\")\n",
    "    #                         self.process_alert(\"UNKNOWN\", detected_objects, is_known=False)\n",
    "    #                     else:\n",
    "    #                         self.logger.debug(f\"UNKNOWN observed at id={person_id} (not yet persistent)\")\n",
    "\n",
    "    #         person_results.append(result)\n",
    "\n",
    "    #     annotated = self.draw_detections(frame, detections, person_results)\n",
    "    #     elapsed = max(1, cv2.getTickCount() - timer)\n",
    "    #     fps = int(cv2.getTickFrequency() / elapsed)\n",
    "    #     cv2.putText(annotated, f\"FPS: {fps}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    #     if detected_objects:\n",
    "    #         cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "    #     return annotated\n",
    "      \n",
    "# ...existing code...\n",
    "    # def confirm_face_from_roi(self, face_roi: np.ndarray, bbox: Tuple[int, int, int, int]) -> Optional[Tuple[str, float]]:\n",
    "    #     \"\"\"Attempt recognition for the face_roi. Returns (name, distance) if confirmed, else None.\"\"\"\n",
    "    #     try:\n",
    "    #         if not self.known_face_encodings:\n",
    "    #             return None\n",
    "\n",
    "    #         # Resize for performance and convert to RGB\n",
    "    #         small = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "    #         rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #         # Detect faces and compute encodings\n",
    "    #         face_locations = face_recognition.face_locations(rgb)\n",
    "    #         if not face_locations:\n",
    "    #             return None\n",
    "    #         encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "    #         if not encodings:\n",
    "    #             return None\n",
    "\n",
    "    #         # Use first encoding for this ROI (speed)\n",
    "    #         enc = encodings[0]\n",
    "    #         distances = face_recognition.face_distance(self.known_face_encodings, enc)\n",
    "    #         if distances is None or len(distances) == 0:\n",
    "    #             return None\n",
    "\n",
    "    #         best_idx = int(np.argmin(distances))\n",
    "    #         best_dist = float(distances[best_idx])\n",
    "\n",
    "    #         # Determine candidate name using strict threshold (allow using recognition distance config)\n",
    "    #         threshold = max(self.config.FACE_CONFIDENCE, self.config.RECOGNITION_DISTANCE_THRESHOLD)\n",
    "    #         candidate_name = self.known_face_names[best_idx] if best_dist <= threshold else \"UNKNOWN\"\n",
    "\n",
    "    #         # Update history and confirm using voting/distance rules\n",
    "    #         person_id = self._get_person_id(bbox)\n",
    "    #         self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "    #         confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "\n",
    "    #         if confirmed and candidate_name != \"UNKNOWN\":\n",
    "    #             return candidate_name, best_dist\n",
    "\n",
    "    #         return None\n",
    "\n",
    "    #     except Exception as e:\n",
    "    #         self.logger.error(f\"confirm_face_from_roi failed: {e}\")\n",
    "    #         return None\n",
    "# ...existing code...\n",
    "\n",
    "\n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture device\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Security monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(frame)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Monitoring interrupted by user\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Runtime error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            pygame.mixer.quit()\n",
    "            self.logger.info(\"System shutdown completed\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Cleanup error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edf530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11n.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    # use a neutral short filename to avoid word-checker flags\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"./media_files/animal_surveillance/goru-churi.mp4\"  # camera index or path\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    FACE_CONFIDENCE: float = 0.5\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Enhanced security monitoring system with face recognition and object detection.\n",
    "\n",
    "    Features:\n",
    "    - Modular design with separate concerns\n",
    "    - Robust error handling\n",
    "    - Performance optimizations\n",
    "    - Comprehensive logging\n",
    "    - Configurable parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models and resources\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Per-person detection history to reduce false positives\n",
    "        # { person_id: { 'name_counts': defaultdict(int), 'last_name': str, 'consecutive': int, 'last_update': float } }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_CONFIDENCE\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "\n",
    "            self.logger.info(\"System initialization completed successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to initialize resources: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        \"\"\"Load known faces from directory with error handling.\"\"\"\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(f\"Known faces directory {self.config.KNOWN_FACES_DIR} not found\")\n",
    "            return\n",
    "\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    encodings = face_recognition.face_encodings(image)\n",
    "                    if encodings:\n",
    "                        self.known_face_encodings.append(encodings[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                    else:\n",
    "                        self.logger.warning(f\"No faces found in {image_path}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "        unique_people = len(set(self.known_face_names))\n",
    "        self.logger.info(f\"Loaded {len(self.known_face_encodings)} face encodings for {unique_people} people\")\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        \"\"\"Setup alarm sound system.\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm system initialized\")\n",
    "            else:\n",
    "                self.logger.warning(f\"Alarm file {self.config.ALARM_FILE} not found\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to setup alarm: {e}\")\n",
    "\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detect objects using YOLO model and return normalized detections.\"\"\"\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, imgsz=640, verbose=False)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({\n",
    "                        'bbox': (x1, y1, x2, y2),\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'class_id': cls\n",
    "                    })\n",
    "            return detections\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Object detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Detect faces in a region of interest using MediaPipe and return list of (x,y,w,h).\"\"\"\n",
    "        try:\n",
    "            rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb_roi)\n",
    "            face_boxes: List[Tuple[int, int, int, int]] = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for detection in results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    x = int(bbox.xmin * w)\n",
    "                    y = int(bbox.ymin * h)\n",
    "                    width = int(bbox.width * w)\n",
    "                    height = int(bbox.height * h)\n",
    "                    face_boxes.append((x, y, width, height))\n",
    "            return face_boxes\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face detection failed: {e}\")\n",
    "            return []\n",
    "\n",
    "    def recognize_face(self, face_roi: ndarray) -> Optional[str]:\n",
    "        \"\"\"Recognize face in given ROI; returns known name or 'Unknown' or None on failure.\"\"\"\n",
    "        try:\n",
    "            if not self.known_face_encodings:\n",
    "                return None\n",
    "            small_roi = cv2.resize(face_roi, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            rgb_small = cv2.cvtColor(small_roi, cv2.COLOR_BGR2RGB)\n",
    "            face_locations = face_recognition.face_locations(rgb_small)\n",
    "            if not face_locations:\n",
    "                return None\n",
    "            encodings = face_recognition.face_encodings(rgb_small, face_locations)\n",
    "            if not encodings:\n",
    "                return None\n",
    "            for enc in encodings:\n",
    "                matches = face_recognition.compare_faces(self.known_face_encodings, enc)\n",
    "                distances = face_recognition.face_distance(self.known_face_encodings, enc)\n",
    "                if len(distances) == 0:\n",
    "                    continue\n",
    "                best_index = int(np.argmin(distances))\n",
    "                if matches and matches[best_index]:\n",
    "                    return self.known_face_names[best_index]\n",
    "            return \"Unknown\"\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Face recognition failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Robust recognition helpers (vote-based) to reduce false positives\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: float) -> None:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        if name != \"UNKNOWN\" and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != \"UNKNOWN\" and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != \"UNKNOWN\" and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"Return (name_or_None, confirmed_bool, distance_or_None).\"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"face_distance failed: {e}\")\n",
    "            return None, False, None\n",
    "        if distances is None or len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.FACE_CONFIDENCE else \"UNKNOWN\"\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != \"UNKNOWN\":\n",
    "            return candidate_name, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        \"\"\"Draw detection results on frame.\"\"\"\n",
    "        display = frame.copy()\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != \"person\":\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "\n",
    "        for person in person_results:\n",
    "            x1, y1, x2, y2 = person['bbox']\n",
    "            color = (0, 255, 0) if person.get('recognized') else (0, 165, 255)\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            label = person.get('name', 'Person') if person.get('recognized') else \"UNKNOWN\"\n",
    "            cv2.putText(display, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            for fx, fy, fw, fh in person.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), (255, 0, 0), 2)\n",
    "                cv2.putText(display, \"Face\", (x1 + fx + 5, y1 + fy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        return display\n",
    "\n",
    "    def process_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Handle alert logic with cooldown.\n",
    "        Only triggers alarm sound for unknown persons (is_known == False).\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            # still in cooldown\n",
    "            return\n",
    "\n",
    "        # Only trigger alert for unknown persons to avoid false alarms for known people\n",
    "        if not is_known:\n",
    "            self._trigger_alert(person_name, detected_objects, is_known=False)\n",
    "            self.last_alert_time = current_time\n",
    "        else:\n",
    "            # Log known person detection but do not play alarm\n",
    "            self.logger.info(f\"Known person '{person_name}' detected. No alarm triggered.\")\n",
    "\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        \"\"\"\n",
    "        Trigger alert mechanisms.\n",
    "        Plays alarm only when is_known is False.\n",
    "        \"\"\"\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            # Do not play alarm for verified known persons\n",
    "            self.logger.info(f\"ALERT(Logged only): Known person {person_name} detected with objects: {objects_str}\")\n",
    "            return\n",
    "\n",
    "        # Unknown person -> play alarm and log\n",
    "        self.logger.info(f\"ALERT: UNKNOWN person detected with objects: {objects_str}\")\n",
    "        try:\n",
    "            if self.alarm_loaded and not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to play alarm: {e}\")\n",
    "\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            result = {'bbox': (x1, y1, x2, y2), 'recognized': False, 'name': None, 'face_boxes': []}\n",
    "            if person_roi.size > 0:\n",
    "                face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "                result['face_boxes'] = face_boxes\n",
    "                if process_faces and face_boxes:\n",
    "                    # attempt recognition from the first face region for speed\n",
    "                    # fx, fy, fw, fh = face_boxes[0]\n",
    "                    # face_crop = person_roi[fy:fy+fh, fx:fx+fw]\n",
    "                    # name = self.recognize_face(face_crop)\n",
    "                    # if name:\n",
    "                    #     result['recognized'] = (name != \"Unknown\")\n",
    "                    #     result['name'] = name if name != \"Unknown\" else None\n",
    "                    #     if result['recognized'] and name:\n",
    "                    #         self.process_alert(name, detected_objects, is_known=True)\n",
    "                    #     else:\n",
    "                    #         self.process_alert(name, detected_objects, is_known=False)   \n",
    "                    fx, fy, fw, fh = face_boxes[0]\n",
    "                    # clamp coordinates to ROI bounds\n",
    "                    h_roi, w_roi = person_roi.shape[:2]\n",
    "                    x0 = max(0, fx); y0 = max(0, fy)\n",
    "                    x1 = min(w_roi, fx + fw); y1 = min(h_roi, fy + fh)\n",
    "                    if x1 > x0 and y1 > y0:\n",
    "                        face_crop = person_roi[y0:y1, x0:x1]\n",
    "                        name = self.recognize_face(face_crop)\n",
    "                        # if recognition failed (None), skip alerting\n",
    "                        if name is None:\n",
    "                            pass\n",
    "                        else:\n",
    "                            result['recognized'] = (name != \"Unknown\")\n",
    "                            result['name'] = name if name != \"Unknown\" else None\n",
    "                            self.process_alert(name, detected_objects, is_known=result['recognized']) \n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        if detected_objects:\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        return annotated\n",
    "    \n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture device\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Security monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(frame)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Monitoring interrupted by user\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Runtime error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            pygame.mixer.quit()\n",
    "            self.logger.info(\"System shutdown completed\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Cleanup error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive refinement helper for the existing notebook (cell index 8)\n",
    "# Usage: run this cell in the same notebook. It will read `cfg` and `system` if available,\n",
    "# ask targeted questions, and print suggested code snippets you can apply manually.\n",
    "\n",
    "def _ask(prompt, default=None):\n",
    "  hint = f\" [{default}]\" if default is not None else \"\"\n",
    "  ans = input(f\"{prompt}{hint}: \").strip()\n",
    "  return ans if ans else default\n",
    "\n",
    "def refine_interactive():\n",
    "  ns = globals()\n",
    "  has_cfg = 'cfg' in ns\n",
    "  has_system = 'system' in ns\n",
    "  print(\"Refinement helper — select area to refine (enter number).\")\n",
    "  print(\"1) Thresholds (YOLO_CONFIDENCE, FACE_CONFIDENCE, RECOGNITION_DISTANCE_THRESHOLD)\")\n",
    "  print(\"2) Model / paths (MODEL_PATH, ALARM_FILE, KNOWN_FACES_DIR)\")\n",
    "  print(\"3) Recognition timing (FACE_RECOGNITION_INTERVAL, MIN_VOTES, CONSECUTIVE_FRAMES, TIME_WINDOW)\")\n",
    "  print(\"4) Alert behavior (ALERT_COOLDOWN, alarm on unknown/known)\")\n",
    "  print(\"5) Known-faces loader (num_jitters, use_cnn, averaging)\")\n",
    "  print(\"6) Performance (RESIZE_FACTOR, processing frequency)\")\n",
    "  print(\"7) Objects of interest list\")\n",
    "  print(\"8) Logging / outputs (log level, log dir, console/file)\")\n",
    "  print(\"9) Run/demo preferences (VIDEO_SOURCE, show window, dry-run)\")\n",
    "  print(\"0) Exit\")\n",
    "  choice = _ask(\"Choice\", \"0\")\n",
    "  suggestions = []\n",
    "  if choice == \"0\":\n",
    "    print(\"Exit. No changes.\")\n",
    "    return {}\n",
    "  if choice == \"1\":\n",
    "    yolo = _ask(\"YOLO_CONFIDENCE (current: cfg.YOLO_CONFIDENCE if available)\", str(getattr(ns.get('cfg'), 'YOLO_CONFIDENCE', '0.5')))\n",
    "    face = _ask(\"FACE_CONFIDENCE (current: cfg.FACE_CONFIDENCE if available)\", str(getattr(ns.get('cfg'), 'FACE_CONFIDENCE', '0.5')))\n",
    "    dist = _ask(\"RECOGNITION_DISTANCE_THRESHOLD (current: cfg.RECOGNITION_DISTANCE_THRESHOLD if available)\", str(getattr(ns.get('cfg'), 'RECOGNITION_DISTANCE_THRESHOLD', '0.45')))\n",
    "    suggestions.append(f\"cfg.YOLO_CONFIDENCE = {float(yolo)}\")\n",
    "    suggestions.append(f\"cfg.FACE_CONFIDENCE = {float(face)}\")\n",
    "    suggestions.append(f\"cfg.RECOGNITION_DISTANCE_THRESHOLD = {float(dist)}\")\n",
    "  elif choice == \"2\":\n",
    "    model = _ask(\"MODEL_PATH\", getattr(ns.get('cfg'), 'MODEL_PATH', 'yolo11n.pt'))\n",
    "    alarm = _ask(\"ALARM_FILE\", getattr(ns.get('cfg'), 'ALARM_FILE', 'pols-aagyi-pols.mp3'))\n",
    "    known = _ask(\"KNOWN_FACES_DIR\", getattr(ns.get('cfg'), 'KNOWN_FACES_DIR', 'family_members'))\n",
    "    suggestions.append(f\"cfg.MODEL_PATH = r'{model}'\")\n",
    "    suggestions.append(f\"cfg.ALARM_FILE = r'{alarm}'\")\n",
    "    suggestions.append(f\"cfg.KNOWN_FACES_DIR = r'{known}'\")\n",
    "  elif choice == \"3\":\n",
    "    interval = _ask(\"FACE_RECOGNITION_INTERVAL (frames)\", str(getattr(ns.get('cfg'), 'FACE_RECOGNITION_INTERVAL', '5')))\n",
    "    min_votes = _ask(\"RECOGNITION_MIN_VOTES\", str(getattr(ns.get('cfg'), 'RECOGNITION_MIN_VOTES', '2')))\n",
    "    cons = _ask(\"RECOGNITION_CONSECUTIVE_FRAMES\", str(getattr(ns.get('cfg'), 'RECOGNITION_CONSECUTIVE_FRAMES', '2')))\n",
    "    window = _ask(\"RECOGNITION_TIME_WINDOW (s)\", str(getattr(ns.get('cfg'), 'RECOGNITION_TIME_WINDOW', '3.0')))\n",
    "    suggestions.append(f\"cfg.FACE_RECOGNITION_INTERVAL = {int(interval)}\")\n",
    "    suggestions.append(f\"cfg.RECOGNITION_MIN_VOTES = {int(min_votes)}\")\n",
    "    suggestions.append(f\"cfg.RECOGNITION_CONSECUTIVE_FRAMES = {int(cons)}\")\n",
    "    suggestions.append(f\"cfg.RECOGNITION_TIME_WINDOW = {float(window)}\")\n",
    "  elif choice == \"4\":\n",
    "    cooldown = _ask(\"ALERT_COOLDOWN (s)\", str(getattr(ns.get('cfg'), 'ALERT_COOLDOWN', '10')))\n",
    "    alarm_for_known = _ask(\"Play alarm for KNOWN people? (yes/no)\", \"no\")\n",
    "    suggestions.append(f\"cfg.ALERT_COOLDOWN = {int(cooldown)}\")\n",
    "    if alarm_for_known.lower() in (\"yes\", \"y\"):\n",
    "      suggestions.append(\"# Note: enabling alarm for known people is not recommended; change system._trigger_alert accordingly.\")\n",
    "      suggestions.append(\"system.alarm_for_known = True  # custom flag (requires code change)\")\n",
    "  elif choice == \"5\":\n",
    "    jitters = _ask(\"Loader num_jitters (e.g., 0..10)\", \"5\")\n",
    "    use_cnn = _ask(\"Use CNN detector for loader? (yes/no)\", \"yes\")\n",
    "    suggestions.append(f\"# When calling loader: load_known_faces(num_jitters={int(jitters)}, use_cnn={'True' if use_cnn.lower() in ('yes','y') else 'False'})\")\n",
    "  elif choice == \"6\":\n",
    "    resize = _ask(\"RESIZE_FACTOR (0.1..1.0)\", str(getattr(ns.get('cfg'), 'RESIZE_FACTOR', '0.25')))\n",
    "    freq = _ask(\"Face recognition interval (frames)\", str(getattr(ns.get('cfg'), 'FACE_RECOGNITION_INTERVAL', '5')))\n",
    "    suggestions.append(f\"cfg.RESIZE_FACTOR = {float(resize)}\")\n",
    "    suggestions.append(f\"cfg.FACE_RECOGNITION_INTERVAL = {int(freq)}\")\n",
    "  elif choice == \"7\":\n",
    "    current = getattr(ns.get('cfg'), 'OBJECTS_OF_INTEREST', None)\n",
    "    print(\"Current objects of interest:\", current)\n",
    "    newlist = _ask(\"Enter comma-separated object names (leave empty to keep current)\", \"\")\n",
    "    if newlist:\n",
    "      objs = [s.strip() for s in newlist.split(\",\") if s.strip()]\n",
    "      suggestions.append(f\"cfg.OBJECTS_OF_INTEREST = {objs!r}\")\n",
    "  elif choice == \"8\":\n",
    "    level = _ask(\"Log level (DEBUG/INFO/WARNING/ERROR)\", \"INFO\")\n",
    "    logdir = _ask(\"LOG_DIR\", getattr(ns.get('cfg'), 'LOG_DIR', 'security_logs'))\n",
    "    suggestions.append(f\"# change logger level in system: system.logger.setLevel(logging.{level.upper()})\")\n",
    "    suggestions.append(f\"cfg.LOG_DIR = r'{logdir}'\")\n",
    "  elif choice == \"9\":\n",
    "    source = _ask(\"VIDEO_SOURCE (0 for webcam or path)\", str(getattr(ns.get('cfg'), 'VIDEO_SOURCE', 0)))\n",
    "    show = _ask(\"Show window? (yes/no)\", \"yes\")\n",
    "    suggestions.append(f\"cfg.VIDEO_SOURCE = {repr(int(source) if str(source).isdigit() else source)}\")\n",
    "    suggestions.append(f\"# To disable GUI: skip cv2.imshow calls or set show_window = {show.lower() in ('yes','y')}\")\n",
    "  else:\n",
    "    print(\"Invalid choice.\")\n",
    "    return {}\n",
    "\n",
    "  print(\"\\nSuggested code snippets to apply (copy & paste into a cell to apply):\\n\")\n",
    "  print(\"#### Start Snippet ####\")\n",
    "  for s in suggestions:\n",
    "    print(s)\n",
    "  print(\"####  End Snippet  ####\\n\")\n",
    "\n",
    "  apply_now = _ask(\"Apply these changes to runtime objects now? (will modify cfg/system in memory) (yes/no)\", \"no\")\n",
    "  applied = {}\n",
    "  if apply_now.lower() in ('yes', 'y'):\n",
    "    for s in suggestions:\n",
    "      # attempt to execute safe simple assignments only (avoid exec of comments)\n",
    "      if s.strip().startswith(\"#\") or \"note\" in s.lower():\n",
    "        continue\n",
    "      try:\n",
    "        exec(s, ns)\n",
    "        applied[s] = \"ok\"\n",
    "      except Exception as e:\n",
    "        applied[s] = f\"failed: {e}\"\n",
    "    print(\"Applied results:\", applied)\n",
    "  else:\n",
    "    print(\"No runtime changes applied. Paste snippets manually to change cfg/system.\")\n",
    "\n",
    "  return {'choice': choice, 'suggestions': suggestions, 'applied': applied}\n",
    "\n",
    "# Run the interactive helper\n",
    "refine_interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7245e975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 01:29:37,235 - INFO: Loading YOLO model...\n",
      "2025-11-22 01:29:37,351 - INFO: Initializing MediaPipe face detection...\n",
      "2025-11-22 01:29:37,998 - WARNING: No face found in family_members\\robin\\image10.jpg\n",
      "2025-11-22 01:29:38,605 - WARNING: No face found in family_members\\robin\\image12.jpg\n",
      "2025-11-22 01:29:39,232 - WARNING: No face found in family_members\\robin\\image14.jpg\n",
      "2025-11-22 01:29:39,840 - WARNING: No face found in family_members\\robin\\image7.jpg\n",
      "2025-11-22 01:29:40,449 - WARNING: No face found in family_members\\robin\\image8.jpg\n",
      "2025-11-22 01:29:41,433 - INFO: Loaded face for robin from robin_01.jpg\n",
      "2025-11-22 01:29:42,405 - INFO: Loaded face for robin from robin_02.jpg\n",
      "2025-11-22 01:29:43,454 - INFO: Loaded face for robin from robin_03.jpg\n",
      "2025-11-22 01:29:44,073 - WARNING: No face found in family_members\\robin\\WIN_20250929_13_24_25_Pro.jpg\n",
      "2025-11-22 01:29:44,681 - WARNING: No face found in family_members\\robin\\WIN_20250929_13_24_33_Pro.jpg\n",
      "2025-11-22 01:29:45,313 - WARNING: No face found in family_members\\robin\\WIN_20251001_12_21_20_Pro.jpg\n",
      "2025-11-22 01:29:45,912 - WARNING: No face found in family_members\\robin\\WIN_20251001_12_21_29_Pro.jpg\n",
      "2025-11-22 01:29:46,531 - WARNING: No face found in family_members\\robin\\WIN_20251001_12_21_49_Pro.jpg\n",
      "2025-11-22 01:29:47,218 - WARNING: No face found in family_members\\robin\\WIN_20251001_12_21_50_Pro.jpg\n",
      "2025-11-22 01:29:48,179 - INFO: Loaded face for robin from WIN_20251008_18_56_08_Pro.jpg\n",
      "2025-11-22 01:29:48,180 - INFO: Loaded 4 encodings for 1 people\n",
      "2025-11-22 01:29:48,457 - INFO: Alarm loaded\n",
      "2025-11-22 01:29:48,458 - INFO: Initialization complete\n",
      "2025-11-22 01:29:48,520 - INFO: Monitoring started. Press 'q' to quit.\n",
      "2025-11-22 01:29:55,686 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:29:56,220 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:29:57,269 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:29:58,331 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:29:58,954 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:29:59,490 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:00,168 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:01,317 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:01,914 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:02,479 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:03,145 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:03,689 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:04,255 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:04,776 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:06,468 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:09,333 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:09,932 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:13,138 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:13,730 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:14,245 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:23,444 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:23,966 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:26,230 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:27,540 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:28,077 - INFO: Known person confirmed: robin; objects: None (no alarm)\n",
      "2025-11-22 01:30:30,717 - WARNING: Failed to grab frame\n",
      "2025-11-22 01:30:30,797 - INFO: Shutdown complete\n"
     ]
    }
   ],
   "source": [
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import cv2\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11n.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"./media_files/WIN_20251103_14_11_20_Pro.mp4\"  # camera index or path\n",
    "    # Recommended default: 10 (good balance). Lower -> more CPU, higher -> slower recognition.\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    # MediaPipe face detection confidence threshold\n",
    "    FACE_DETECTION_CONF: float = 0.5\n",
    "    # Face distance threshold used to accept a name from face_distance\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\", \"face\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "\n",
    "    # Color & font constants\n",
    "    COLOR_YELLOW = (0, 255, 255)\n",
    "    COLOR_GREEN = (0, 255, 0)\n",
    "    COLOR_ORANGE = (0, 165, 255)\n",
    "    COLOR_BLUE = (255, 0, 0)\n",
    "    COLOR_WHITE = (255, 255, 255)\n",
    "\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE_SMALL = 0.5\n",
    "    FONT_SCALE_MEDIUM = 0.7\n",
    "    FONT_THICKNESS = 2\n",
    "\n",
    "    # Labels\n",
    "    UNKNOWN_LABEL = \"UNKNOWN\"\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Security system with improved, consistent face confirmation logic to reduce false alarms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "\n",
    "        # Known faces\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "\n",
    "        # Alarm\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Detection history per coarse person grid cell -> used to vote/confirm\n",
    "        # person_id -> { name_counts: defaultdict(int), last_name: str, consecutive: int, last_update: float }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_DETECTION_CONF\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "            self.logger.info(\"Initialization complete\")\n",
    "        except Exception as e:\n",
    "            self.logger.exception(\"Failed to initialize resources\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(\"Known faces dir not found: %s\", self.config.KNOWN_FACES_DIR)\n",
    "            return\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for img in os.listdir(person_dir):\n",
    "                path = os.path.join(person_dir, img)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(path)\n",
    "                    encs = face_recognition.face_encodings(image)\n",
    "                    if encs:\n",
    "                        self.known_face_encodings.append(encs[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(\"Loaded face for %s from %s\", person_name, img)\n",
    "                    else:\n",
    "                        self.logger.warning(\"No face found in %s\", path)\n",
    "                except Exception:\n",
    "                    self.logger.exception(\"Failed to load known face %s\", path)\n",
    "        self.logger.info(\"Loaded %d encodings for %d people\",\n",
    "                         len(self.known_face_encodings), len(set(self.known_face_names)))\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm loaded\")\n",
    "            else:\n",
    "                self.logger.warning(\"Alarm file missing: %s\", self.config.ALARM_FILE)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to initialize alarm\")\n",
    "\n",
    "    # ---------- Utility helpers ----------\n",
    "    def _extract_bbox(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int, int, int]:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "    def _clamp(self, v, lo, hi):\n",
    "        return max(lo, min(hi, v))\n",
    "\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    # ---------- Detection ----------\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, imgsz=640, verbose=False)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({'bbox': (x1, y1, x2, y2), 'class_name': class_name, 'confidence': conf, 'class_id': cls})\n",
    "            return detections\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Object detection failed\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb)\n",
    "            boxes = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for det in results.detections:\n",
    "                    r = det.location_data.relative_bounding_box\n",
    "                    x = int(r.xmin * w)\n",
    "                    y = int(r.ymin * h)\n",
    "                    width = int(r.width * w)\n",
    "                    height = int(r.height * h)\n",
    "                    boxes.append((x, y, width, height))\n",
    "            return boxes\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Face detection failed\")\n",
    "            return []\n",
    "\n",
    "    # Return a single face encoding (or None). Uses RESIZE_FACTOR to speed up encoding.\n",
    "    def get_face_encoding(self, face_crop: ndarray) -> Optional[ndarray]:\n",
    "        try:\n",
    "            if face_crop.size == 0:\n",
    "                return None\n",
    "            # resize for speed but keep enough detail; resizing can affect distances: tune RESIZE_FACTOR\n",
    "            if self.config.RESIZE_FACTOR and self.config.RESIZE_FACTOR != 1.0:\n",
    "                small = cv2.resize(face_crop, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            else:\n",
    "                small = face_crop\n",
    "            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "            encs = face_recognition.face_encodings(rgb)\n",
    "            if not encs:\n",
    "                return None\n",
    "            return encs[0]\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to get face encoding\")\n",
    "            return None\n",
    "\n",
    "    # ---------- Confirmation logic ----------\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: float) -> None:\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {'name_counts': defaultdict(int), 'last_name': None, 'consecutive': 0, 'last_update': now}\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        \"\"\"Confirm recognition using vote / consecutive / distance rules.\"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        # Immediate acceptance if distance is confidently low\n",
    "        if name != self.config.UNKNOWN_LABEL and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        # votes\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != self.config.UNKNOWN_LABEL and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != self.config.UNKNOWN_LABEL and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"\n",
    "        Given a face encoding, find best match and decide whether the match is confirmed.\n",
    "        Returns: (confirmed_name_or_None, confirmed_bool, best_distance)\n",
    "        \"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"face_distance failed\")\n",
    "            return None, False, None\n",
    "        if len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        # determine candidate name by using the recognition distance threshold (consistent)\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.RECOGNITION_DISTANCE_THRESHOLD else self.config.UNKNOWN_LABEL\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != self.config.UNKNOWN_LABEL:\n",
    "            return candidate_name, True, best_dist\n",
    "        # If candidate_name is UNKNOWN and it's confirmed (multiple unknown votes) consider it an unknown confirmed\n",
    "        if confirmed and candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            return self.config.UNKNOWN_LABEL, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    # ---------- Alerting ----------\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            self.logger.info(\"Known person confirmed: %s; objects: %s (no alarm)\", person_name, objects_str)\n",
    "            return\n",
    "        self.logger.warning(\"ALERT: UNKNOWN person confirmed; objects: %s\", objects_str)\n",
    "        if self.alarm_loaded:\n",
    "            try:\n",
    "                if not pygame.mixer.music.get_busy():\n",
    "                    pygame.mixer.music.play()\n",
    "            except Exception:\n",
    "                self.logger.exception(\"Failed to start alarm\")\n",
    "\n",
    "    def process_alert(self, candidate_name: Optional[str], confirmed: bool, detected_objects: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Only triggers alarm for a confirmed unknown person (confirmed True and candidate_name == UNKNOWN_LABEL).\n",
    "        Observed cooldown prevents repeated alarms.\n",
    "        \"\"\"\n",
    "        if not confirmed:\n",
    "            return\n",
    "        now = time.time()\n",
    "        if now - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            return\n",
    "        if candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=False)\n",
    "            self.last_alert_time = now\n",
    "        else:\n",
    "            # confirmed known person -> log but do not alarm\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=True)\n",
    "\n",
    "    # ---------- Drawing ----------\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        display = frame.copy()\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != 'person':\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), self.config.COLOR_YELLOW, 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, self.config.FONT_THICKNESS)\n",
    "\n",
    "        for p in person_results:\n",
    "            x1, y1, x2, y2 = p['bbox']\n",
    "            color = self.config.COLOR_GREEN if p.get('confirmed_known') else (self.config.COLOR_ORANGE if p.get('recognized') else self.config.COLOR_ORANGE)\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            label = p.get('name') if p.get('name') else (\"Person\" if p.get('recognized') else \"UNKNOWN\")\n",
    "            cv2.putText(display, label, (x1, y1 - 10), self.config.FONT, self.config.FONT_SCALE_MEDIUM, color, self.config.FONT_THICKNESS)\n",
    "            for fx, fy, fw, fh in p.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), self.config.COLOR_BLUE, 2)\n",
    "        return display\n",
    "\n",
    "    # ---------- Main frame processing ----------\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            result = {'bbox': (x1, y1, x2, y2), 'recognized': False, 'confirmed_known': False, 'name': None, 'face_boxes': []}\n",
    "            if person_roi.size == 0:\n",
    "                person_results.append(result)\n",
    "                continue\n",
    "            face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "            result['face_boxes'] = face_boxes\n",
    "            if process_faces and face_boxes:\n",
    "                fx, fy, fw, fh = face_boxes[0]\n",
    "                h_roi, w_roi = person_roi.shape[:2]\n",
    "                x0 = self._clamp(fx, 0, w_roi-1); y0 = self._clamp(fy, 0, h_roi-1)\n",
    "                x1f = self._clamp(fx+fw, 0, w_roi); y1f = self._clamp(fy+fh, 0, h_roi)\n",
    "                if x1f > x0 and y1f > y0:\n",
    "                    face_crop = person_roi[y0:y1f, x0:x1f]\n",
    "                    face_enc = self.get_face_encoding(face_crop)\n",
    "                    if face_enc is not None:\n",
    "                        name, confirmed, dist = self.confirm_face(face_enc, (x1, y1, x2, y2))\n",
    "                        # Only update UI / alerts if confirmed (reduces false positives)\n",
    "                        if confirmed:\n",
    "                            result['recognized'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                            result['confirmed_known'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                            result['name'] = name if name != self.config.UNKNOWN_LABEL else None\n",
    "                        else:\n",
    "                            # tentative recognized (not yet confirmed) - set recognized True if distance indicates a candidate\n",
    "                            # this is optional: here we leave recognized False until confirmed\n",
    "                            result['recognized'] = False\n",
    "                            result['name'] = None\n",
    "                        # process alert only for confirmed outcomes\n",
    "                        self.process_alert(name if confirmed else None, confirmed, detected_objects)\n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, 30), self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.COLOR_GREEN, self.config.FONT_THICKNESS)\n",
    "        if detected_objects:\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, 60), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, self.config.FONT_THICKNESS)\n",
    "        return annotated\n",
    "\n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(frame)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Interrupted\")\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            try:\n",
    "                pygame.mixer.quit()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self.logger.info(\"Shutdown complete\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Cleanup error\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7254bd",
   "metadata": {},
   "source": [
    "# Deepseek opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "import cv2\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11n.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"./media_files/animal_surveillance/goru-churi.mp4\"  # camera index or path\n",
    "    # VIDEO_SOURCE: str = 0  # camera index or path\n",
    "    # Recommended default: 10 (good balance). Lower -> more CPU, higher -> slower recognition.\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    # MediaPipe face detection confidence threshold\n",
    "    FACE_DETECTION_CONF: float = 0.5\n",
    "    # Face distance threshold used to accept a name from face_distance\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\", \"face\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "\n",
    "    # Color & font constants\n",
    "    COLOR_YELLOW = (0, 255, 255)\n",
    "    COLOR_GREEN = (0, 255, 0)\n",
    "    COLOR_ORANGE = (0, 165, 255)\n",
    "    COLOR_BLUE = (255, 0, 0)\n",
    "    COLOR_RED = (0, 0, 255)\n",
    "    COLOR_WHITE = (255, 255, 255)\n",
    "    COLOR_CYAN = (255, 255, 0)\n",
    "\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE_SMALL = 0.5\n",
    "    FONT_SCALE_MEDIUM = 0.7\n",
    "    FONT_THICKNESS = 2\n",
    "\n",
    "    # Labels\n",
    "    UNKNOWN_LABEL = \"UNKNOWN\"\n",
    "    PERSON_LABEL = \"Person\"\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Security system with improved, consistent face confirmation logic to reduce false alarms.\n",
    "    Enhanced to update person labels dynamically based on detection and recognition status.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "\n",
    "        # Known faces\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "\n",
    "        # Alarm\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Detection history per coarse person grid cell -> used to vote/confirm\n",
    "        # person_id -> { name_counts: defaultdict(int), last_name: str, consecutive: int, last_update: float }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Track current person states for consistent labeling\n",
    "        self.current_person_states: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_DETECTION_CONF\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "            self.logger.info(\"Initialization complete\")\n",
    "        except Exception as e:\n",
    "            self.logger.exception(\"Failed to initialize resources\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(\"Known faces dir not found: %s\", self.config.KNOWN_FACES_DIR)\n",
    "            return\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for img in os.listdir(person_dir):\n",
    "                path = os.path.join(person_dir, img)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(path)\n",
    "                    encs = face_recognition.face_encodings(image)\n",
    "                    if encs:\n",
    "                        self.known_face_encodings.append(encs[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(\"Loaded face for %s from %s\", person_name, img)\n",
    "                    else:\n",
    "                        self.logger.warning(\"No face found in %s\", path)\n",
    "                except Exception:\n",
    "                    self.logger.exception(\"Failed to load known face %s\", path)\n",
    "        self.logger.info(\"Loaded %d encodings for %d people\",\n",
    "                         len(self.known_face_encodings), len(set(self.known_face_names)))\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm loaded\")\n",
    "            else:\n",
    "                self.logger.warning(\"Alarm file missing: %s\", self.config.ALARM_FILE)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to initialize alarm\")\n",
    "\n",
    "    # ---------- Utility helpers ----------\n",
    "    def _extract_bbox(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int, int, int]:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "    def _clamp(self, v, lo, hi):\n",
    "        return max(lo, min(hi, v))\n",
    "\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    # ---------- Detection ----------\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, conf=self.config.YOLO_CONFIDENCE)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({'bbox': (x1, y1, x2, y2), 'class_name': class_name, 'confidence': conf, 'class_id': cls})\n",
    "            return detections\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Object detection failed\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb)\n",
    "            boxes = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for det in results.detections:\n",
    "                    r = det.location_data.relative_bounding_box\n",
    "                    x = int(r.xmin * w)\n",
    "                    y = int(r.ymin * h)\n",
    "                    width = int(r.width * w)\n",
    "                    height = int(r.height * h)\n",
    "                    boxes.append((x, y, width, height))\n",
    "            return boxes\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Face detection failed\")\n",
    "            return []\n",
    "\n",
    "    # Return a single face encoding (or None). Uses RESIZE_FACTOR to speed up encoding.\n",
    "    def get_face_encoding(self, face_crop: ndarray) -> Optional[ndarray]:\n",
    "        try:\n",
    "            if face_crop.size == 0:\n",
    "                return None\n",
    "            # resize for speed but keep enough detail; resizing can affect distances: tune RESIZE_FACTOR\n",
    "            if self.config.RESIZE_FACTOR and self.config.RESIZE_FACTOR != 1.0:\n",
    "                small = cv2.resize(face_crop, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            else:\n",
    "                small = face_crop\n",
    "            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "            encs = face_recognition.face_encodings(rgb)\n",
    "            if not encs:\n",
    "                return None\n",
    "            return encs[0]\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to get face encoding\")\n",
    "            return None\n",
    "\n",
    "    # ---------- Enhanced recognition with dynamic labeling ----------\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: Optional[float] = None) -> None:\n",
    "        \"\"\"\n",
    "        Update per-person recent votes and consecutive counts.\n",
    "        Stores last_distance to avoid 'unused parameter' warnings and enable distance-aware logic.\n",
    "        \"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now,\n",
    "                'last_distance': None\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        # Reset history if stale\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "            entry['last_distance'] = None\n",
    "\n",
    "        # Tally vote and consecutive\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "        entry['last_distance'] = distance\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        \"\"\"Confirm recognition using vote / consecutive / distance rules.\"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        # Immediate acceptance if distance is confidently low\n",
    "        if name != self.config.UNKNOWN_LABEL and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        # votes\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != self.config.UNKNOWN_LABEL and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != self.config.UNKNOWN_LABEL and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"\n",
    "        Given a face encoding, find best match and decide whether the match is confirmed.\n",
    "        Returns: (confirmed_name_or_None, confirmed_bool, best_distance)\n",
    "        \"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"face_distance failed\")\n",
    "            return None, False, None\n",
    "        if len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        # determine candidate name by using the recognition distance threshold (consistent)\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.RECOGNITION_DISTANCE_THRESHOLD else self.config.UNKNOWN_LABEL\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != self.config.UNKNOWN_LABEL:\n",
    "            return candidate_name, True, best_dist\n",
    "        # If candidate_name is UNKNOWN and it's confirmed (multiple unknown votes) consider it an unknown confirmed\n",
    "        if confirmed and candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            return self.config.UNKNOWN_LABEL, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    def _get_person_label(self, person_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate appropriate label for person based on detection and recognition status\"\"\"\n",
    "        if person_result.get('confirmed_known'):\n",
    "            return f\"{person_result['name']} ✓\"\n",
    "        elif person_result.get('recognized'):\n",
    "            if person_result.get('name'):\n",
    "                return f\"{person_result['name']} ?\"\n",
    "            else:\n",
    "                return \"Recognizing...\"\n",
    "        elif person_result.get('face_boxes'):\n",
    "            return \"Face Detected\"\n",
    "        else:\n",
    "            return self.config.PERSON_LABEL\n",
    "\n",
    "    def _get_person_color(self, person_result: Dict[str, Any]) -> Tuple[int, int, int]:\n",
    "        \"\"\"Get color for person bounding box based on status\"\"\"\n",
    "        if person_result.get('confirmed_known'):\n",
    "            return self.config.COLOR_GREEN  # Confirmed known person\n",
    "        elif person_result.get('recognized'):\n",
    "            return self.config.COLOR_CYAN  # Recognition in progress\n",
    "        elif person_result.get('face_boxes'):\n",
    "            return self.config.COLOR_BLUE  # Face detected but not recognized\n",
    "        else:\n",
    "            return self.config.COLOR_ORANGE  # Just person detection\n",
    "\n",
    "    # ---------- Alerting ----------\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            self.logger.info(\"Known person confirmed: %s; objects: %s (no alarm)\", person_name, objects_str)\n",
    "            return\n",
    "        self.logger.warning(\"ALERT: UNKNOWN person confirmed; objects: %s\", objects_str)\n",
    "        if self.alarm_loaded:\n",
    "            try:\n",
    "                if not pygame.mixer.music.get_busy():\n",
    "                    pygame.mixer.music.play()\n",
    "            except Exception:\n",
    "                self.logger.exception(\"Failed to start alarm\")\n",
    "\n",
    "    def process_alert(self, candidate_name: Optional[str], confirmed: bool, detected_objects: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Only triggers alarm for a confirmed unknown person (confirmed True and candidate_name == UNKNOWN_LABEL).\n",
    "        Observed cooldown prevents repeated alarms.\n",
    "        \"\"\"\n",
    "        if not confirmed:\n",
    "            return\n",
    "        now = time.time()\n",
    "        if now - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            return\n",
    "        if candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=True)\n",
    "            self.last_alert_time = now\n",
    "        else:\n",
    "            # confirmed known person -> log but do not alarm\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=False)\n",
    "\n",
    "    # ---------- Enhanced Drawing ----------\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        display = frame.copy()\n",
    "        \n",
    "        # Draw object detections first\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != 'person':\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), self.config.COLOR_YELLOW, 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, self.config.FONT_THICKNESS)\n",
    "\n",
    "        # Draw person detections with dynamic labels\n",
    "        for p in person_results:\n",
    "            x1, y1, x2, y2 = p['bbox']\n",
    "            \n",
    "            # Get appropriate color and label based on detection status\n",
    "            color = self._get_person_color(p)\n",
    "            label = self._get_person_label(p)\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw label with background for better visibility\n",
    "            label_bg_size = cv2.getTextSize(label, self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.FONT_THICKNESS)[0]\n",
    "            cv2.rectangle(display, (x1, y1 - label_bg_size[1] - 10), (x1 + label_bg_size[0] + 10, y1), color, -1)\n",
    "            cv2.putText(display, label, (x1 + 5, y1 - 5), self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.COLOR_WHITE, self.config.FONT_THICKNESS)\n",
    "            \n",
    "            # Draw face boxes if any\n",
    "            for fx, fy, fw, fh in p.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), self.config.COLOR_BLUE, 1)\n",
    "                \n",
    "            # Add confidence if available\n",
    "            if p.get('confidence'):\n",
    "                conf_text = f\"Conf: {p['confidence']:.2f}\"\n",
    "                cv2.putText(display, conf_text, (x1, y2 + 20), self.config.FONT, self.config.FONT_SCALE_SMALL, color, 1)\n",
    "                \n",
    "        return display\n",
    "\n",
    "    # ---------- Enhanced Main frame processing ----------\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Initialize result with basic detection info\n",
    "            result = {\n",
    "                'bbox': (x1, y1, x2, y2), \n",
    "                'recognized': False, \n",
    "                'confirmed_known': False, \n",
    "                'name': None, \n",
    "                'face_boxes': [],\n",
    "                'confidence': det['confidence']\n",
    "            }\n",
    "            \n",
    "            if person_roi.size == 0:\n",
    "                person_results.append(result)\n",
    "                continue\n",
    "                \n",
    "            # Always detect faces for visual feedback\n",
    "            face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "            result['face_boxes'] = face_boxes\n",
    "            \n",
    "            # Process face recognition on specified intervals\n",
    "            if process_faces and face_boxes:\n",
    "                # Try all detected faces, not just the first one\n",
    "                for i, (fx, fy, fw, fh) in enumerate(face_boxes):\n",
    "                    h_roi, w_roi = person_roi.shape[:2]\n",
    "                    x0 = self._clamp(fx, 0, w_roi-1)\n",
    "                    y0 = self._clamp(fy, 0, h_roi-1)\n",
    "                    x1f = self._clamp(fx+fw, 0, w_roi)\n",
    "                    y1f = self._clamp(fy+fh, 0, h_roi)\n",
    "                    \n",
    "                    if x1f > x0 and y1f > y0:\n",
    "                        face_crop = person_roi[y0:y1f, x0:x1f]\n",
    "                        face_enc = self.get_face_encoding(face_crop)\n",
    "                        \n",
    "                        if face_enc is not None:\n",
    "                            name, confirmed, dist = self.confirm_face(face_enc, (x1, y1, x2, y2))\n",
    "                            \n",
    "                            # Update result based on recognition outcome\n",
    "                            if confirmed:\n",
    "                                result['recognized'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                                result['confirmed_known'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                                result['name'] = name if name != self.config.UNKNOWN_LABEL else None\n",
    "                            else:\n",
    "                                # Show tentative recognition for immediate feedback\n",
    "                                result['recognized'] = True\n",
    "                                result['name'] = name if name and name != self.config.UNKNOWN_LABEL else None\n",
    "                            \n",
    "                            # Process alert only for confirmed outcomes\n",
    "                            self.process_alert(name if confirmed else None, confirmed, detected_objects)\n",
    "                            \n",
    "                            # Break after first successful face encoding to save processing\n",
    "                            break\n",
    "            \n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        \n",
    "        # Enhanced status display\n",
    "        status_y = 30\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.COLOR_GREEN, self.config.FONT_THICKNESS)\n",
    "        \n",
    "        # Show recognition status\n",
    "        recognized_count = sum(1 for p in person_results if p.get('confirmed_known'))\n",
    "        detecting_count = sum(1 for p in person_results if p.get('face_boxes'))\n",
    "        \n",
    "        status_y += 30\n",
    "        cv2.putText(annotated, f\"Recognized: {recognized_count}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_GREEN, 1)\n",
    "        \n",
    "        status_y += 25\n",
    "        cv2.putText(annotated, f\"Detecting: {detecting_count}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_BLUE, 1)\n",
    "        \n",
    "        if detected_objects:\n",
    "            status_y += 25\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, 1)\n",
    "            \n",
    "        return annotated\n",
    "\n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, im0 = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(im0)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Interrupted\")\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            try:\n",
    "                pygame.mixer.quit()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self.logger.info(\"Shutdown complete\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Cleanup error\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba39e11",
   "metadata": {},
   "source": [
    "# fixed by deepseek.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aece4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m     UNKNOWN_LABEL = \u001b[33m\"\u001b[39m\u001b[33mUNKNOWN\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m     PERSON_LABEL = \u001b[33m\"\u001b[39m\u001b[33mPerson\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mSecuritySystem\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[33;43;03m    Security system with improved, consistent face confirmation logic to reduce false alarms.\u001b[39;49;00m\n\u001b[32m     72\u001b[39m \u001b[33;43;03m    Enhanced to update person labels dynamically based on detection and recognition status.\u001b[39;49;00m\n\u001b[32m     73\u001b[39m \u001b[33;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mConfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mSecuritySystem\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# Initialize heavy resources\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_resources()\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_setup_logging\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[43mlogging\u001b[49m.Logger:\n\u001b[32m    108\u001b[39m     logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mSecuritySystem\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:\n",
      "\u001b[31mNameError\u001b[39m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "# Consolidated, cleaned and runnable version of the notebook code.\n",
    "# Preserves comments and intent; fixes naming/type inconsistencies and unused imports.\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from collections import defaultdict\n",
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "from ultralytics.utils import LOGGER\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the security system.\"\"\"\n",
    "    MODEL_PATH: str = \"yolo11m.pt\"\n",
    "    KNOWN_FACES_DIR: str = \"family_members\"\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    VIDEO_SOURCE: str = \"/media_files/WIN_20251103_14_11_20_Pro.mp4\"  # camera index or path\n",
    "    # VIDEO_SOURCE: str = \"./media_files/people walking/computer_vision_object_and_detection_tracking_people_walking_video_20250819_173636_1.mp4\"  # camera index or path\n",
    "    # VIDEO_SOURCE: str = 0  # camera index or path\n",
    "    # Recommended default: 10 (good balance). Lower -> more CPU, higher -> slower recognition.\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10\n",
    "    YOLO_CONFIDENCE: float = 0.5\n",
    "    # MediaPipe face detection confidence threshold\n",
    "    FACE_DETECTION_CONF: float = 0.25\n",
    "    # Face distance threshold used to accept a name from face_distance\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RESIZE_FACTOR: float = 0.25\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"backpack\",\n",
    "        \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"cell phone\", \"laptop\",\n",
    "        \"book\", \"scissors\", \"knife\", \"face\"\n",
    "    ])\n",
    "\n",
    "    # Stricter recognition controls to reduce false positives\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0  # seconds\n",
    "\n",
    "    # Color & font constants\n",
    "    COLOR_YELLOW = (0, 255, 255)\n",
    "    COLOR_GREEN = (0, 255, 0)\n",
    "    COLOR_ORANGE = (0, 165, 255)\n",
    "    COLOR_BLUE = (255, 0, 0)\n",
    "    COLOR_RED = (0, 0, 255)\n",
    "    COLOR_WHITE = (255, 255, 255)\n",
    "    COLOR_CYAN = (255, 255, 0)\n",
    "\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE_SMALL = 0.5\n",
    "    FONT_SCALE_MEDIUM = 0.7\n",
    "    FONT_THICKNESS = 2\n",
    "\n",
    "    # Labels\n",
    "    UNKNOWN_LABEL = \"UNKNOWN\"\n",
    "    PERSON_LABEL = \"Person\"\n",
    "\n",
    "class SecuritySystem:\n",
    "    \"\"\"\n",
    "    Security system with improved, consistent face confirmation logic to reduce false alarms.\n",
    "    Enhanced to update person labels dynamically based on detection and recognition status.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "\n",
    "        # Models\n",
    "        self.yolo_model: Optional[YOLO] = None\n",
    "        self.mp_face_detection = None\n",
    "\n",
    "        # Known faces\n",
    "        self.known_face_encodings: List[ndarray] = []\n",
    "        self.known_face_names: List[str] = []\n",
    "\n",
    "        # Alarm\n",
    "        self.alarm_loaded = False\n",
    "\n",
    "        # State\n",
    "        self.frame_count = 0\n",
    "        self.last_alert_time = 0.0\n",
    "\n",
    "        # Detection history per coarse person grid cell -> used to vote/confirm\n",
    "        # person_id -> { name_counts: defaultdict(int), last_name: str, consecutive: int, last_update: float }\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Track current person states for consistent labeling\n",
    "        self.current_person_states: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # Track alerted persons to avoid repeated alarms\n",
    "        self.alerted_persons: Dict[str, float] = {}  # person_id -> last_alert_time\n",
    "\n",
    "        # Initialize heavy resources\n",
    "        self._initialize_resources()\n",
    "\n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        logger = logging.getLogger('SecuritySystem')\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            os.makedirs(self.config.LOG_DIR, exist_ok=True)\n",
    "            log_file = os.path.join(self.config.LOG_DIR, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "            fh = logging.FileHandler(log_file)\n",
    "            fh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s: %(message)s'))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _initialize_resources(self) -> None:\n",
    "        try:\n",
    "            self.logger.info(\"Loading YOLO model...\")\n",
    "            self.yolo_model = YOLO(self.config.MODEL_PATH)\n",
    "\n",
    "            self.logger.info(\"Initializing MediaPipe face detection...\")\n",
    "            mp_face = mp.solutions.face_detection\n",
    "            self.mp_face_detection = mp_face.FaceDetection(\n",
    "                model_selection=0,\n",
    "                min_detection_confidence=self.config.FACE_DETECTION_CONF\n",
    "            )\n",
    "\n",
    "            self._load_known_faces()\n",
    "            self._setup_alarm()\n",
    "            self.logger.info(\"Initialization complete\")\n",
    "        except Exception as e:\n",
    "            self.logger.exception(\"Failed to initialize resources\")\n",
    "            raise\n",
    "\n",
    "    def _load_known_faces(self) -> None:\n",
    "        if not os.path.exists(self.config.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(\"Known faces dir not found: %s\", self.config.KNOWN_FACES_DIR)\n",
    "            return\n",
    "        for person_name in os.listdir(self.config.KNOWN_FACES_DIR):\n",
    "            person_dir = os.path.join(self.config.KNOWN_FACES_DIR, person_name)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            for img in os.listdir(person_dir):\n",
    "                path = os.path.join(person_dir, img)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(path)\n",
    "                    encs = face_recognition.face_encodings(image)\n",
    "                    if encs:\n",
    "                        self.known_face_encodings.append(encs[0])\n",
    "                        self.known_face_names.append(person_name)\n",
    "                        self.logger.info(\"Loaded face for %s from %s\", person_name, img)\n",
    "                    else:\n",
    "                        self.logger.warning(\"No face found in %s\", path)\n",
    "                except Exception:\n",
    "                    self.logger.exception(\"Failed to load known face %s\", path)\n",
    "        self.logger.info(\"Loaded %d encodings for %d people\",\n",
    "                         len(self.known_face_encodings), len(set(self.known_face_names)))\n",
    "\n",
    "    def _setup_alarm(self) -> None:\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            if os.path.exists(self.config.ALARM_FILE):\n",
    "                pygame.mixer.music.load(self.config.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm loaded\")\n",
    "            else:\n",
    "                self.logger.warning(\"Alarm file missing: %s\", self.config.ALARM_FILE)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to initialize alarm\")\n",
    "\n",
    "    # ---------- Utility helpers ----------\n",
    "    def _extract_bbox(self, bbox: Tuple[int, int, int, int]) -> Tuple[int, int, int, int]:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        return int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "    def _clamp(self, v, lo, hi):\n",
    "        return max(lo, min(hi, v))\n",
    "\n",
    "    def _get_person_id(self, bbox: Tuple[int, int, int, int]) -> str:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cx = (x1 + x2) // 2\n",
    "        cy = (y1 + y2) // 2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    # ---------- Detection ----------\n",
    "    def detect_objects(self, frame: ndarray) -> List[Dict[str, Any]]:\n",
    "        if not self.yolo_model:\n",
    "            return []\n",
    "        try:\n",
    "            results = self.yolo_model(frame, conf=self.config.YOLO_CONFIDENCE)\n",
    "            detections: List[Dict[str, Any]] = []\n",
    "            for result in results:\n",
    "                if getattr(result, \"boxes\", None) is None:\n",
    "                    continue\n",
    "                for box in result.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    class_name = result.names[cls] if hasattr(result, \"names\") else str(cls)\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        continue\n",
    "                    detections.append({'bbox': (x1, y1, x2, y2), 'class_name': class_name, 'confidence': conf, 'class_id': cls})\n",
    "            return detections\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Object detection failed\")\n",
    "            return []\n",
    "\n",
    "    def detect_faces_mediapipe(self, roi: ndarray) -> List[Tuple[int, int, int, int]]:\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            results = self.mp_face_detection.process(rgb)\n",
    "            boxes = []\n",
    "            if results and getattr(results, \"detections\", None):\n",
    "                h, w = roi.shape[:2]\n",
    "                for det in results.detections:\n",
    "                    r = det.location_data.relative_bounding_box\n",
    "                    x = int(r.xmin * w)\n",
    "                    y = int(r.ymin * h)\n",
    "                    width = int(r.width * w)\n",
    "                    height = int(r.height * h)\n",
    "                    boxes.append((x, y, width, height))\n",
    "            return boxes\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Face detection failed\")\n",
    "            return []\n",
    "\n",
    "    # Return a single face encoding (or None). Uses RESIZE_FACTOR to speed up encoding.\n",
    "    def get_face_encoding(self, face_crop: ndarray) -> Optional[ndarray]:\n",
    "        try:\n",
    "            if face_crop.size == 0:\n",
    "                return None\n",
    "            # resize for speed but keep enough detail; resizing can affect distances: tune RESIZE_FACTOR\n",
    "            if self.config.RESIZE_FACTOR and self.config.RESIZE_FACTOR != 1.0:\n",
    "                small = cv2.resize(face_crop, (0, 0), fx=self.config.RESIZE_FACTOR, fy=self.config.RESIZE_FACTOR)\n",
    "            else:\n",
    "                small = face_crop\n",
    "            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "            encs = face_recognition.face_encodings(rgb)\n",
    "            if not encs:\n",
    "                return None\n",
    "            return encs[0]\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to get face encoding\")\n",
    "            return None\n",
    "\n",
    "    # ---------- Enhanced recognition with dynamic labeling ----------\n",
    "    def _update_detection_history(self, person_id: str, name: str, distance: Optional[float] = None) -> None:\n",
    "        \"\"\"\n",
    "        Update per-person recent votes and consecutive counts.\n",
    "        Stores last_distance to avoid 'unused parameter' warnings and enable distance-aware logic.\n",
    "        \"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if entry is None:\n",
    "            entry = {\n",
    "                'name_counts': defaultdict(int),\n",
    "                'last_name': None,\n",
    "                'consecutive': 0,\n",
    "                'last_update': now,\n",
    "                'last_distance': None\n",
    "            }\n",
    "            self.detection_history[person_id] = entry\n",
    "\n",
    "        # Reset history if stale\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            entry['name_counts'] = defaultdict(int)\n",
    "            entry['last_name'] = None\n",
    "            entry['consecutive'] = 0\n",
    "            entry['last_distance'] = None\n",
    "\n",
    "        # Tally vote and consecutive\n",
    "        entry['name_counts'][name] += 1\n",
    "        if entry['last_name'] == name:\n",
    "            entry['consecutive'] += 1\n",
    "        else:\n",
    "            entry['last_name'] = name\n",
    "            entry['consecutive'] = 1\n",
    "        entry['last_update'] = now\n",
    "        entry['last_distance'] = distance\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, distance: float) -> bool:\n",
    "        \"\"\"Confirm recognition using vote / consecutive / distance rules.\"\"\"\n",
    "        now = time.time()\n",
    "        entry = self.detection_history.get(person_id)\n",
    "        if not entry:\n",
    "            return False\n",
    "        if now - entry['last_update'] > self.config.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        # Immediate acceptance if distance is confidently low\n",
    "        if name != self.config.UNKNOWN_LABEL and distance <= self.config.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        # votes\n",
    "        votes = entry['name_counts'].get(name, 0)\n",
    "        if name != self.config.UNKNOWN_LABEL and votes >= self.config.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != self.config.UNKNOWN_LABEL and entry['consecutive'] >= self.config.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def confirm_face(self, face_encoding: ndarray, bbox: Tuple[int, int, int, int]) -> Tuple[Optional[str], bool, Optional[float]]:\n",
    "        \"\"\"\n",
    "        Given a face encoding, find best match and decide whether the match is confirmed.\n",
    "        Returns: (confirmed_name_or_None, confirmed_bool, best_distance)\n",
    "        \"\"\"\n",
    "        if not self.known_face_encodings:\n",
    "            return None, False, None\n",
    "        try:\n",
    "            distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"face_distance failed\")\n",
    "            return None, False, None\n",
    "        if len(distances) == 0:\n",
    "            return None, False, None\n",
    "        best_idx = int(np.argmin(distances))\n",
    "        best_dist = float(distances[best_idx])\n",
    "        # determine candidate name by using the recognition distance threshold (consistent)\n",
    "        candidate_name = self.known_face_names[best_idx] if best_dist <= self.config.RECOGNITION_DISTANCE_THRESHOLD else self.config.UNKNOWN_LABEL\n",
    "        person_id = self._get_person_id(bbox)\n",
    "        self._update_detection_history(person_id, candidate_name, best_dist)\n",
    "        confirmed = self._confirm_recognition(person_id, candidate_name, best_dist)\n",
    "        if confirmed and candidate_name != self.config.UNKNOWN_LABEL:\n",
    "            return candidate_name, True, best_dist\n",
    "        # If candidate_name is UNKNOWN and it's confirmed (multiple unknown votes) consider it an unknown confirmed\n",
    "        if confirmed and candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            return self.config.UNKNOWN_LABEL, True, best_dist\n",
    "        return None, False, best_dist\n",
    "\n",
    "    def _get_person_label(self, person_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate appropriate label for person based on detection and recognition status\"\"\"\n",
    "        if person_result.get('confirmed_known'):\n",
    "            return f\"{person_result['name']} ✓\"\n",
    "        elif person_result.get('recognized'):\n",
    "            if person_result.get('name'):\n",
    "                return f\"{person_result['name']} ?\"\n",
    "            else:\n",
    "                return \"Recognizing...\"\n",
    "        elif person_result.get('face_boxes'):\n",
    "            return \"Face Detected\"\n",
    "        else:\n",
    "            return self.config.PERSON_LABEL\n",
    "\n",
    "    def _get_person_color(self, person_result: Dict[str, Any]) -> Tuple[int, int, int]:\n",
    "        \"\"\"Get color for person bounding box based on status\"\"\"\n",
    "        if person_result.get('confirmed_known'):\n",
    "            return self.config.COLOR_GREEN  # Confirmed known person\n",
    "        elif person_result.get('recognized'):\n",
    "            return self.config.COLOR_CYAN  # Recognition in progress\n",
    "        elif person_result.get('face_boxes'):\n",
    "            return self.config.COLOR_BLUE  # Face detected but not recognized\n",
    "        else:\n",
    "            return self.config.COLOR_ORANGE  # Just person detection\n",
    "\n",
    "    # ---------- FIXED Alerting Logic ----------\n",
    "    def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "        objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "        if is_known:\n",
    "            self.logger.info(\"Known person confirmed: %s; objects: %s (no alarm)\", person_name, objects_str)\n",
    "            return\n",
    "        \n",
    "        # Only trigger alarm for unknown persons\n",
    "        self.logger.warning(\"ALERT: UNKNOWN person confirmed; objects: %s\", objects_str)\n",
    "        if self.alarm_loaded:\n",
    "            try:\n",
    "                if not pygame.mixer.music.get_busy():\n",
    "                    pygame.mixer.music.play()\n",
    "                    self.logger.info(\"Alarm triggered for unknown person\")\n",
    "            except Exception:\n",
    "                self.logger.exception(\"Failed to start alarm\")\n",
    "\n",
    "    def process_alert(self, candidate_name: Optional[str], confirmed: bool, detected_objects: List[str], person_id: str) -> None:\n",
    "        \"\"\"\n",
    "        Only triggers alarm for a confirmed unknown person (confirmed True and candidate_name == UNKNOWN_LABEL).\n",
    "        Uses person-specific cooldown to prevent repeated alarms for the same person.\n",
    "        \"\"\"\n",
    "        if not confirmed:\n",
    "            return\n",
    "            \n",
    "        now = time.time()\n",
    "        \n",
    "        # Check global cooldown\n",
    "        if now - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "            return\n",
    "            \n",
    "        # Check person-specific cooldown\n",
    "        if person_id in self.alerted_persons:\n",
    "            if now - self.alerted_persons[person_id] <= self.config.ALERT_COOLDOWN:\n",
    "                return\n",
    "        \n",
    "        if candidate_name == self.config.UNKNOWN_LABEL:\n",
    "            # Unknown person - trigger alarm\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=False)\n",
    "            self.last_alert_time = now\n",
    "            self.alerted_persons[person_id] = now\n",
    "        else:\n",
    "            # Known person - log but do not alarm\n",
    "            self._trigger_alert(candidate_name, detected_objects, is_known=True)\n",
    "    #     # ---------- FIXED Alerting Logic ----------\n",
    "    # def _trigger_alert(self, person_name: str, detected_objects: List[str], is_known: bool) -> None:\n",
    "    #     objects_str = \", \".join(set(detected_objects)) if detected_objects else \"None\"\n",
    "    #     if is_known:\n",
    "    #         self.logger.info(\"Known person confirmed: %s; objects: %s (no alarm)\", person_name, objects_str)\n",
    "    #         return\n",
    "\n",
    "    #     # Only trigger alarm for unknown persons\n",
    "    #     self.logger.warning(\"⚠️ ALERT: UNKNOWN or unrecognized person detected; objects: %s\", objects_str)\n",
    "    #     if self.alarm_loaded:\n",
    "    #         try:\n",
    "    #             if not pygame.mixer.music.get_busy():\n",
    "    #                 pygame.mixer.music.play()\n",
    "    #                 self.logger.info(\"Alarm triggered for unknown/unrecognized person\")\n",
    "    #         except Exception:\n",
    "    #             self.logger.exception(\"Failed to start alarm\")\n",
    "\n",
    "    # def process_alert(self, candidate_name: Optional[str], confirmed: bool, detected_objects: List[str], person_id: str) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Triggers alarm when an unknown or unrecognized person is confirmed.\n",
    "    #     Uses cooldown per person and global cooldown to prevent alarm spam.\n",
    "    #     \"\"\"\n",
    "    #     if not confirmed:\n",
    "    #         return\n",
    "\n",
    "    #     now = time.time()\n",
    "    #     if now - self.last_alert_time <= self.config.ALERT_COOLDOWN:\n",
    "    #         return\n",
    "\n",
    "    #     if person_id in self.alerted_persons and now - self.alerted_persons[person_id] <= self.config.ALERT_COOLDOWN:\n",
    "    #         return\n",
    "\n",
    "    #     # If name is missing or explicitly unknown\n",
    "    #     if not candidate_name or candidate_name == self.config.UNKNOWN_LABEL:\n",
    "    #         self._trigger_alert(self.config.UNKNOWN_LABEL, detected_objects, is_known=False)\n",
    "    #         self.last_alert_time = now\n",
    "    #         self.alerted_persons[person_id] = now\n",
    "    #     else:\n",
    "    #         self._trigger_alert(candidate_name, detected_objects, is_known=True)\n",
    "\n",
    "    # ---------- Enhanced Drawing ----------\n",
    "    def draw_detections(self, frame: ndarray, detections: List[Dict[str, Any]], person_results: List[Dict[str, Any]]) -> ndarray:\n",
    "        display = frame.copy()\n",
    "        \n",
    "        # Draw object detections first\n",
    "        for det in detections:\n",
    "            if det['class_name'] in self.config.OBJECTS_OF_INTEREST and det['class_name'] != 'person':\n",
    "                x1, y1, x2, y2 = det['bbox']\n",
    "                cv2.rectangle(display, (x1, y1), (x2, y2), self.config.COLOR_YELLOW, 2)\n",
    "                label = f\"{det['class_name']}: {det['confidence']:.2f}\"\n",
    "                cv2.putText(display, label, (x1, y1 - 10), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, self.config.FONT_THICKNESS)\n",
    "\n",
    "        # Draw person detections with dynamic labels\n",
    "        for p in person_results:\n",
    "            x1, y1, x2, y2 = p['bbox']\n",
    "            \n",
    "            # Get appropriate color and label based on detection status\n",
    "            color = self._get_person_color(p)\n",
    "            label = self._get_person_label(p)\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # Draw label with background for better visibility\n",
    "            label_bg_size = cv2.getTextSize(label, self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.FONT_THICKNESS)[0]\n",
    "            cv2.rectangle(display, (x1, y1 - label_bg_size[1] - 10), (x1 + label_bg_size[0] + 10, y1), color, -1)\n",
    "            cv2.putText(display, label, (x1 + 5, y1 - 5), self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.COLOR_WHITE, self.config.FONT_THICKNESS)\n",
    "            \n",
    "            # Draw face boxes if any\n",
    "            for fx, fy, fw, fh in p.get('face_boxes', []):\n",
    "                cv2.rectangle(display, (x1 + fx, y1 + fy), (x1 + fx + fw, y1 + fy + fh), self.config.COLOR_BLUE, 1)\n",
    "                \n",
    "            # Add confidence if available\n",
    "            if p.get('confidence'):\n",
    "                conf_text = f\"Conf: {p['confidence']:.2f}\"\n",
    "                cv2.putText(display, conf_text, (x1, y2 + 20), self.config.FONT, self.config.FONT_SCALE_SMALL, color, 1)\n",
    "                \n",
    "        return display\n",
    "\n",
    "    # ---------- Enhanced Main frame processing ----------\n",
    "    def process_frame(self, frame: ndarray) -> ndarray:\n",
    "        self.frame_count += 1\n",
    "        timer = cv2.getTickCount()\n",
    "        detections = self.detect_objects(frame)\n",
    "        person_detections = [d for d in detections if d['class_name'] == 'person']\n",
    "        detected_objects = [d['class_name'] for d in detections if d['class_name'] in self.config.OBJECTS_OF_INTEREST and d['class_name'] != 'person']\n",
    "\n",
    "        person_results: List[Dict[str, Any]] = []\n",
    "        process_faces = (self.frame_count % self.config.FACE_RECOGNITION_INTERVAL) == 0\n",
    "\n",
    "        for det in person_detections:\n",
    "            x1, y1, x2, y2 = det['bbox']\n",
    "            x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "            person_id = self._get_person_id((x1, y1, x2, y2))\n",
    "            \n",
    "            # Initialize result with basic detection info\n",
    "            result = {\n",
    "                'bbox': (x1, y1, x2, y2), \n",
    "                'recognized': False, \n",
    "                'confirmed_known': False, \n",
    "                'name': None, \n",
    "                'face_boxes': [],\n",
    "                'confidence': det['confidence']\n",
    "            }\n",
    "            \n",
    "            if person_roi.size == 0:\n",
    "                person_results.append(result)\n",
    "                continue\n",
    "                \n",
    "            # Always detect faces for visual feedback\n",
    "            face_boxes = self.detect_faces_mediapipe(person_roi)\n",
    "            result['face_boxes'] = face_boxes\n",
    "            \n",
    "            # Process face recognition on specified intervals\n",
    "            if process_faces and face_boxes:\n",
    "                # Try all detected faces, not just the first one\n",
    "                for i, (fx, fy, fw, fh) in enumerate(face_boxes):\n",
    "                    h_roi, w_roi = person_roi.shape[:2]\n",
    "                    x0 = self._clamp(fx, 0, w_roi-1)\n",
    "                    y0 = self._clamp(fy, 0, h_roi-1)\n",
    "                    x1f = self._clamp(fx+fw, 0, w_roi)\n",
    "                    y1f = self._clamp(fy+fh, 0, h_roi)\n",
    "                    \n",
    "                    if x1f > x0 and y1f > y0:\n",
    "                        face_crop = person_roi[y0:y1f, x0:x1f]\n",
    "                        face_enc = self.get_face_encoding(face_crop)\n",
    "                        \n",
    "                        if face_enc is not None:\n",
    "                            name, confirmed, dist = self.confirm_face(face_enc, (x1, y1, x2, y2))\n",
    "                            \n",
    "                            # Update result based on recognition outcome\n",
    "                            if confirmed:\n",
    "                                result['recognized'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                                result['confirmed_known'] = (name != self.config.UNKNOWN_LABEL)\n",
    "                                result['name'] = name if name != self.config.UNKNOWN_LABEL else None\n",
    "                                \n",
    "                                # Process alert with person_id for cooldown tracking\n",
    "                                self.process_alert(name, confirmed, detected_objects, person_id)\n",
    "                            else:\n",
    "                                # Show tentative recognition for immediate feedback\n",
    "                                result['recognized'] = True\n",
    "                                result['name'] = name if name and name != self.config.UNKNOWN_LABEL else None\n",
    "                                # # Tentative or unknown\n",
    "                                # result['recognized'] = True\n",
    "                                # result['name'] = name if name and name != self.config.UNKNOWN_LABEL else None\n",
    "                                # # Force alarm for unknown/unrecognized face\n",
    "                                # if name == self.config.UNKNOWN_LABEL or name is None:\n",
    "                                #     self.process_alert(self.config.UNKNOWN_LABEL, True, detected_objects, person_id)\n",
    "                            \n",
    "                            # Break after first successful face encoding to save processing\n",
    "                            break\n",
    "            \n",
    "            person_results.append(result)\n",
    "\n",
    "        annotated = self.draw_detections(frame, detections, person_results)\n",
    "        elapsed = max(1, cv2.getTickCount() - timer)\n",
    "        fps = int(cv2.getTickFrequency() / elapsed)\n",
    "        \n",
    "        # Enhanced status display\n",
    "        status_y = 30\n",
    "        cv2.putText(annotated, f\"FPS: {fps}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_MEDIUM, self.config.COLOR_GREEN, self.config.FONT_THICKNESS)\n",
    "        \n",
    "        # Show recognition status\n",
    "        recognized_count = sum(1 for p in person_results if p.get('confirmed_known'))\n",
    "        detecting_count = sum(1 for p in person_results if p.get('face_boxes'))\n",
    "        \n",
    "        status_y += 30\n",
    "        cv2.putText(annotated, f\"Recognized: {recognized_count}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_GREEN, 1)\n",
    "        \n",
    "        status_y += 25\n",
    "        cv2.putText(annotated, f\"Detecting: {detecting_count}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_BLUE, 1)\n",
    "        \n",
    "        # Show alarm status\n",
    "        status_y += 25\n",
    "        alarm_status = \"ALARM READY\" if self.alarm_loaded else \"NO ALARM FILE\"\n",
    "        alarm_color = self.config.COLOR_GREEN if self.alarm_loaded else self.config.COLOR_RED\n",
    "        cv2.putText(annotated, f\"Alarm: {alarm_status}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, alarm_color, 1)\n",
    "        \n",
    "        if detected_objects:\n",
    "            status_y += 25\n",
    "            cv2.putText(annotated, f\"Objects: {', '.join(set(detected_objects))}\", (20, status_y), self.config.FONT, self.config.FONT_SCALE_SMALL, self.config.COLOR_YELLOW, 1)\n",
    "            \n",
    "        return annotated\n",
    "\n",
    "    def run(self) -> None:\n",
    "        cap = cv2.VideoCapture(self.config.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Could not open video capture\")\n",
    "            raise RuntimeError(\"Video capture failed\")\n",
    "        self.logger.info(\"Monitoring started. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.warning(\"Failed to grab frame\")\n",
    "                    break\n",
    "                annotated = self.process_frame(frame)\n",
    "                cv2.imshow(self.config.WINDOW_NAME, annotated)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Interrupted\")\n",
    "        finally:\n",
    "            self._cleanup(cap)\n",
    "\n",
    "    def _cleanup(self, cap) -> None:\n",
    "        try:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.mp_face_detection:\n",
    "                self.mp_face_detection.close()\n",
    "            try:\n",
    "                pygame.mixer.quit()\n",
    "            except Exception:\n",
    "                pass\n",
    "            self.logger.info(\"Shutdown complete\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Cleanup error\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    system = SecuritySystem(cfg)\n",
    "    system.run()  # uncomment to run live monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f7535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Ultralytics Solutions:  {'source': 'media_files/WIN_20251103_14_11_20_Pro.mp4', 'model': 'yolo11m.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': None, 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': False, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 01:22:29,134 - INFO - Loading YOLO model...\n",
      "2025-11-22 01:22:29,252 - INFO - Models initialized\n",
      "2025-11-22 01:22:29,851 - WARNING - No face found in family_members/robin\\image10.jpg\n",
      "2025-11-22 01:22:30,427 - WARNING - No face found in family_members/robin\\image12.jpg\n",
      "2025-11-22 01:22:30,996 - WARNING - No face found in family_members/robin\\image14.jpg\n",
      "2025-11-22 01:22:31,580 - WARNING - No face found in family_members/robin\\image7.jpg\n",
      "2025-11-22 01:22:32,184 - WARNING - No face found in family_members/robin\\image8.jpg\n",
      "2025-11-22 01:22:33,089 - INFO - Loaded known face: robin (robin_01.jpg)\n",
      "2025-11-22 01:22:34,005 - INFO - Loaded known face: robin (robin_02.jpg)\n",
      "2025-11-22 01:22:34,906 - INFO - Loaded known face: robin (robin_03.jpg)\n",
      "2025-11-22 01:22:35,496 - WARNING - No face found in family_members/robin\\WIN_20250929_13_24_25_Pro.jpg\n",
      "2025-11-22 01:22:36,076 - WARNING - No face found in family_members/robin\\WIN_20250929_13_24_33_Pro.jpg\n",
      "2025-11-22 01:22:36,655 - WARNING - No face found in family_members/robin\\WIN_20251001_12_21_20_Pro.jpg\n",
      "2025-11-22 01:22:37,227 - WARNING - No face found in family_members/robin\\WIN_20251001_12_21_29_Pro.jpg\n",
      "2025-11-22 01:22:37,833 - WARNING - No face found in family_members/robin\\WIN_20251001_12_21_49_Pro.jpg\n",
      "2025-11-22 01:22:38,507 - WARNING - No face found in family_members/robin\\WIN_20251001_12_21_50_Pro.jpg\n",
      "2025-11-22 01:22:39,581 - INFO - Loaded known face: robin (WIN_20251008_18_56_08_Pro.jpg)\n",
      "2025-11-22 01:22:39,582 - INFO - Total known faces: 4\n",
      "2025-11-22 01:22:39,873 - INFO - Alarm sound loaded\n",
      "2025-11-22 01:22:39,933 - INFO - Starting monitoring. Press 'q' to quit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cup, 1 chair, 1 laptop, 67.5ms\n",
      "Speed: 3.7ms preprocess, 67.5ms inference, 116.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 01:22:44,552 - INFO - Shutdown complete\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 580\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# === USER: adjust configuration below as needed ===\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# cfg.VIDEO_SOURCE = \"your_camera_or_video_path\"\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# cfg.MODEL_PATH = \"yolov8n.pt\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    577\u001b[39m \u001b[38;5;66;03m# cfg.USE_GPIO = True  # only on Raspberry Pi\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[32m    579\u001b[39m system = SecuritySurveillance(cfg=cfg, model=cfg.MODEL_PATH, source=cfg.VIDEO_SOURCE)\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 552\u001b[39m, in \u001b[36mSecuritySurveillance.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVideo frame is empty or video processing has been successfully completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[38;5;28mprint\u001b[39m(results) \n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv2.waitKey(\u001b[32m1\u001b[39m) & \u001b[32m0xFF\u001b[39m == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 408\u001b[39m, in \u001b[36mSecuritySurveillance.process_frame\u001b[39m\u001b[34m(self, frame)\u001b[39m\n\u001b[32m    405\u001b[39m pid = \u001b[38;5;28mself\u001b[39m._get_person_id((x1, y1, x2, y2))\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# draw person box basic\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m165\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# skip if ROI empty\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m roi.size == \u001b[32m0\u001b[39m:\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "# security_surveillance.py\n",
    "# Requirements:\n",
    "#   pip install ultralytics face_recognition mediapipe pygame opencv-python numpy\n",
    "# Optional (Raspberry Pi buzzer):\n",
    "#   pip install RPi.GPIO\n",
    "#\n",
    "# Configure Config class below before running.\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import logging\n",
    "from collections import deque, defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "# ultralytics libs  \n",
    "from ultralytics import solutions\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions.config import SolutionConfig\n",
    "from ultralytics.solutions.solutions import BaseSolution, SolutionAnnotator, SolutionResults\n",
    "from ultralytics.utils.plotting import colors\n",
    "\n",
    "# third-party libs\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Install ultralytics: pip install ultralytics\") from e\n",
    "\n",
    "try:\n",
    "    import face_recognition\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Install face_recognition (dlib dependency): pip install face_recognition\") from e\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Install mediapipe: pip install mediapipe\") from e\n",
    "\n",
    "try:\n",
    "    import pygame\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"Install pygame: pip install pygame\") from e\n",
    "\n",
    "# Optional Raspberry Pi GPIO (if running on Raspberry Pi with buzzer)\n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    HAS_RPI = True\n",
    "except Exception:\n",
    "    HAS_RPI = False\n",
    "\n",
    "# Optional: Telegram notification via bot\n",
    "import requests\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # model & known faces\n",
    "    MODEL_PATH: str = \"yolo11m.pt\"  # change to your model\n",
    "    KNOWN_FACES_DIR: str = \"family_members/\"\n",
    "    ALARM_FILE: str = \"pols-aagyi-pols.mp3\"\n",
    "    LOG_DIR: str = \"security_logs\"\n",
    "    OUTPUT_DIR: str = \"security_output\"\n",
    "    # VIDEO_SOURCE: str = 0  # camera index or video path\n",
    "    VIDEO_SOURCE: str = \"media_files/WIN_20251103_14_11_20_Pro.mp4\"  # camera index or video path\n",
    "    FACE_RECOGNITION_INTERVAL: int = 5\n",
    "    ALERT_COOLDOWN: int = 10  # seconds global cooldown\n",
    "    PERSON_COOLDOWN: int = 20  # per person cooldown seconds\n",
    "    YOLO_CONFIDENCE: float = 0.45\n",
    "    FACE_DETECTION_CONF: float = 0.5\n",
    "    RECOGNITION_DISTANCE_THRESHOLD: float = 0.45\n",
    "    RESIZE_FACTOR: float = 0.35\n",
    "\n",
    "    # Clip saving\n",
    "    SAVE_CLIP_SECONDS: int = 6  # seconds to save when alarm triggers (uses ring buffer)\n",
    "    CLIP_FPS: int = 20\n",
    "\n",
    "    # GPIO buzzer (optional)\n",
    "    USE_GPIO: bool = False\n",
    "    BUZZER_PIN: int = 18  # BCM pin; only used if USE_GPIO True and HAS_RPI True\n",
    "    BUZZER_SECONDS: float = 5.0\n",
    "\n",
    "    # Telegram\n",
    "    USE_TELEGRAM: bool = False\n",
    "    TELEGRAM_BOT_TOKEN: str = \"\"  # put your bot token\n",
    "    TELEGRAM_CHAT_ID: str = \"\"    # put your chat id\n",
    "    SEND_IMAGE_ON_ALERT: bool = True\n",
    "\n",
    "    # secure zone: rectangle (x1,y1,x2,y2) relative fraction of frame: (left, top, right, bottom)\n",
    "    # set to None to consider whole frame as secure zone\n",
    "    SECURE_ZONE_REL: Optional[Tuple[float, float, float, float]] = (0.0, 0.0, 1.0, 1.0)\n",
    "\n",
    "    # recognition thresholds & voting\n",
    "    RECOGNITION_MIN_VOTES: int = 2\n",
    "    RECOGNITION_CONSECUTIVE_FRAMES: int = 2\n",
    "    RECOGNITION_TIME_WINDOW: float = 3.0\n",
    "\n",
    "    # drawing & UI\n",
    "    WINDOW_NAME: str = \"Security Monitoring\"\n",
    "    OBJECTS_OF_INTEREST: List[str] = field(default_factory=lambda: [\"person\", \"car\", \"truck\", \"bicycle\", \"motorcycle\", \"cell phone\", \"face\"])\n",
    "\n",
    "class SecuritySurveillance(solutions.VisionEye):\n",
    "    # def __init__(self, cfg: Config):\n",
    "    def __init__(self, cfg: Config, *args, known_face_encodings=None, known_face_names=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cfg = cfg\n",
    "        os.makedirs(self.cfg.LOG_DIR, exist_ok=True)\n",
    "        os.makedirs(self.cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        self.logger = self._setup_logger()\n",
    "        self._init_models()\n",
    "        self._load_known_faces()\n",
    "        self._setup_alarm()\n",
    "        self.frame_count = 0\n",
    "\n",
    "        # ring buffer for last N frames to save clip when alarm triggers\n",
    "        self.ring_buffer = deque(maxlen=int(self.cfg.SAVE_CLIP_SECONDS * self.cfg.CLIP_FPS))\n",
    "        self.last_alert_time = 0.0\n",
    "        self.person_alert_times: Dict[str, float] = {}\n",
    "        self.detection_history: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "        # gpio\n",
    "        if self.cfg.USE_GPIO and HAS_RPI:\n",
    "            GPIO.setmode(GPIO.BCM)\n",
    "            GPIO.setup(self.cfg.BUZZER_PIN, GPIO.OUT)\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        logger = logging.getLogger(\"SecuritySurv\")\n",
    "        if not logger.handlers:\n",
    "            logger.setLevel(logging.INFO)\n",
    "            fh = logging.FileHandler(os.path.join(self.cfg.LOG_DIR, f\"sec_{datetime.now().strftime('%Y%m%d')}.log\"))\n",
    "            fh.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "            logger.addHandler(fh)\n",
    "            sh = logging.StreamHandler()\n",
    "            sh.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "            logger.addHandler(sh)\n",
    "        return logger\n",
    "\n",
    "    def _init_models(self):\n",
    "        self.logger.info(\"Loading YOLO model...\")\n",
    "        self.yolo = YOLO(self.cfg.MODEL_PATH)\n",
    "        mp_face = mp.solutions.face_detection\n",
    "        self.mp_detector = mp_face.FaceDetection(model_selection=0, min_detection_confidence=self.cfg.FACE_DETECTION_CONF)\n",
    "        self.logger.info(\"Models initialized\")\n",
    "\n",
    "    def _load_known_faces(self):\n",
    "        self.known_encodings = []\n",
    "        self.known_names = []\n",
    "        if not os.path.exists(self.cfg.KNOWN_FACES_DIR):\n",
    "            self.logger.warning(\"Known faces directory missing: %s\", self.cfg.KNOWN_FACES_DIR)\n",
    "            return\n",
    "        for person in os.listdir(self.cfg.KNOWN_FACES_DIR):\n",
    "            pdir = os.path.join(self.cfg.KNOWN_FACES_DIR, person)\n",
    "            if not os.path.isdir(pdir):\n",
    "                continue\n",
    "            for f in os.listdir(pdir):\n",
    "                path = os.path.join(pdir, f)\n",
    "                try:\n",
    "                    img = face_recognition.load_image_file(path)\n",
    "                    encs = face_recognition.face_encodings(img)\n",
    "                    if encs:\n",
    "                        self.known_encodings.append(encs[0])\n",
    "                        self.known_names.append(person)\n",
    "                        self.logger.info(\"Loaded known face: %s (%s)\", person, f)\n",
    "                    else:\n",
    "                        self.logger.warning(\"No face found in %s\", path)\n",
    "                except Exception:\n",
    "                    self.logger.exception(\"Failed loading face %s\", path)\n",
    "        self.logger.info(\"Total known faces: %d\", len(self.known_encodings))\n",
    "\n",
    "    def _setup_alarm(self):\n",
    "        pygame.mixer.init()\n",
    "        self.alarm_loaded = False\n",
    "        if os.path.exists(self.cfg.ALARM_FILE):\n",
    "            try:\n",
    "                pygame.mixer.music.load(self.cfg.ALARM_FILE)\n",
    "                self.alarm_loaded = True\n",
    "                self.logger.info(\"Alarm sound loaded\")\n",
    "            except Exception:\n",
    "                self.logger.exception(\"Failed to load alarm sound\")\n",
    "        else:\n",
    "            self.logger.warning(\"Alarm file not found: %s\", self.cfg.ALARM_FILE)\n",
    "\n",
    "    # ---------- detection helpers ----------\n",
    "    def _is_in_secure_zone(self, bbox: Tuple[int,int,int,int], frame_shape) -> bool:\n",
    "        if not self.cfg.SECURE_ZONE_REL:\n",
    "            return True\n",
    "        h, w = frame_shape[:2]\n",
    "        rx1, ry1, rx2, ry2 = self.cfg.SECURE_ZONE_REL\n",
    "        sx1, sy1, sx2, sy2 = int(rx1*w), int(ry1*h), int(rx2*w), int(ry2*h)\n",
    "        x1,y1,x2,y2 = bbox\n",
    "        # check center point inside zone\n",
    "        cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "        return (sx1 <= cx <= sx2) and (sy1 <= cy <= sy2)\n",
    "\n",
    "    def _get_person_id(self, bbox: Tuple[int,int,int,int]) -> str:\n",
    "        x1,y1,x2,y2 = bbox\n",
    "        cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "        return f\"{cx//50}_{cy//50}\"\n",
    "\n",
    "    def _save_snapshot(self, frame, prefix=\"unknown\"):\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        fname = os.path.join(self.cfg.OUTPUT_DIR, f\"{prefix}_snap_{ts}.jpg\")\n",
    "        cv2.imwrite(fname, frame)\n",
    "        self.logger.info(\"Snapshot saved: %s\", fname)\n",
    "        return fname\n",
    "\n",
    "    def _save_clip_from_buffer(self, fps=None, prefix=\"unknown\"):\n",
    "        if fps is None:\n",
    "            fps = self.cfg.CLIP_FPS\n",
    "        if not self.ring_buffer:\n",
    "            self.logger.warning(\"Ring buffer empty, no clip to save\")\n",
    "            return None\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        fname = os.path.join(self.cfg.OUTPUT_DIR, f\"{prefix}_clip_{ts}.avi\")\n",
    "        h, w = self.ring_buffer[0].shape[:2]\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(fname, fourcc, fps, (w,h))\n",
    "        for f in self.ring_buffer:\n",
    "            out.write(f)\n",
    "        out.release()\n",
    "        self.logger.info(\"Clip saved: %s\", fname)\n",
    "        return fname\n",
    "\n",
    "    def _play_alarm_sound(self):\n",
    "        if not self.alarm_loaded:\n",
    "            self.logger.warning(\"No alarm sound loaded\")\n",
    "            return\n",
    "        try:\n",
    "            if not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play()\n",
    "                self.logger.info(\"Playing alarm sound\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Failed to play alarm\")\n",
    "\n",
    "    def _trigger_buzzer(self):\n",
    "        if not (self.cfg.USE_GPIO and HAS_RPI):\n",
    "            return\n",
    "        try:\n",
    "            GPIO.output(self.cfg.BUZZER_PIN, GPIO.HIGH)\n",
    "            time.sleep(self.cfg.BUZZER_SECONDS)\n",
    "            GPIO.output(self.cfg.BUZZER_PIN, GPIO.LOW)\n",
    "            self.logger.info(\"Buzzer cycle complete\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"GPIO buzzer failed\")\n",
    "\n",
    "    def _send_telegram(self, text: str, image_path: Optional[str]=None):\n",
    "        if not self.cfg.USE_TELEGRAM or not self.cfg.TELEGRAM_BOT_TOKEN or not self.cfg.TELEGRAM_CHAT_ID:\n",
    "            return\n",
    "        try:\n",
    "            token = self.cfg.TELEGRAM_BOT_TOKEN\n",
    "            chat_id = self.cfg.TELEGRAM_CHAT_ID\n",
    "            url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "            payload = {\"chat_id\": chat_id, \"text\": text}\n",
    "            resp = requests.post(url, data=payload, timeout=10)\n",
    "            if resp.ok:\n",
    "                self.logger.info(\"Telegram message sent\")\n",
    "            if image_path and self.cfg.SEND_IMAGE_ON_ALERT:\n",
    "                url2 = f\"https://api.telegram.org/bot{token}/sendPhoto\"\n",
    "                with open(image_path, \"rb\") as f:\n",
    "                    files = {\"photo\": f}\n",
    "                    data = {\"chat_id\": chat_id, \"caption\": text}\n",
    "                    r2 = requests.post(url2, files=files, data=data, timeout=20)\n",
    "                    if r2.ok:\n",
    "                        self.logger.info(\"Telegram image sent\")\n",
    "        except Exception:\n",
    "            self.logger.exception(\"Telegram send failed\")\n",
    "\n",
    "    # ---------- recognition voting ----------\n",
    "    def _update_history(self, person_id: str, name: str, dist: Optional[float]):\n",
    "        now = time.time()\n",
    "        e = self.detection_history.get(person_id)\n",
    "        if not e:\n",
    "            e = {\"name_counts\": defaultdict(int), \"last_name\": None, \"consecutive\":0, \"last_update\": now, \"last_distance\": None}\n",
    "            self.detection_history[person_id] = e\n",
    "        if now - e[\"last_update\"] > self.cfg.RECOGNITION_TIME_WINDOW:\n",
    "            e[\"name_counts\"] = defaultdict(int)\n",
    "            e[\"last_name\"] = None\n",
    "            e[\"consecutive\"] = 0\n",
    "            e[\"last_distance\"] = None\n",
    "        e[\"name_counts\"][name] += 1\n",
    "        if e[\"last_name\"] == name:\n",
    "            e[\"consecutive\"] += 1\n",
    "        else:\n",
    "            e[\"last_name\"] = name\n",
    "            e[\"consecutive\"] = 1\n",
    "        e[\"last_update\"] = now\n",
    "        e[\"last_distance\"] = dist\n",
    "\n",
    "    def _confirm_recognition(self, person_id: str, name: str, dist: Optional[float]) -> bool:\n",
    "        e = self.detection_history.get(person_id)\n",
    "        if not e:\n",
    "            return False\n",
    "        now = time.time()\n",
    "        if now - e[\"last_update\"] > self.cfg.RECOGNITION_TIME_WINDOW:\n",
    "            return False\n",
    "        # strong acceptance if low distance\n",
    "        if name != \"UNKNOWN\" and dist is not None and dist <= self.cfg.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return True\n",
    "        # votes\n",
    "        votes = e[\"name_counts\"].get(name, 0)\n",
    "        if name != \"UNKNOWN\" and votes >= self.cfg.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        if name != \"UNKNOWN\" and e[\"consecutive\"] >= self.cfg.RECOGNITION_CONSECUTIVE_FRAMES:\n",
    "            return True\n",
    "        # if UNKNOWN gets multiple votes treat as confirmed unknown\n",
    "        if name == \"UNKNOWN\" and votes >= self.cfg.RECOGNITION_MIN_VOTES:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _match_face(self, encoding) -> Tuple[Optional[str], Optional[float]]:\n",
    "        if not self.known_encodings:\n",
    "            return None, None\n",
    "        try:\n",
    "            dists = face_recognition.face_distance(self.known_encodings, encoding)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"face_distance error\")\n",
    "            return None, None\n",
    "        idx = int(np.argmin(dists))\n",
    "        best = float(dists[idx])\n",
    "        if best <= self.cfg.RECOGNITION_DISTANCE_THRESHOLD:\n",
    "            return self.known_names[idx], best\n",
    "        else:\n",
    "            return \"UNKNOWN\", best\n",
    "\n",
    "    # ---------- alert logic ----------\n",
    "    def _should_alert(self, person_id: str, is_unknown: bool) -> bool:\n",
    "        now = time.time()\n",
    "        if not is_unknown:\n",
    "            return False\n",
    "        if now - self.last_alert_time <= self.cfg.ALERT_COOLDOWN:\n",
    "            return False\n",
    "        last = self.person_alert_times.get(person_id)\n",
    "        if last and (now - last) <= self.cfg.PERSON_COOLDOWN:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def _handle_alert_actions(self, frame_for_save, person_bbox):\n",
    "        # run non-blocking actions: play sound, buzzer, save files, send telegram\n",
    "        # save snapshot and clip\n",
    "        snap = self._save_snapshot(frame_for_save, prefix=\"unknown\")\n",
    "        clip = self._save_clip_from_buffer(prefix=\"unknown\")\n",
    "        self.last_alert_time = time.time()\n",
    "        pid = self._get_person_id(person_bbox)\n",
    "        self.person_alert_times[pid] = self.last_alert_time\n",
    "\n",
    "        # spawn threads for alarm and notifications\n",
    "        threads = []\n",
    "        t_sound = threading.Thread(target=self._play_alarm_sound, daemon=True)\n",
    "        threads.append(t_sound)\n",
    "        if self.cfg.USE_GPIO and HAS_RPI:\n",
    "            t_buzz = threading.Thread(target=self._trigger_buzzer, daemon=True)\n",
    "            threads.append(t_buzz)\n",
    "        if self.cfg.USE_TELEGRAM and self.cfg.TELEGRAM_BOT_TOKEN:\n",
    "            text = f\"ALERT: Unknown person detected at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "            t_tele = threading.Thread(target=self._send_telegram, args=(text, snap), daemon=True)\n",
    "            threads.append(t_tele)\n",
    "        for t in threads:\n",
    "            t.start()\n",
    "        self.logger.warning(\"Alert actions started (threads spawned)\")\n",
    "\n",
    "    # ---------- core processing ----------\n",
    "    def process_frame(self, frame: np.ndarray) -> np.ndarray:\n",
    "        self.frame_count += 1\n",
    "        # keep in ring buffer (for clip saving)\n",
    "        self.ring_buffer.append(frame.copy())\n",
    "\n",
    "        annotated = frame.copy()\n",
    "        # self.extract_tracks(frame.copy())\n",
    "        annotator = SolutionAnnotator(annotated, line_width=self.line_width)\n",
    "        \n",
    "        # detect objects\n",
    "        try:\n",
    "            results = self.yolo.track(frame, conf=self.cfg.YOLO_CONFIDENCE, persist=True)\n",
    "        except Exception:\n",
    "            self.logger.exception(\"YOLO inference failed\")\n",
    "            results = []\n",
    "\n",
    "        detections = []\n",
    "        for res in results:\n",
    "            if getattr(res, \"boxes\", None) is None:\n",
    "                continue\n",
    "            for box in res.boxes:\n",
    "                x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                t_id = int(box.id[0]) if box.id is not None else None\n",
    "                name = res.names[cls] if hasattr(res, \"names\") else str(cls)\n",
    "                detections.append({\"bbox\":(x1,y1,x2,y2), \"class_name\":name, \"confidence\":conf, \"box\": box, \"cls\": cls, \"t_id\": t_id})\n",
    "\n",
    "        # person detections\n",
    "        persons = [d for d in detections if d[\"class_name\"] == \"person\"]\n",
    "        objects = [d[\"class_name\"] for d in detections if d[\"class_name\"] in self.cfg.OBJECTS_OF_INTEREST and d[\"class_name\"]!=\"person\"]\n",
    "\n",
    "        process_faces = (self.frame_count % self.cfg.FACE_RECOGNITION_INTERVAL) == 0\n",
    "        for p in persons:\n",
    "            box, cls, conf, t_id = p[\"box\"], p[\"cls\"], p[\"confidence\"], p[\"t_id\"]\n",
    "            # extract bbox and clamp\n",
    "            x1, y1, x2, y2 = p[\"bbox\"]\n",
    "            x1, y1, x2, y2 = p[\"bbox\"]\n",
    "            x1 = max(0, x1); y1 = max(0, y1)\n",
    "            x2 = min(frame.shape[1]-1, x2); y2 = min(frame.shape[0]-1, y2)\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "            pid = self._get_person_id((x1, y1, x2, y2))\n",
    "\n",
    "            # draw person box basic\n",
    "            cv2.rectangle(annotator, (x1, y1), (x2, y2), (0,165,255), 2)\n",
    "\n",
    "            # skip if ROI empty\n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            # check secure zone\n",
    "            in_zone = self._is_in_secure_zone((x1, y1, x2, y2), frame.shape)\n",
    "            if not in_zone:\n",
    "                # label as outside zone\n",
    "                cv2.putText(annotator, \"Outside Zone\", (x1, y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "                continue\n",
    "\n",
    "            # face detection using mediapipe for visual box and cropping\n",
    "            faces = []\n",
    "            try:\n",
    "                rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "                res = self.mp_detector.process(rgb)\n",
    "                if res and getattr(res, \"detections\", None):\n",
    "                    h, w = roi.shape[:2]\n",
    "                    for det in res.detections:\n",
    "                        r = det.location_data.relative_bounding_box\n",
    "                        fx = int(r.xmin * w)\n",
    "                        fy = int(r.ymin * h)\n",
    "                        fw = int(r.width * w)\n",
    "                        fh = int(r.height * h)\n",
    "                        faces.append((fx, fy, fw, fh))\n",
    "                        cv2.rectangle(annotator, (x1+fx, y1+fy), (x1+fx+fw, y1+fy+fh), (255,0,0), 1)\n",
    "            except Exception:\n",
    "                self.logger.exception(\"Face detection failure\")\n",
    "\n",
    "            # perform face recognition at intervals and if face found\n",
    "            recognized_name = None\n",
    "            is_confirmed_known = False\n",
    "            is_confirmed_unknown = False\n",
    "\n",
    "            if process_faces and faces:\n",
    "                # Use the first detected face for simplicity and performance\n",
    "                fx, fy, fw, fh = faces[0]\n",
    "                fx0, fy0 = max(0, fx), max(0, fy)\n",
    "                fx1, fy1 = min(roi.shape[1], fx + fw), min(roi.shape[0], fy + fh)\n",
    "\n",
    "                if fx1 > fx0 and fy1 > fy0:\n",
    "                    face_crop = roi[fy0:fy1, fx0:fx1]\n",
    "                    try:\n",
    "                        rgb_face = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)\n",
    "                        encodings = face_recognition.face_encodings(rgb_face)\n",
    "                        if encodings:\n",
    "                            name, dist = self._match_face(encodings[0])\n",
    "                            vote_name = name if name is not None else \"UNKNOWN\"\n",
    "                            self._update_history(pid, vote_name, dist)\n",
    "                    except Exception:\n",
    "                        self.logger.exception(\"Face encoding or matching error\")\n",
    "\n",
    "            # --- Confirmation and Alerting Logic ---\n",
    "            history = self.detection_history.get(pid)\n",
    "            if history:\n",
    "                # Check if confirmed as any known person\n",
    "                for known_name in self.known_names:\n",
    "                    if self._confirm_recognition(pid, known_name, history.get(\"last_distance\")):\n",
    "                        is_confirmed_known = True\n",
    "                        recognized_name = known_name\n",
    "                        break\n",
    "                # If not a known person, check if confirmed as unknown\n",
    "                if not is_confirmed_known:\n",
    "                    if self._confirm_recognition(pid, \"UNKNOWN\", history.get(\"last_distance\")):\n",
    "                        is_confirmed_unknown = True\n",
    "\n",
    "            # --- Annotation and Action ---\n",
    "            # if is_confirmed_known:\n",
    "            #     cv2.putText(annotated, f\"{recognized_name} ✓\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "            # elif is_confirmed_unknown:\n",
    "            #     if self._should_alert(pid, is_unknown=True):\n",
    "            #         self._handle_alert_actions(frame, (x1, y1, x2, y2))\n",
    "            #     cv2.putText(annotated, \"UNKNOWN - ALERT\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "            if is_confirmed_known:\n",
    "                color = (0, 255, 0)  # Green for Known\n",
    "                label = f\"{recognized_name}\"\n",
    "                base_label = self.adjust_box_label(cls, conf, t_id)\n",
    "                final_label = f\"{label}: {base_label}\" if base_label else label\n",
    "                annotator.box_label(box, label=final_label, color=color)\n",
    "            elif is_confirmed_unknown:\n",
    "                if self._should_alert(pid, is_unknown=True):\n",
    "                    self._handle_alert_actions(frame, (x1, y1, x2, y2))\n",
    "                color = (0, 0, 255)  # Red for Unknown\n",
    "                label_text = f\"Unknown ({conf:.2f})\"\n",
    "                base_label = self.adjust_box_label(int(cls), float(conf) if conf is not None else 0.0, t_id)\n",
    "\n",
    "                # Custom label for 'person' class (COCO id 0).\n",
    "                prefix = str(self.CFG.get(\"person_label_prefix\", label_text))\n",
    "                custom_label = f\"{prefix}:\"\n",
    "                final_label = f\"{custom_label} {base_label}\" if base_label else custom_label\n",
    "                annotator.box_label(box, label=final_label, color=color)\n",
    "            else:\n",
    "                # For an unconfirmed person, use default labeling\n",
    "                annotator.box_label(box, label=self.adjust_box_label(cls, conf, t_id), color=colors(t_id if t_id is not None else cls, True))\n",
    "                \n",
    "            annotator.visioneye(box, self.vision_points.get(t_id, None))\n",
    "\n",
    "        # draw secure zone\n",
    "        if self.cfg.SECURE_ZONE_REL:\n",
    "            h,w = frame.shape[:2]\n",
    "            rx1,ry1,rx2,ry2 = self.cfg.SECURE_ZONE_REL\n",
    "            sx1,sy1,sx2,sy2 = int(rx1*w), int(ry1*h), int(rx2*w), int(ry2*h)\n",
    "            cv2.rectangle(annotator, (sx1,sy1), (sx2,sy2), (0,255,0), 1)\n",
    "            cv2.putText(annotator, \"Secure Zone\", (sx1+5, sy1+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)\n",
    "\n",
    "        # show fps & status\n",
    "        fps = int(1.0 / max(1e-3, (time.time() - getattr(self, \"_last_t\", time.time()))))\n",
    "        self._last_t = time.time()\n",
    "        cv2.putText(annotator, f\"FPS: {fps}\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
    "\n",
    "        # return annotator\n",
    "        plot_im = annotator.result()\n",
    "        self.display_output(plot_im) \n",
    "        \n",
    "        \n",
    "        # Display track count on the frame\n",
    "        total_tracks = len(getattr(self, \"track_ids\", []))\n",
    "        cv2.putText(plot_im, f\"Tracks: {total_tracks}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        return SolutionResults(plot_im=plot_im, total_tracks=len(self.track_ids))\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(self.cfg.VIDEO_SOURCE)\n",
    "        if not cap.isOpened():\n",
    "            self.logger.error(\"Cannot open video source: %s\", self.cfg.VIDEO_SOURCE)\n",
    "            return\n",
    "        self.logger.info(\"Starting monitoring. Press 'q' to quit.\")\n",
    "        try:\n",
    "            while True: \n",
    "                # ret, frame = cap.read()\n",
    "                # if not ret:\n",
    "                #     self.logger.warning(\"Frame read failed or video ended\")\n",
    "                #     break\n",
    "                # # annotated = self.process_frame(frame)\n",
    "                # annotator = process_frame(frame)\n",
    "                # cv2.imshow(self.cfg.WINDOW_NAME, annotator)\n",
    "                success, im0 = cap.read()\n",
    "\n",
    "                if not success:\n",
    "                    print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "                    break\n",
    "\n",
    "                results = self.process_frame(im0)\n",
    "\n",
    "                print(results) \n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        except KeyboardInterrupt:\n",
    "            self.logger.info(\"Interrupted by user\")\n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            if self.cfg.USE_GPIO and HAS_RPI:\n",
    "                GPIO.cleanup()\n",
    "            self.logger.info(\"Shutdown complete\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = Config()\n",
    "    # === USER: adjust configuration below as needed ===\n",
    "    # cfg.VIDEO_SOURCE = \"your_camera_or_video_path\"\n",
    "    # cfg.MODEL_PATH = \"yolov8n.pt\"\n",
    "    # cfg.KNOWN_FACES_DIR = \"./known_faces\"\n",
    "    # cfg.ALARM_FILE = \"./alarm.mp3\"\n",
    "    # cfg.USE_TELEGRAM = True\n",
    "    # cfg.TELEGRAM_BOT_TOKEN = \"<token>\"\n",
    "    # cfg.TELEGRAM_CHAT_ID = \"<chat_id>\"\n",
    "    # cfg.USE_GPIO = True  # only on Raspberry Pi\n",
    "    # ===================================================\n",
    "    system = SecuritySurveillance(cfg=cfg, model=cfg.MODEL_PATH, source=cfg.VIDEO_SOURCE)\n",
    "    system.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_YOLO_WITH_FACE_RECOGNITION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
