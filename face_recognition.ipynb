{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3dcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7804cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "# import smtplib\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def detect_faces_mediapipe(frame):\n",
    "    \"\"\"\n",
    "    Detect faces using MediaPipe\n",
    "    Returns list of face bounding boxes in format [x, y, w, h]\n",
    "    \"\"\"\n",
    "    face_boxes = []\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        # Convert BGR to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(rgb_frame)\n",
    "        \n",
    "        if results.detections:\n",
    "            h, w, _ = frame.shape\n",
    "            for detection in results.detections:\n",
    "                bbox = detection.location_data.relative_bounding_box\n",
    "                x = int(bbox.xmin * w)\n",
    "                y = int(bbox.ymin * h)\n",
    "                width = int(bbox.width * w)\n",
    "                height = int(bbox.height * h)\n",
    "                face_boxes.append([x, y, width, height])\n",
    "    \n",
    "    return face_boxes\n",
    "\n",
    "# def draw_detections(frame, yolo_results, face_boxes):\n",
    "#     \"\"\"\n",
    "#     Draw YOLO detections and face detections on frame\n",
    "#     \"\"\"\n",
    "#     result_frame = frame.copy()\n",
    "    \n",
    "#     # Draw YOLO detections\n",
    "#     if yolo_results and len(yolo_results) > 0:\n",
    "#         for result in yolo_results:\n",
    "#             if result.boxes is not None:\n",
    "#                 boxes = result.boxes.xyxy.cpu().numpy()\n",
    "#                 confidences = result.boxes.conf.cpu().numpy()\n",
    "#                 classes = result.boxes.cls.cpu().numpy()\n",
    "                \n",
    "#                 for box, conf, cls in zip(boxes, confidences, classes):\n",
    "#                     x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "#                     # Get class name\n",
    "#                     class_name = result.names[int(cls)] if hasattr(result, 'names') else f\"Class {int(cls)}\"\n",
    "                    \n",
    "#                     # Draw bounding box\n",
    "#                     cv2.rectangle(result_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "#                     # Draw label\n",
    "#                     label = f\"{class_name}: {conf:.2f}\"\n",
    "#                     label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "#                     cv2.rectangle(result_frame, (x1, y1 - label_size[1] - 10), \n",
    "#                                 (x1 + label_size[0], y1), (0, 255, 0), -1)\n",
    "#                     cv2.putText(result_frame, label, (x1, y1 - 5), \n",
    "#                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
    "    \n",
    "#     # Draw face detections\n",
    "#     for face_box in face_boxes:\n",
    "#         x, y, w, h = face_box\n",
    "#         # Draw face bounding box in red\n",
    "#         cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        \n",
    "#         # Draw face label\n",
    "#         cv2.rectangle(result_frame, (x, y - 25), (x + 60, y), (0, 0, 255), -1)\n",
    "#         cv2.putText(result_frame, \"Face\", (x + 5, y - 5), \n",
    "#                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    \n",
    "#     return result_frame\n",
    "\n",
    "# Initialize YOLO model for object detection\n",
    "# Using YOLOv8n which can detect 80 different object classes\n",
    "# model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "model = YOLO(\"yolo11m.pt\")\n",
    "\n",
    "# Initialize MediaPipe for pose detection\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Load known faces\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Setup for known faces - replace with your implementation\n",
    "known_faces_dir = \"images\"  # Create this directory and add images\n",
    "if os.path.exists(known_faces_dir):\n",
    "    for person_name in os.listdir(known_faces_dir):\n",
    "        person_dir = os.path.join(known_faces_dir, person_name)\n",
    "        if os.path.isdir(person_dir):\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, image_name)\n",
    "                try:\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    face_encodings = face_recognition.face_encodings(image)\n",
    "                    if face_encodings:\n",
    "                        known_face_encodings.append(face_encodings[0])\n",
    "                        known_face_names.append(person_name)\n",
    "                        print(f\"Loaded face: {person_name} from {image_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {image_path}: {e}\")\n",
    "\n",
    "# Print summary of loaded faces\n",
    "if known_face_encodings:\n",
    "    print(f\"Successfully loaded {len(known_face_encodings)} face encodings for {len(set(known_face_names))} people\")\n",
    "else:\n",
    "    print(\"Warning: No face encodings loaded. Face recognition will not work.\")\n",
    "\n",
    "# Setup alarm sound\n",
    "pygame.mixer.init()\n",
    "alarm_file = \"pols-aagyi-pols.mp3\"\n",
    "if os.path.exists(alarm_file):\n",
    "    pygame.mixer.music.load(alarm_file)\n",
    "else:\n",
    "    print(f\"Warning: Alarm file {alarm_file} not found\")\n",
    "\n",
    "# Create log directory\n",
    "log_dir = \"security_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "def log_event(event_type, details=\"\"):\n",
    "    \"\"\"Log security events to file\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_file = os.path.join(log_dir, f\"security_log_{datetime.now().strftime('%Y-%m-%d')}.txt\")\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{timestamp} - {event_type}: {details}\\n\")\n",
    "\n",
    "def  send_email_alert(person_name=\"Unknown\", objects_detected=None):\n",
    "    \"\"\"Function to send email alert when a person is detected.\"\"\"\n",
    "    if objects_detected is None:\n",
    "        objects_detected = []\n",
    "    \n",
    "    objects_str = \", \".join(objects_detected) if objects_detected else \"None\"\n",
    "    log_event(\"ALERT_TRIGGERED\", f\"Person: {person_name}, Objects: {objects_str}\")\n",
    "    print(f\"Alert triggered: {person_name} detected with objects: {objects_str}\")\n",
    "\n",
    "# Start Video Capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap = cv2.VideoCapture(\"./Test-Video-And-Images/istockphoto-2174886250-640_adpp_is.mp4\")\n",
    "# cap = cv2.VideoCapture(\"https://www.youtube.com/watch?v=wswxrDiSiHI\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture device\")\n",
    "    exit()\n",
    "\n",
    "# Performance optimization variables\n",
    "frame_count = 0\n",
    "face_recognition_interval = 5  # Process face recognition every 5 frames\n",
    "last_alert_time = 0\n",
    "alert_cooldown = 10  # Seconds between alerts\n",
    "\n",
    "# Define objects of interest (subset of COCO classes that YOLO can detect)\n",
    "objects_of_interest = [\n",
    "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"bus\", \"truck\", \"mouse\"\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\",\n",
    "    \"cell phone\", \"laptop\", \"book\", \"scissors\", \"knife\", \"face\"\n",
    "]\n",
    "\n",
    "print(\"Security monitoring started. Press 'q' to quit.\")\n",
    "log_event(\"SYSTEM_START\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Start a high-resolution timer to measure performance or track elapsed time using OpenCV's getTickCount() method\n",
    "        timer = cv2.getTickCount()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        # Determine whether to process faces based on frame count interval\n",
    "        # Helps optimize performance by reducing face recognition computations\n",
    "        process_faces = frame_count % face_recognition_interval == 0\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # YOLO Detection for all objects\n",
    "        # results = model.predict(frame, conf=0.5, verbose=False)\n",
    "        results = model(frame, imgsz=640, verbose=False)\n",
    "        # results = \n",
    "        \n",
    "        # Face Detection using MediaPipe\n",
    "        # results = model.predict(frame, conf=0.5, classes=[i for i in range(100) if i != 0], verbose=False\n",
    "        # results = model.predict(frame, conf=0.5, classes=[i for i in range(100) if i != 0], verbose=False)\n",
    "        # results = detect_faces_mediapipe(frame)\n",
    "        \n",
    "        # Visualize the results on the frame\n",
    "        # annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        # cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "        \n",
    "        # Track detected objects in this frame\n",
    "        detected_objects = []\n",
    "        detected_persons = []\n",
    "\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            \n",
    "            for i, box in enumerate(boxes):\n",
    "                # Get box coordinates\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                \n",
    "                # Ensure coordinates are within frame boundaries\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "                \n",
    "                if x2 <= x1 or y2 <= y1:\n",
    "                    continue  # Skip invalid boxes\n",
    "                \n",
    "                # Get class and confidence\n",
    "                cls = int(box.cls[0])\n",
    "                conf = float(box.conf[0])\n",
    "                class_name = result.names[cls]\n",
    "                \n",
    "                # Add to detected objects list if it's an object of interest\n",
    "                if class_name in objects_of_interest and class_name != \"person\":\n",
    "                    detected_objects.append(class_name)\n",
    "                    \n",
    "                    # Draw bounding box for object\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # Display object name and confidence\n",
    "                    label = f\"{class_name}: {conf:.2f}\"\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)                \n",
    "                \n",
    "                # Process persons separately for face recognition\n",
    "                if class_name == \"person\":\n",
    "                    detected_persons.append((x1, y1, x2, y2))\n",
    "                    person_roi = frame[y1:y2, x1:x2]\n",
    "                    \n",
    "                    # Only proceed if person ROI is valid\n",
    "                    if person_roi.size > 0 and person_roi.shape[0] > 0 and person_roi.shape[1] > 0:\n",
    "                        # Face detection on person ROI\n",
    "                        face_boxes = detect_faces_mediapipe(person_roi)\n",
    "                        \n",
    "                        if face_boxes:\n",
    "                            # Draw bounding boxes around faces (not person)\n",
    "                            for face_box in face_boxes:\n",
    "                                fx, fy, fw, fh = face_box\n",
    "                                # Adjust face coordinates to original frame coordinates\n",
    "                                face_x1 = x1 + fx\n",
    "                                face_y1 = y1 + fy\n",
    "                                face_x2 = face_x1 + fw\n",
    "                                face_y2 = face_y1 + fh\n",
    "                                \n",
    "                                # Draw face bounding box in red\n",
    "                                cv2.rectangle(frame, (face_x1, face_y1), (face_x2, face_y2), (0, 0, 255), 2)\n",
    "                                \n",
    "                                # Add face label\n",
    "                                # cv2.rectangle(frame, (face_x1, face_y1 - 25), (face_x1 + 60, face_y1), (0, 0, 255), -1)\n",
    "                                cv2.putText(frame, \"Face\", (face_x1 + 5, face_y1 - 5), \n",
    "                                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                                # cv2.putText(frame, \"KNOWN: {name}\",(face_x1 + 20, face_y1 - 20), \n",
    "                                #           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                        # else:\n",
    "                        #     # If no face detected in person, draw person box with \"No Face\" label\n",
    "                        #     cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "                        #     cv2.putText(frame, \"Person - No Face\", (x1, y1 - 10), \n",
    "                        #               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "                    # Face Recognition - only process every few frames\n",
    "                    # Conditionally process face recognition only at specified intervals and when a valid person region of interest (ROI) exists\n",
    "                    if process_faces and person_roi.size > 0:\n",
    "                        # Convert the person ROI to RGB format\n",
    "                        # Converts BGR (Blue, Green, Red) color space to RGB (Red, Green, Blue) color space\n",
    "                        # Used for face recognition and comparison\n",
    "                        rgb_small_frame = cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB)\n",
    "                       \n",
    "                        # Resize the person region of interest to a smaller scale for faster face recognition processing\n",
    "                        # Reduces image dimensions to 25% of the original size using bilinear interpolation\n",
    "                        # Helps improve performance by reducing computational complexity of face detection\n",
    "                        small_frame = cv2.resize(person_roi, (0, 0), fx=0.25, fy=0.25)\n",
    "                        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                                                \n",
    "                        \n",
    "                        # Detect face locations in a resized RGB frame using face_recognition library\n",
    "                        # Identifies and returns the bounding box coordinates of faces in the input image\n",
    "                        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "                        # Identifies face locations and generates corresponding face encodings\n",
    "                        \n",
    "                        if face_locations:\n",
    "                            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "                            \n",
    "                            for face_encoding in face_encodings:\n",
    "                                if known_face_encodings:  # Only compare if we have known faces\n",
    "                                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                                    \n",
    "                                    if any(matches):\n",
    "                                        # Find the name of the matched person\n",
    "                                        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                                        best_match_index = np.argmin(face_distances)\n",
    "                                        if matches[best_match_index]:\n",
    "                                            name = known_face_names[best_match_index]\n",
    "                                            \n",
    "                                            print(f\"✅ Known Person Detected: {name}\")\n",
    "                                            cv2.putText(frame, f\"KNOWN: {name}\", (x1, y1 - 10), \n",
    "                                                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                                            \n",
    "                                            # Alert with cooldown\n",
    "                                            if current_time - last_alert_time > alert_cooldown:\n",
    "                                                if not pygame.mixer.music.get_busy():\n",
    "                                                    pygame.mixer.music.play()\n",
    "                                                # send_email_alert(name, detected_objects)\n",
    "                                                log_event(\"KNOWN_PERSON\", f\"Detected: {name} with objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "                                                last_alert_time = current_time\n",
    "                                    else:\n",
    "                                        print(\"⚠️ Unknown Person Detected!\")\n",
    "                                        cv2.putText(frame, \"UNKNOWN\", (x1, y1 - 10), \n",
    "                                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                                        log_event(\"UNKNOWN_PERSON\", f\"With objects: {', '.join(detected_objects) if detected_objects else 'None'}\")\n",
    "        \n",
    "        # Display detected objects summary\n",
    "        if detected_objects:\n",
    "            objects_text = f\"Objects: {', '.join(set(detected_objects))}\"\n",
    "            cv2.putText(frame, objects_text, (20, 60), \n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        \n",
    "        # Calculate and display FPS\n",
    "        fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "      \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Security Monitoring', frame)\n",
    "        \n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    log_event(\"SYSTEM_ERROR\", str(e))\n",
    "finally:\n",
    "    # Clean up resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pose.close()  # Close MediaPipe resources\n",
    "    pygame.mixer.quit()\n",
    "    log_event(\"SYSTEM_SHUTDOWN\")\n",
    "    print(\"Security monitoring stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11_ext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
